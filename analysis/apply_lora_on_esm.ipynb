{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/RuBisCO_ML/ESM_LoRA/analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "%cd /home/kaustubh/RuBisCO_ML/ESM_LoRA/analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lora_esm2_script_updated import *\n",
    "# from lora_esm2_script_updated import CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "NVIDIA L40S\n",
      "OrderedDict({'active.all.allocated': 0, 'active.all.current': 0, 'active.all.freed': 0, 'active.all.peak': 0, 'active.large_pool.allocated': 0, 'active.large_pool.current': 0, 'active.large_pool.freed': 0, 'active.large_pool.peak': 0, 'active.small_pool.allocated': 0, 'active.small_pool.current': 0, 'active.small_pool.freed': 0, 'active.small_pool.peak': 0, 'active_bytes.all.allocated': 0, 'active_bytes.all.current': 0, 'active_bytes.all.freed': 0, 'active_bytes.all.peak': 0, 'active_bytes.large_pool.allocated': 0, 'active_bytes.large_pool.current': 0, 'active_bytes.large_pool.freed': 0, 'active_bytes.large_pool.peak': 0, 'active_bytes.small_pool.allocated': 0, 'active_bytes.small_pool.current': 0, 'active_bytes.small_pool.freed': 0, 'active_bytes.small_pool.peak': 0, 'allocated_bytes.all.allocated': 0, 'allocated_bytes.all.current': 0, 'allocated_bytes.all.freed': 0, 'allocated_bytes.all.peak': 0, 'allocated_bytes.large_pool.allocated': 0, 'allocated_bytes.large_pool.current': 0, 'allocated_bytes.large_pool.freed': 0, 'allocated_bytes.large_pool.peak': 0, 'allocated_bytes.small_pool.allocated': 0, 'allocated_bytes.small_pool.current': 0, 'allocated_bytes.small_pool.freed': 0, 'allocated_bytes.small_pool.peak': 0, 'allocation.all.allocated': 0, 'allocation.all.current': 0, 'allocation.all.freed': 0, 'allocation.all.peak': 0, 'allocation.large_pool.allocated': 0, 'allocation.large_pool.current': 0, 'allocation.large_pool.freed': 0, 'allocation.large_pool.peak': 0, 'allocation.small_pool.allocated': 0, 'allocation.small_pool.current': 0, 'allocation.small_pool.freed': 0, 'allocation.small_pool.peak': 0, 'inactive_split.all.allocated': 0, 'inactive_split.all.current': 0, 'inactive_split.all.freed': 0, 'inactive_split.all.peak': 0, 'inactive_split.large_pool.allocated': 0, 'inactive_split.large_pool.current': 0, 'inactive_split.large_pool.freed': 0, 'inactive_split.large_pool.peak': 0, 'inactive_split.small_pool.allocated': 0, 'inactive_split.small_pool.current': 0, 'inactive_split.small_pool.freed': 0, 'inactive_split.small_pool.peak': 0, 'inactive_split_bytes.all.allocated': 0, 'inactive_split_bytes.all.current': 0, 'inactive_split_bytes.all.freed': 0, 'inactive_split_bytes.all.peak': 0, 'inactive_split_bytes.large_pool.allocated': 0, 'inactive_split_bytes.large_pool.current': 0, 'inactive_split_bytes.large_pool.freed': 0, 'inactive_split_bytes.large_pool.peak': 0, 'inactive_split_bytes.small_pool.allocated': 0, 'inactive_split_bytes.small_pool.current': 0, 'inactive_split_bytes.small_pool.freed': 0, 'inactive_split_bytes.small_pool.peak': 0, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 0, 'num_device_free': 0, 'num_ooms': 0, 'num_sync_all_streams': 0, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 0, 'requested_bytes.all.current': 0, 'requested_bytes.all.freed': 0, 'requested_bytes.all.peak': 0, 'requested_bytes.large_pool.allocated': 0, 'requested_bytes.large_pool.current': 0, 'requested_bytes.large_pool.freed': 0, 'requested_bytes.large_pool.peak': 0, 'requested_bytes.small_pool.allocated': 0, 'requested_bytes.small_pool.current': 0, 'requested_bytes.small_pool.freed': 0, 'requested_bytes.small_pool.peak': 0, 'reserved_bytes.all.allocated': 0, 'reserved_bytes.all.current': 0, 'reserved_bytes.all.freed': 0, 'reserved_bytes.all.peak': 0, 'reserved_bytes.large_pool.allocated': 0, 'reserved_bytes.large_pool.current': 0, 'reserved_bytes.large_pool.freed': 0, 'reserved_bytes.large_pool.peak': 0, 'reserved_bytes.small_pool.allocated': 0, 'reserved_bytes.small_pool.current': 0, 'reserved_bytes.small_pool.freed': 0, 'reserved_bytes.small_pool.peak': 0, 'segment.all.allocated': 0, 'segment.all.current': 0, 'segment.all.freed': 0, 'segment.all.peak': 0, 'segment.large_pool.allocated': 0, 'segment.large_pool.current': 0, 'segment.large_pool.freed': 0, 'segment.large_pool.peak': 0, 'segment.small_pool.allocated': 0, 'segment.small_pool.current': 0, 'segment.small_pool.freed': 0, 'segment.small_pool.peak': 0})\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.memory_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'active.all.allocated': 0, 'active.all.current': 0, 'active.all.freed': 0, 'active.all.peak': 0, 'active.large_pool.allocated': 0, 'active.large_pool.current': 0, 'active.large_pool.freed': 0, 'active.large_pool.peak': 0, 'active.small_pool.allocated': 0, 'active.small_pool.current': 0, 'active.small_pool.freed': 0, 'active.small_pool.peak': 0, 'active_bytes.all.allocated': 0, 'active_bytes.all.current': 0, 'active_bytes.all.freed': 0, 'active_bytes.all.peak': 0, 'active_bytes.large_pool.allocated': 0, 'active_bytes.large_pool.current': 0, 'active_bytes.large_pool.freed': 0, 'active_bytes.large_pool.peak': 0, 'active_bytes.small_pool.allocated': 0, 'active_bytes.small_pool.current': 0, 'active_bytes.small_pool.freed': 0, 'active_bytes.small_pool.peak': 0, 'allocated_bytes.all.allocated': 0, 'allocated_bytes.all.current': 0, 'allocated_bytes.all.freed': 0, 'allocated_bytes.all.peak': 0, 'allocated_bytes.large_pool.allocated': 0, 'allocated_bytes.large_pool.current': 0, 'allocated_bytes.large_pool.freed': 0, 'allocated_bytes.large_pool.peak': 0, 'allocated_bytes.small_pool.allocated': 0, 'allocated_bytes.small_pool.current': 0, 'allocated_bytes.small_pool.freed': 0, 'allocated_bytes.small_pool.peak': 0, 'allocation.all.allocated': 0, 'allocation.all.current': 0, 'allocation.all.freed': 0, 'allocation.all.peak': 0, 'allocation.large_pool.allocated': 0, 'allocation.large_pool.current': 0, 'allocation.large_pool.freed': 0, 'allocation.large_pool.peak': 0, 'allocation.small_pool.allocated': 0, 'allocation.small_pool.current': 0, 'allocation.small_pool.freed': 0, 'allocation.small_pool.peak': 0, 'inactive_split.all.allocated': 0, 'inactive_split.all.current': 0, 'inactive_split.all.freed': 0, 'inactive_split.all.peak': 0, 'inactive_split.large_pool.allocated': 0, 'inactive_split.large_pool.current': 0, 'inactive_split.large_pool.freed': 0, 'inactive_split.large_pool.peak': 0, 'inactive_split.small_pool.allocated': 0, 'inactive_split.small_pool.current': 0, 'inactive_split.small_pool.freed': 0, 'inactive_split.small_pool.peak': 0, 'inactive_split_bytes.all.allocated': 0, 'inactive_split_bytes.all.current': 0, 'inactive_split_bytes.all.freed': 0, 'inactive_split_bytes.all.peak': 0, 'inactive_split_bytes.large_pool.allocated': 0, 'inactive_split_bytes.large_pool.current': 0, 'inactive_split_bytes.large_pool.freed': 0, 'inactive_split_bytes.large_pool.peak': 0, 'inactive_split_bytes.small_pool.allocated': 0, 'inactive_split_bytes.small_pool.current': 0, 'inactive_split_bytes.small_pool.freed': 0, 'inactive_split_bytes.small_pool.peak': 0, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 0, 'num_device_free': 0, 'num_ooms': 0, 'num_sync_all_streams': 1, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 0, 'requested_bytes.all.current': 0, 'requested_bytes.all.freed': 0, 'requested_bytes.all.peak': 0, 'requested_bytes.large_pool.allocated': 0, 'requested_bytes.large_pool.current': 0, 'requested_bytes.large_pool.freed': 0, 'requested_bytes.large_pool.peak': 0, 'requested_bytes.small_pool.allocated': 0, 'requested_bytes.small_pool.current': 0, 'requested_bytes.small_pool.freed': 0, 'requested_bytes.small_pool.peak': 0, 'reserved_bytes.all.allocated': 0, 'reserved_bytes.all.current': 0, 'reserved_bytes.all.freed': 0, 'reserved_bytes.all.peak': 0, 'reserved_bytes.large_pool.allocated': 0, 'reserved_bytes.large_pool.current': 0, 'reserved_bytes.large_pool.freed': 0, 'reserved_bytes.large_pool.peak': 0, 'reserved_bytes.small_pool.allocated': 0, 'reserved_bytes.small_pool.current': 0, 'reserved_bytes.small_pool.freed': 0, 'reserved_bytes.small_pool.peak': 0, 'segment.all.allocated': 0, 'segment.all.current': 0, 'segment.all.freed': 0, 'segment.all.peak': 0, 'segment.large_pool.allocated': 0, 'segment.large_pool.current': 0, 'segment.large_pool.freed': 0, 'segment.large_pool.peak': 0, 'segment.small_pool.allocated': 0, 'segment.small_pool.current': 0, 'segment.small_pool.freed': 0, 'segment.small_pool.peak': 0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['method', 'metric', 'parameters'])\n",
      "Trial 1/10\n",
      "learning_rate:  1e-05\n",
      "OrderedDict({'active.all.allocated': 770, 'active.all.current': 770, 'active.all.freed': 0, 'active.all.peak': 770, 'active.large_pool.allocated': 200, 'active.large_pool.current': 200, 'active.large_pool.freed': 0, 'active.large_pool.peak': 200, 'active.small_pool.allocated': 570, 'active.small_pool.current': 570, 'active.small_pool.freed': 0, 'active.small_pool.peak': 570, 'active_bytes.all.allocated': 2694874112, 'active_bytes.all.current': 2694874112, 'active_bytes.all.freed': 0, 'active_bytes.all.peak': 2694874112, 'active_bytes.large_pool.allocated': 2676238336, 'active_bytes.large_pool.current': 2676238336, 'active_bytes.large_pool.freed': 0, 'active_bytes.large_pool.peak': 2676238336, 'active_bytes.small_pool.allocated': 18635776, 'active_bytes.small_pool.current': 18635776, 'active_bytes.small_pool.freed': 0, 'active_bytes.small_pool.peak': 18635776, 'allocated_bytes.all.allocated': 2694874112, 'allocated_bytes.all.current': 2694874112, 'allocated_bytes.all.freed': 0, 'allocated_bytes.all.peak': 2694874112, 'allocated_bytes.large_pool.allocated': 2676238336, 'allocated_bytes.large_pool.current': 2676238336, 'allocated_bytes.large_pool.freed': 0, 'allocated_bytes.large_pool.peak': 2676238336, 'allocated_bytes.small_pool.allocated': 18635776, 'allocated_bytes.small_pool.current': 18635776, 'allocated_bytes.small_pool.freed': 0, 'allocated_bytes.small_pool.peak': 18635776, 'allocation.all.allocated': 770, 'allocation.all.current': 770, 'allocation.all.freed': 0, 'allocation.all.peak': 770, 'allocation.large_pool.allocated': 200, 'allocation.large_pool.current': 200, 'allocation.large_pool.freed': 0, 'allocation.large_pool.peak': 200, 'allocation.small_pool.allocated': 570, 'allocation.small_pool.current': 570, 'allocation.small_pool.freed': 0, 'allocation.small_pool.peak': 570, 'inactive_split.all.allocated': 54, 'inactive_split.all.current': 48, 'inactive_split.all.freed': 6, 'inactive_split.all.peak': 49, 'inactive_split.large_pool.allocated': 45, 'inactive_split.large_pool.current': 45, 'inactive_split.large_pool.freed': 0, 'inactive_split.large_pool.peak': 45, 'inactive_split.small_pool.allocated': 9, 'inactive_split.small_pool.current': 3, 'inactive_split.small_pool.freed': 6, 'inactive_split.small_pool.peak': 5, 'inactive_split_bytes.all.allocated': 668279808, 'inactive_split_bytes.all.current': 67075072, 'inactive_split_bytes.all.freed': 601204736, 'inactive_split_bytes.all.peak': 73704448, 'inactive_split_bytes.large_pool.allocated': 650106880, 'inactive_split_bytes.large_pool.current': 66836480, 'inactive_split_bytes.large_pool.freed': 583270400, 'inactive_split_bytes.large_pool.peak': 73390080, 'inactive_split_bytes.small_pool.allocated': 18172928, 'inactive_split_bytes.small_pool.current': 238592, 'inactive_split_bytes.small_pool.freed': 17934336, 'inactive_split_bytes.small_pool.peak': 2094592, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 120, 'num_device_free': 0, 'num_ooms': 0, 'num_sync_all_streams': 2, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 2625653480, 'requested_bytes.all.current': 2625653480, 'requested_bytes.all.freed': 0, 'requested_bytes.all.peak': 2625653480, 'requested_bytes.large_pool.allocated': 2607032320, 'requested_bytes.large_pool.current': 2607032320, 'requested_bytes.large_pool.freed': 0, 'requested_bytes.large_pool.peak': 2607032320, 'requested_bytes.small_pool.allocated': 18621160, 'requested_bytes.small_pool.current': 18621160, 'requested_bytes.small_pool.freed': 0, 'requested_bytes.small_pool.peak': 18621160, 'reserved_bytes.all.allocated': 2761949184, 'reserved_bytes.all.current': 2761949184, 'reserved_bytes.all.freed': 0, 'reserved_bytes.all.peak': 2761949184, 'reserved_bytes.large_pool.allocated': 2743074816, 'reserved_bytes.large_pool.current': 2743074816, 'reserved_bytes.large_pool.freed': 0, 'reserved_bytes.large_pool.peak': 2743074816, 'reserved_bytes.small_pool.allocated': 18874368, 'reserved_bytes.small_pool.current': 18874368, 'reserved_bytes.small_pool.freed': 0, 'reserved_bytes.small_pool.peak': 18874368, 'segment.all.allocated': 120, 'segment.all.current': 120, 'segment.all.freed': 0, 'segment.all.peak': 120, 'segment.large_pool.allocated': 111, 'segment.large_pool.current': 111, 'segment.large_pool.freed': 0, 'segment.large_pool.peak': 111, 'segment.small_pool.allocated': 9, 'segment.small_pool.current': 9, 'segment.small_pool.freed': 0, 'segment.small_pool.peak': 9})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkauamritkar\u001b[0m (\u001b[33mkauamritkar-university-of-wisconsin-madison\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kaustubh/RuBisCO_ML/ESM_LoRA/analysis/wandb/run-20250507_013909-q8uaodkp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface/runs/q8uaodkp' target=\"_blank\">/home/kaustubh/RuBisCO_ML/ESM_LoRA/training_runs/esm2_t33_650M-finetuned-lora_2025-05-07_01-39-02</a></strong> to <a href='https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface' target=\"_blank\">https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface/runs/q8uaodkp' target=\"_blank\">https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface/runs/q8uaodkp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 34:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.664780</td>\n",
       "      <td>0.751860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.634400</td>\n",
       "      <td>0.595468</td>\n",
       "      <td>0.798207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.497100</td>\n",
       "      <td>0.537516</td>\n",
       "      <td>0.870940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.541700</td>\n",
       "      <td>0.510735</td>\n",
       "      <td>0.878762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.494398</td>\n",
       "      <td>0.889910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.8899103537598091\n",
      "Updating best trial\n",
      "Trial 2/10\n",
      "learning_rate:  0.00010899999999999999\n",
      "OrderedDict({'active.all.allocated': 18703059, 'active.all.current': 2474, 'active.all.freed': 18700585, 'active.all.peak': 3453, 'active.large_pool.allocated': 11514427, 'active.large_pool.current': 402, 'active.large_pool.freed': 11514025, 'active.large_pool.peak': 903, 'active.small_pool.allocated': 7188632, 'active.small_pool.current': 2072, 'active.small_pool.freed': 7186560, 'active.small_pool.peak': 2650, 'active_bytes.all.allocated': 286799897923584, 'active_bytes.all.current': 5442967552, 'active_bytes.all.freed': 286794454956032, 'active_bytes.all.peak': 18568513536, 'active_bytes.large_pool.allocated': 285895438946304, 'active_bytes.large_pool.current': 5369516032, 'active_bytes.large_pool.freed': 285890069430272, 'active_bytes.large_pool.peak': 18463608832, 'active_bytes.small_pool.allocated': 904458977280, 'active_bytes.small_pool.current': 73451520, 'active_bytes.small_pool.freed': 904385525760, 'active_bytes.small_pool.peak': 105969664, 'allocated_bytes.all.allocated': 286799897923584, 'allocated_bytes.all.current': 5442967552, 'allocated_bytes.all.freed': 286794454956032, 'allocated_bytes.all.peak': 18568513536, 'allocated_bytes.large_pool.allocated': 285895438946304, 'allocated_bytes.large_pool.current': 5369516032, 'allocated_bytes.large_pool.freed': 285890069430272, 'allocated_bytes.large_pool.peak': 18463608832, 'allocated_bytes.small_pool.allocated': 904458977280, 'allocated_bytes.small_pool.current': 73451520, 'allocated_bytes.small_pool.freed': 904385525760, 'allocated_bytes.small_pool.peak': 105969664, 'allocation.all.allocated': 18703059, 'allocation.all.current': 2474, 'allocation.all.freed': 18700585, 'allocation.all.peak': 3453, 'allocation.large_pool.allocated': 11514427, 'allocation.large_pool.current': 402, 'allocation.large_pool.freed': 11514025, 'allocation.large_pool.peak': 903, 'allocation.small_pool.allocated': 7188632, 'allocation.small_pool.current': 2072, 'allocation.small_pool.freed': 7186560, 'allocation.small_pool.peak': 2650, 'inactive_split.all.allocated': 7944061, 'inactive_split.all.current': 135, 'inactive_split.all.freed': 7943926, 'inactive_split.all.peak': 399, 'inactive_split.large_pool.allocated': 6069088, 'inactive_split.large_pool.current': 93, 'inactive_split.large_pool.freed': 6068995, 'inactive_split.large_pool.peak': 203, 'inactive_split.small_pool.allocated': 1874973, 'inactive_split.small_pool.current': 42, 'inactive_split.small_pool.freed': 1874931, 'inactive_split.small_pool.peak': 196, 'inactive_split_bytes.all.allocated': 166789602402304, 'inactive_split_bytes.all.current': 162719744, 'inactive_split_bytes.all.freed': 166789439682560, 'inactive_split_bytes.all.peak': 2027309056, 'inactive_split_bytes.large_pool.allocated': 165776753473536, 'inactive_split_bytes.large_pool.current': 160673792, 'inactive_split_bytes.large_pool.freed': 165776592799744, 'inactive_split_bytes.large_pool.peak': 2017576960, 'inactive_split_bytes.small_pool.allocated': 1012848928768, 'inactive_split_bytes.small_pool.current': 2045952, 'inactive_split_bytes.small_pool.freed': 1012846882816, 'inactive_split_bytes.small_pool.peak': 19872768, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 432, 'num_device_free': 172, 'num_ooms': 0, 'num_sync_all_streams': 4, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 286681272669166, 'requested_bytes.all.current': 5304524256, 'requested_bytes.all.freed': 286675968144910, 'requested_bytes.all.peak': 18430066204, 'requested_bytes.large_pool.allocated': 285777811104920, 'requested_bytes.large_pool.current': 5231104000, 'requested_bytes.large_pool.freed': 285772580000920, 'requested_bytes.large_pool.peak': 18325196800, 'requested_bytes.small_pool.allocated': 903461564246, 'requested_bytes.small_pool.current': 73420256, 'requested_bytes.small_pool.freed': 903388143990, 'requested_bytes.small_pool.peak': 105936396, 'reserved_bytes.all.allocated': 20264779776, 'reserved_bytes.all.current': 5605687296, 'reserved_bytes.all.freed': 14659092480, 'reserved_bytes.all.peak': 20264779776, 'reserved_bytes.large_pool.allocated': 20157825024, 'reserved_bytes.large_pool.current': 5530189824, 'reserved_bytes.large_pool.freed': 14627635200, 'reserved_bytes.large_pool.peak': 20157825024, 'reserved_bytes.small_pool.allocated': 106954752, 'reserved_bytes.small_pool.current': 75497472, 'reserved_bytes.small_pool.freed': 31457280, 'reserved_bytes.small_pool.peak': 106954752, 'segment.all.allocated': 432, 'segment.all.current': 260, 'segment.all.freed': 172, 'segment.all.peak': 432, 'segment.large_pool.allocated': 381, 'segment.large_pool.current': 224, 'segment.large_pool.freed': 157, 'segment.large_pool.peak': 381, 'segment.small_pool.allocated': 51, 'segment.small_pool.current': 36, 'segment.small_pool.freed': 15, 'segment.small_pool.peak': 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 34:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.365100</td>\n",
       "      <td>0.472515</td>\n",
       "      <td>0.921502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.231525</td>\n",
       "      <td>0.975443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.186113</td>\n",
       "      <td>0.985550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.991619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.326200</td>\n",
       "      <td>0.159005</td>\n",
       "      <td>0.991035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.9916194732965944\n",
      "Best trial metric: 0.8899103537598091\n",
      "Updating best trial\n",
      "Trial 3/10\n",
      "learning_rate:  0.000208\n",
      "OrderedDict({'active.all.allocated': 37405346, 'active.all.current': 3244, 'active.all.freed': 37402102, 'active.all.peak': 4223, 'active.large_pool.allocated': 23028652, 'active.large_pool.current': 602, 'active.large_pool.freed': 23028050, 'active.large_pool.peak': 1103, 'active.small_pool.allocated': 14376694, 'active.small_pool.current': 2642, 'active.small_pool.freed': 14374052, 'active.small_pool.peak': 3220, 'active_bytes.all.allocated': 573509185347584, 'active_bytes.all.current': 8137841664, 'active_bytes.all.freed': 573501047505920, 'active_bytes.all.peak': 21263387648, 'active_bytes.large_pool.allocated': 571700286028800, 'active_bytes.large_pool.current': 8045754368, 'active_bytes.large_pool.freed': 571692240274432, 'active_bytes.large_pool.peak': 21139847168, 'active_bytes.small_pool.allocated': 1808899318784, 'active_bytes.small_pool.current': 92087296, 'active_bytes.small_pool.freed': 1808807231488, 'active_bytes.small_pool.peak': 124605440, 'allocated_bytes.all.allocated': 573509185347584, 'allocated_bytes.all.current': 8137841664, 'allocated_bytes.all.freed': 573501047505920, 'allocated_bytes.all.peak': 21263387648, 'allocated_bytes.large_pool.allocated': 571700286028800, 'allocated_bytes.large_pool.current': 8045754368, 'allocated_bytes.large_pool.freed': 571692240274432, 'allocated_bytes.large_pool.peak': 21139847168, 'allocated_bytes.small_pool.allocated': 1808899318784, 'allocated_bytes.small_pool.current': 92087296, 'allocated_bytes.small_pool.freed': 1808807231488, 'allocated_bytes.small_pool.peak': 124605440, 'allocation.all.allocated': 37405346, 'allocation.all.current': 3244, 'allocation.all.freed': 37402102, 'allocation.all.peak': 4223, 'allocation.large_pool.allocated': 23028652, 'allocation.large_pool.current': 602, 'allocation.large_pool.freed': 23028050, 'allocation.large_pool.peak': 1103, 'allocation.small_pool.allocated': 14376694, 'allocation.small_pool.current': 2642, 'allocation.small_pool.freed': 14374052, 'allocation.small_pool.peak': 3220, 'inactive_split.all.allocated': 16319494, 'inactive_split.all.current': 192, 'inactive_split.all.freed': 16319302, 'inactive_split.all.peak': 455, 'inactive_split.large_pool.allocated': 12250266, 'inactive_split.large_pool.current': 136, 'inactive_split.large_pool.freed': 12250130, 'inactive_split.large_pool.peak': 247, 'inactive_split.small_pool.allocated': 4069228, 'inactive_split.small_pool.current': 56, 'inactive_split.small_pool.freed': 4069172, 'inactive_split.small_pool.peak': 209, 'inactive_split_bytes.all.allocated': 328046875006976, 'inactive_split_bytes.all.current': 187851776, 'inactive_split_bytes.all.freed': 328046687155200, 'inactive_split_bytes.all.peak': 2045841408, 'inactive_split_bytes.large_pool.allocated': 326026053069824, 'inactive_split_bytes.large_pool.current': 185567232, 'inactive_split_bytes.large_pool.freed': 326025867502592, 'inactive_split_bytes.large_pool.peak': 2035870720, 'inactive_split_bytes.small_pool.allocated': 2020821937152, 'inactive_split_bytes.small_pool.current': 2284544, 'inactive_split_bytes.small_pool.freed': 2020819652608, 'inactive_split_bytes.small_pool.peak': 33057792, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 724, 'num_device_free': 346, 'num_ooms': 0, 'num_sync_all_streams': 6, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 573359902645492, 'requested_bytes.all.current': 7930177736, 'requested_bytes.all.freed': 573351972467756, 'requested_bytes.all.peak': 21055719684, 'requested_bytes.large_pool.allocated': 571552998138160, 'requested_bytes.large_pool.current': 7838136320, 'requested_bytes.large_pool.freed': 571545160001840, 'requested_bytes.large_pool.peak': 20932229120, 'requested_bytes.small_pool.allocated': 1806904507332, 'requested_bytes.small_pool.current': 92041416, 'requested_bytes.small_pool.freed': 1806812465916, 'requested_bytes.small_pool.peak': 124557556, 'reserved_bytes.all.allocated': 37694210048, 'reserved_bytes.all.current': 8325693440, 'reserved_bytes.all.freed': 29368516608, 'reserved_bytes.all.peak': 23035117568, 'reserved_bytes.large_pool.allocated': 37536923648, 'reserved_bytes.large_pool.current': 8231321600, 'reserved_bytes.large_pool.freed': 29305602048, 'reserved_bytes.large_pool.peak': 22909288448, 'reserved_bytes.small_pool.allocated': 157286400, 'reserved_bytes.small_pool.current': 94371840, 'reserved_bytes.small_pool.freed': 62914560, 'reserved_bytes.small_pool.peak': 125829120, 'segment.all.allocated': 724, 'segment.all.current': 378, 'segment.all.freed': 346, 'segment.all.peak': 552, 'segment.large_pool.allocated': 649, 'segment.large_pool.current': 333, 'segment.large_pool.freed': 316, 'segment.large_pool.peak': 492, 'segment.small_pool.allocated': 75, 'segment.small_pool.current': 45, 'segment.small_pool.freed': 30, 'segment.small_pool.peak': 60})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 35:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.318350</td>\n",
       "      <td>0.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.323300</td>\n",
       "      <td>0.159207</td>\n",
       "      <td>0.986464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163700</td>\n",
       "      <td>0.178958</td>\n",
       "      <td>0.991264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.134554</td>\n",
       "      <td>0.995149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.131948</td>\n",
       "      <td>0.994972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.9951494527262107\n",
      "Best trial metric: 0.9916194732965944\n",
      "Updating best trial\n",
      "Trial 4/10\n",
      "learning_rate:  0.000307\n",
      "OrderedDict({'active.all.allocated': 56107633, 'active.all.current': 4014, 'active.all.freed': 56103619, 'active.all.peak': 4993, 'active.large_pool.allocated': 34542877, 'active.large_pool.current': 802, 'active.large_pool.freed': 34542075, 'active.large_pool.peak': 1303, 'active.small_pool.allocated': 21564756, 'active.small_pool.current': 3212, 'active.small_pool.freed': 21561544, 'active.small_pool.peak': 3790, 'active_bytes.all.allocated': 860218472771584, 'active_bytes.all.current': 10832715776, 'active_bytes.all.freed': 860207640055808, 'active_bytes.all.peak': 23958261760, 'active_bytes.large_pool.allocated': 857505133111296, 'active_bytes.large_pool.current': 10721992704, 'active_bytes.large_pool.freed': 857494411118592, 'active_bytes.large_pool.peak': 23816085504, 'active_bytes.small_pool.allocated': 2713339660288, 'active_bytes.small_pool.current': 110723072, 'active_bytes.small_pool.freed': 2713228937216, 'active_bytes.small_pool.peak': 143241216, 'allocated_bytes.all.allocated': 860218472771584, 'allocated_bytes.all.current': 10832715776, 'allocated_bytes.all.freed': 860207640055808, 'allocated_bytes.all.peak': 23958261760, 'allocated_bytes.large_pool.allocated': 857505133111296, 'allocated_bytes.large_pool.current': 10721992704, 'allocated_bytes.large_pool.freed': 857494411118592, 'allocated_bytes.large_pool.peak': 23816085504, 'allocated_bytes.small_pool.allocated': 2713339660288, 'allocated_bytes.small_pool.current': 110723072, 'allocated_bytes.small_pool.freed': 2713228937216, 'allocated_bytes.small_pool.peak': 143241216, 'allocation.all.allocated': 56107633, 'allocation.all.current': 4014, 'allocation.all.freed': 56103619, 'allocation.all.peak': 4993, 'allocation.large_pool.allocated': 34542877, 'allocation.large_pool.current': 802, 'allocation.large_pool.freed': 34542075, 'allocation.large_pool.peak': 1303, 'allocation.small_pool.allocated': 21564756, 'allocation.small_pool.current': 3212, 'allocation.small_pool.freed': 21561544, 'allocation.small_pool.peak': 3790, 'inactive_split.all.allocated': 24658621, 'inactive_split.all.current': 247, 'inactive_split.all.freed': 24658374, 'inactive_split.all.peak': 509, 'inactive_split.large_pool.allocated': 18467237, 'inactive_split.large_pool.current': 181, 'inactive_split.large_pool.freed': 18467056, 'inactive_split.large_pool.peak': 291, 'inactive_split.small_pool.allocated': 6191384, 'inactive_split.small_pool.current': 66, 'inactive_split.small_pool.freed': 6191318, 'inactive_split.small_pool.peak': 219, 'inactive_split_bytes.all.allocated': 490488165327872, 'inactive_split_bytes.all.current': 254926848, 'inactive_split_bytes.all.freed': 490487910401024, 'inactive_split_bytes.all.peak': 2112916480, 'inactive_split_bytes.large_pool.allocated': 487459534297088, 'inactive_split_bytes.large_pool.current': 252403712, 'inactive_split_bytes.large_pool.freed': 487459281893376, 'inactive_split_bytes.large_pool.peak': 2102707200, 'inactive_split_bytes.small_pool.allocated': 3028631030784, 'inactive_split_bytes.small_pool.current': 2523136, 'inactive_split_bytes.small_pool.freed': 3028628507648, 'inactive_split_bytes.small_pool.peak': 33409024, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 1017, 'num_device_free': 519, 'num_ooms': 0, 'num_sync_all_streams': 8, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 860038532621818, 'requested_bytes.all.current': 10555831216, 'requested_bytes.all.freed': 860027976790602, 'requested_bytes.all.peak': 23681373164, 'requested_bytes.large_pool.allocated': 857328185171400, 'requested_bytes.large_pool.current': 10445168640, 'requested_bytes.large_pool.freed': 857317740002760, 'requested_bytes.large_pool.peak': 23539261440, 'requested_bytes.small_pool.allocated': 2710347450418, 'requested_bytes.small_pool.current': 110662576, 'requested_bytes.small_pool.freed': 2710236787842, 'requested_bytes.small_pool.peak': 143178716, 'reserved_bytes.all.allocated': 55155097600, 'reserved_bytes.all.current': 11087642624, 'reserved_bytes.all.freed': 44067454976, 'reserved_bytes.all.peak': 25786580992, 'reserved_bytes.large_pool.allocated': 54947479552, 'reserved_bytes.large_pool.current': 10974396416, 'reserved_bytes.large_pool.freed': 43973083136, 'reserved_bytes.large_pool.peak': 25641877504, 'reserved_bytes.small_pool.allocated': 207618048, 'reserved_bytes.small_pool.current': 113246208, 'reserved_bytes.small_pool.freed': 94371840, 'reserved_bytes.small_pool.peak': 144703488, 'segment.all.allocated': 1017, 'segment.all.current': 498, 'segment.all.freed': 519, 'segment.all.peak': 671, 'segment.large_pool.allocated': 918, 'segment.large_pool.current': 444, 'segment.large_pool.freed': 474, 'segment.large_pool.peak': 602, 'segment.small_pool.allocated': 99, 'segment.small_pool.current': 54, 'segment.small_pool.freed': 45, 'segment.small_pool.peak': 69})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 35:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.340469</td>\n",
       "      <td>0.957894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>0.174444</td>\n",
       "      <td>0.984407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.178242</td>\n",
       "      <td>0.992864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.127899</td>\n",
       "      <td>0.995581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.226100</td>\n",
       "      <td>0.131180</td>\n",
       "      <td>0.995530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.9955811768291134\n",
      "Best trial metric: 0.9951494527262107\n",
      "Updating best trial\n",
      "Trial 5/10\n",
      "learning_rate:  0.000406\n",
      "OrderedDict({'active.all.allocated': 74809920, 'active.all.current': 4784, 'active.all.freed': 74805136, 'active.all.peak': 5763, 'active.large_pool.allocated': 46057102, 'active.large_pool.current': 1002, 'active.large_pool.freed': 46056100, 'active.large_pool.peak': 1503, 'active.small_pool.allocated': 28752818, 'active.small_pool.current': 3782, 'active.small_pool.freed': 28749036, 'active.small_pool.peak': 4360, 'active_bytes.all.allocated': 1147014763602944, 'active_bytes.all.current': 13527589888, 'active_bytes.all.freed': 1147001236013056, 'active_bytes.all.peak': 26653135872, 'active_bytes.large_pool.allocated': 1143396983601152, 'active_bytes.large_pool.current': 13398231040, 'active_bytes.large_pool.freed': 1143383585370112, 'active_bytes.large_pool.peak': 26492323840, 'active_bytes.small_pool.allocated': 3617780001792, 'active_bytes.small_pool.current': 129358848, 'active_bytes.small_pool.freed': 3617650642944, 'active_bytes.small_pool.peak': 161876992, 'allocated_bytes.all.allocated': 1147014763602944, 'allocated_bytes.all.current': 13527589888, 'allocated_bytes.all.freed': 1147001236013056, 'allocated_bytes.all.peak': 26653135872, 'allocated_bytes.large_pool.allocated': 1143396983601152, 'allocated_bytes.large_pool.current': 13398231040, 'allocated_bytes.large_pool.freed': 1143383585370112, 'allocated_bytes.large_pool.peak': 26492323840, 'allocated_bytes.small_pool.allocated': 3617780001792, 'allocated_bytes.small_pool.current': 129358848, 'allocated_bytes.small_pool.freed': 3617650642944, 'allocated_bytes.small_pool.peak': 161876992, 'allocation.all.allocated': 74809920, 'allocation.all.current': 4784, 'allocation.all.freed': 74805136, 'allocation.all.peak': 5763, 'allocation.large_pool.allocated': 46057102, 'allocation.large_pool.current': 1002, 'allocation.large_pool.freed': 46056100, 'allocation.large_pool.peak': 1503, 'allocation.small_pool.allocated': 28752818, 'allocation.small_pool.current': 3782, 'allocation.small_pool.freed': 28749036, 'allocation.small_pool.peak': 4360, 'inactive_split.all.allocated': 32968001, 'inactive_split.all.current': 307, 'inactive_split.all.freed': 32967694, 'inactive_split.all.peak': 584, 'inactive_split.large_pool.allocated': 24499186, 'inactive_split.large_pool.current': 226, 'inactive_split.large_pool.freed': 24498960, 'inactive_split.large_pool.peak': 337, 'inactive_split.small_pool.allocated': 8468815, 'inactive_split.small_pool.current': 81, 'inactive_split.small_pool.freed': 8468734, 'inactive_split.small_pool.peak': 248, 'inactive_split_bytes.all.allocated': 653680711816192, 'inactive_split_bytes.all.current': 322001920, 'inactive_split_bytes.all.freed': 653680389814272, 'inactive_split_bytes.all.peak': 2179853312, 'inactive_split_bytes.large_pool.allocated': 649648852667392, 'inactive_split_bytes.large_pool.current': 319240192, 'inactive_split_bytes.large_pool.freed': 649648533427200, 'inactive_split_bytes.large_pool.peak': 2169405440, 'inactive_split_bytes.small_pool.allocated': 4031859148800, 'inactive_split_bytes.small_pool.current': 2761728, 'inactive_split_bytes.small_pool.freed': 4031856387072, 'inactive_split_bytes.small_pool.peak': 33872896, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 1310, 'num_device_free': 692, 'num_ooms': 0, 'num_sync_all_streams': 10, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 1146717162598144, 'requested_bytes.all.current': 13181484696, 'requested_bytes.all.freed': 1146703981113448, 'requested_bytes.all.peak': 26307026644, 'requested_bytes.large_pool.allocated': 1143103372204640, 'requested_bytes.large_pool.current': 13052200960, 'requested_bytes.large_pool.freed': 1143090320003680, 'requested_bytes.large_pool.peak': 26146293760, 'requested_bytes.small_pool.allocated': 3613790393504, 'requested_bytes.small_pool.current': 129283736, 'requested_bytes.small_pool.freed': 3613661109768, 'requested_bytes.small_pool.peak': 161799876, 'reserved_bytes.all.allocated': 72609693696, 'reserved_bytes.all.current': 13849591808, 'reserved_bytes.all.freed': 58760101888, 'reserved_bytes.all.peak': 28542238720, 'reserved_bytes.large_pool.allocated': 72351744000, 'reserved_bytes.large_pool.current': 13717471232, 'reserved_bytes.large_pool.freed': 58634272768, 'reserved_bytes.large_pool.peak': 28378660864, 'reserved_bytes.small_pool.allocated': 257949696, 'reserved_bytes.small_pool.current': 132120576, 'reserved_bytes.small_pool.freed': 125829120, 'reserved_bytes.small_pool.peak': 163577856, 'segment.all.allocated': 1310, 'segment.all.current': 618, 'segment.all.freed': 692, 'segment.all.peak': 791, 'segment.large_pool.allocated': 1187, 'segment.large_pool.current': 555, 'segment.large_pool.freed': 632, 'segment.large_pool.peak': 713, 'segment.small_pool.allocated': 123, 'segment.small_pool.current': 63, 'segment.small_pool.freed': 60, 'segment.small_pool.peak': 78})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 35:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.410185</td>\n",
       "      <td>0.949031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.174425</td>\n",
       "      <td>0.988496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.185568</td>\n",
       "      <td>0.991315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.117152</td>\n",
       "      <td>0.995759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.110293</td>\n",
       "      <td>0.996622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.996622393783173\n",
      "Best trial metric: 0.9955811768291134\n",
      "Updating best trial\n",
      "Trial 6/10\n",
      "learning_rate:  0.000505\n",
      "OrderedDict({'active.all.allocated': 93512207, 'active.all.current': 5554, 'active.all.freed': 93506653, 'active.all.peak': 6533, 'active.large_pool.allocated': 57571327, 'active.large_pool.current': 1202, 'active.large_pool.freed': 57570125, 'active.large_pool.peak': 1703, 'active.small_pool.allocated': 35940880, 'active.small_pool.current': 4352, 'active.small_pool.freed': 35936528, 'active.small_pool.peak': 4930, 'active_bytes.all.allocated': 1433724051026944, 'active_bytes.all.current': 16222464000, 'active_bytes.all.freed': 1433707828562944, 'active_bytes.all.peak': 29348009984, 'active_bytes.large_pool.allocated': 1429201830683648, 'active_bytes.large_pool.current': 16074469376, 'active_bytes.large_pool.freed': 1429185756214272, 'active_bytes.large_pool.peak': 29168562176, 'active_bytes.small_pool.allocated': 4522220343296, 'active_bytes.small_pool.current': 147994624, 'active_bytes.small_pool.freed': 4522072348672, 'active_bytes.small_pool.peak': 180512768, 'allocated_bytes.all.allocated': 1433724051026944, 'allocated_bytes.all.current': 16222464000, 'allocated_bytes.all.freed': 1433707828562944, 'allocated_bytes.all.peak': 29348009984, 'allocated_bytes.large_pool.allocated': 1429201830683648, 'allocated_bytes.large_pool.current': 16074469376, 'allocated_bytes.large_pool.freed': 1429185756214272, 'allocated_bytes.large_pool.peak': 29168562176, 'allocated_bytes.small_pool.allocated': 4522220343296, 'allocated_bytes.small_pool.current': 147994624, 'allocated_bytes.small_pool.freed': 4522072348672, 'allocated_bytes.small_pool.peak': 180512768, 'allocation.all.allocated': 93512207, 'allocation.all.current': 5554, 'allocation.all.freed': 93506653, 'allocation.all.peak': 6533, 'allocation.large_pool.allocated': 57571327, 'allocation.large_pool.current': 1202, 'allocation.large_pool.freed': 57570125, 'allocation.large_pool.peak': 1703, 'allocation.small_pool.allocated': 35940880, 'allocation.small_pool.current': 4352, 'allocation.small_pool.freed': 35936528, 'allocation.small_pool.peak': 4930, 'inactive_split.all.allocated': 41460473, 'inactive_split.all.current': 359, 'inactive_split.all.freed': 41460114, 'inactive_split.all.peak': 633, 'inactive_split.large_pool.allocated': 30677531, 'inactive_split.large_pool.current': 270, 'inactive_split.large_pool.freed': 30677261, 'inactive_split.large_pool.peak': 381, 'inactive_split.small_pool.allocated': 10782942, 'inactive_split.small_pool.current': 89, 'inactive_split.small_pool.freed': 10782853, 'inactive_split.small_pool.peak': 254, 'inactive_split_bytes.all.allocated': 814879467907072, 'inactive_split_bytes.all.current': 368105472, 'inactive_split_bytes.all.freed': 814879099801600, 'inactive_split_bytes.all.peak': 2223997952, 'inactive_split_bytes.large_pool.allocated': 809838581350400, 'inactive_split_bytes.large_pool.current': 365105152, 'inactive_split_bytes.large_pool.freed': 809838216245248, 'inactive_split_bytes.large_pool.peak': 2215408640, 'inactive_split_bytes.small_pool.allocated': 5040886556672, 'inactive_split_bytes.small_pool.current': 3000320, 'inactive_split_bytes.small_pool.freed': 5040883556352, 'inactive_split_bytes.small_pool.peak': 34403328, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 1603, 'num_device_free': 866, 'num_ooms': 0, 'num_sync_all_streams': 12, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 1433395792574470, 'requested_bytes.all.current': 15807138176, 'requested_bytes.all.freed': 1433379985436294, 'requested_bytes.all.peak': 28932680124, 'requested_bytes.large_pool.allocated': 1428878559237880, 'requested_bytes.large_pool.current': 15659233280, 'requested_bytes.large_pool.freed': 1428862900004600, 'requested_bytes.large_pool.peak': 28753326080, 'requested_bytes.small_pool.allocated': 4517233336590, 'requested_bytes.small_pool.current': 147904896, 'requested_bytes.small_pool.freed': 4517085431694, 'requested_bytes.small_pool.peak': 180421036, 'reserved_bytes.all.allocated': 90060095488, 'reserved_bytes.all.current': 16590569472, 'reserved_bytes.all.freed': 73469526016, 'reserved_bytes.all.peak': 31299993600, 'reserved_bytes.large_pool.allocated': 89751814144, 'reserved_bytes.large_pool.current': 16439574528, 'reserved_bytes.large_pool.freed': 73312239616, 'reserved_bytes.large_pool.peak': 31117541376, 'reserved_bytes.small_pool.allocated': 308281344, 'reserved_bytes.small_pool.current': 150994944, 'reserved_bytes.small_pool.freed': 157286400, 'reserved_bytes.small_pool.peak': 182452224, 'segment.all.allocated': 1603, 'segment.all.current': 737, 'segment.all.freed': 866, 'segment.all.peak': 911, 'segment.large_pool.allocated': 1456, 'segment.large_pool.current': 665, 'segment.large_pool.freed': 791, 'segment.large_pool.peak': 824, 'segment.small_pool.allocated': 147, 'segment.small_pool.current': 72, 'segment.small_pool.freed': 75, 'segment.small_pool.peak': 87})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 34:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.318442</td>\n",
       "      <td>0.975062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.179211</td>\n",
       "      <td>0.986236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.168286</td>\n",
       "      <td>0.992127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.116151</td>\n",
       "      <td>0.996089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.108544</td>\n",
       "      <td>0.996216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.996216065215735\n",
      "Best trial metric: 0.996622393783173\n",
      "Trial 7/10\n",
      "learning_rate:  0.0006039999999999999\n",
      "OrderedDict({'active.all.allocated': 112214494, 'active.all.current': 6324, 'active.all.freed': 112208170, 'active.all.peak': 7303, 'active.large_pool.allocated': 69085552, 'active.large_pool.current': 1402, 'active.large_pool.freed': 69084150, 'active.large_pool.peak': 1903, 'active.small_pool.allocated': 43128942, 'active.small_pool.current': 4922, 'active.small_pool.freed': 43124020, 'active.small_pool.peak': 5500, 'active_bytes.all.allocated': 1720433338450944, 'active_bytes.all.current': 18917338112, 'active_bytes.all.freed': 1720414421112832, 'active_bytes.all.peak': 32042884096, 'active_bytes.large_pool.allocated': 1715006677766144, 'active_bytes.large_pool.current': 18750707712, 'active_bytes.large_pool.freed': 1714987927058432, 'active_bytes.large_pool.peak': 31844800512, 'active_bytes.small_pool.allocated': 5426660684800, 'active_bytes.small_pool.current': 166630400, 'active_bytes.small_pool.freed': 5426494054400, 'active_bytes.small_pool.peak': 199148544, 'allocated_bytes.all.allocated': 1720433338450944, 'allocated_bytes.all.current': 18917338112, 'allocated_bytes.all.freed': 1720414421112832, 'allocated_bytes.all.peak': 32042884096, 'allocated_bytes.large_pool.allocated': 1715006677766144, 'allocated_bytes.large_pool.current': 18750707712, 'allocated_bytes.large_pool.freed': 1714987927058432, 'allocated_bytes.large_pool.peak': 31844800512, 'allocated_bytes.small_pool.allocated': 5426660684800, 'allocated_bytes.small_pool.current': 166630400, 'allocated_bytes.small_pool.freed': 5426494054400, 'allocated_bytes.small_pool.peak': 199148544, 'allocation.all.allocated': 112214494, 'allocation.all.current': 6324, 'allocation.all.freed': 112208170, 'allocation.all.peak': 7303, 'allocation.large_pool.allocated': 69085552, 'allocation.large_pool.current': 1402, 'allocation.large_pool.freed': 69084150, 'allocation.large_pool.peak': 1903, 'allocation.small_pool.allocated': 43128942, 'allocation.small_pool.current': 4922, 'allocation.small_pool.freed': 43124020, 'allocation.small_pool.peak': 5500, 'inactive_split.all.allocated': 49983811, 'inactive_split.all.current': 418, 'inactive_split.all.freed': 49983393, 'inactive_split.all.peak': 693, 'inactive_split.large_pool.allocated': 36894506, 'inactive_split.large_pool.current': 315, 'inactive_split.large_pool.freed': 36894191, 'inactive_split.large_pool.peak': 425, 'inactive_split.small_pool.allocated': 13089305, 'inactive_split.small_pool.current': 103, 'inactive_split.small_pool.freed': 13089202, 'inactive_split.small_pool.peak': 271, 'inactive_split_bytes.all.allocated': 977321619035136, 'inactive_split_bytes.all.current': 433083392, 'inactive_split_bytes.all.freed': 977321185951744, 'inactive_split_bytes.all.peak': 2293170176, 'inactive_split_bytes.large_pool.allocated': 971272031120384, 'inactive_split_bytes.large_pool.current': 431941632, 'inactive_split_bytes.large_pool.freed': 971271599178752, 'inactive_split_bytes.large_pool.peak': 2282245120, 'inactive_split_bytes.small_pool.allocated': 6049587914752, 'inactive_split_bytes.small_pool.current': 1141760, 'inactive_split_bytes.small_pool.freed': 6049586772992, 'inactive_split_bytes.small_pool.peak': 35138560, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 1896, 'num_device_free': 1040, 'num_ooms': 0, 'num_sync_all_streams': 14, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 1720074422550796, 'requested_bytes.all.current': 18432791656, 'requested_bytes.all.freed': 1720055989759140, 'requested_bytes.all.peak': 31558333604, 'requested_bytes.large_pool.allocated': 1714653746271120, 'requested_bytes.large_pool.current': 18266265600, 'requested_bytes.large_pool.freed': 1714635480005520, 'requested_bytes.large_pool.peak': 31360358400, 'requested_bytes.small_pool.allocated': 5420676279676, 'requested_bytes.small_pool.current': 166526056, 'requested_bytes.small_pool.freed': 5420509753620, 'requested_bytes.small_pool.peak': 199042196, 'reserved_bytes.all.allocated': 107520983040, 'reserved_bytes.all.current': 19350421504, 'reserved_bytes.all.freed': 88170561536, 'reserved_bytes.all.peak': 34051457024, 'reserved_bytes.large_pool.allocated': 107162370048, 'reserved_bytes.large_pool.current': 19182649344, 'reserved_bytes.large_pool.freed': 87979720704, 'reserved_bytes.large_pool.peak': 33850130432, 'reserved_bytes.small_pool.allocated': 358612992, 'reserved_bytes.small_pool.current': 167772160, 'reserved_bytes.small_pool.freed': 190840832, 'reserved_bytes.small_pool.peak': 201326592, 'segment.all.allocated': 1896, 'segment.all.current': 856, 'segment.all.freed': 1040, 'segment.all.peak': 1030, 'segment.large_pool.allocated': 1725, 'segment.large_pool.current': 776, 'segment.large_pool.freed': 949, 'segment.large_pool.peak': 934, 'segment.small_pool.allocated': 171, 'segment.small_pool.current': 80, 'segment.small_pool.freed': 91, 'segment.small_pool.peak': 96})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 34:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.664200</td>\n",
       "      <td>0.673864</td>\n",
       "      <td>0.693781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.573600</td>\n",
       "      <td>0.536015</td>\n",
       "      <td>0.865277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>0.183299</td>\n",
       "      <td>0.977779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.231900</td>\n",
       "      <td>0.135181</td>\n",
       "      <td>0.992711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243300</td>\n",
       "      <td>0.124596</td>\n",
       "      <td>0.994743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.9947431241587729\n",
      "Best trial metric: 0.996622393783173\n",
      "Trial 8/10\n",
      "learning_rate:  0.000703\n",
      "OrderedDict({'active.all.allocated': 130916781, 'active.all.current': 7094, 'active.all.freed': 130909687, 'active.all.peak': 8073, 'active.large_pool.allocated': 80599777, 'active.large_pool.current': 1602, 'active.large_pool.freed': 80598175, 'active.large_pool.peak': 2103, 'active.small_pool.allocated': 50317004, 'active.small_pool.current': 5492, 'active.small_pool.freed': 50311512, 'active.small_pool.peak': 6070, 'active_bytes.all.allocated': 2007229629282304, 'active_bytes.all.current': 21612212224, 'active_bytes.all.freed': 2007208017070080, 'active_bytes.all.peak': 34737758208, 'active_bytes.large_pool.allocated': 2000898528256000, 'active_bytes.large_pool.current': 21426946048, 'active_bytes.large_pool.freed': 2000877101309952, 'active_bytes.large_pool.peak': 34521038848, 'active_bytes.small_pool.allocated': 6331101026304, 'active_bytes.small_pool.current': 185266176, 'active_bytes.small_pool.freed': 6330915760128, 'active_bytes.small_pool.peak': 217784320, 'allocated_bytes.all.allocated': 2007229629282304, 'allocated_bytes.all.current': 21612212224, 'allocated_bytes.all.freed': 2007208017070080, 'allocated_bytes.all.peak': 34737758208, 'allocated_bytes.large_pool.allocated': 2000898528256000, 'allocated_bytes.large_pool.current': 21426946048, 'allocated_bytes.large_pool.freed': 2000877101309952, 'allocated_bytes.large_pool.peak': 34521038848, 'allocated_bytes.small_pool.allocated': 6331101026304, 'allocated_bytes.small_pool.current': 185266176, 'allocated_bytes.small_pool.freed': 6330915760128, 'allocated_bytes.small_pool.peak': 217784320, 'allocation.all.allocated': 130916781, 'allocation.all.current': 7094, 'allocation.all.freed': 130909687, 'allocation.all.peak': 8073, 'allocation.large_pool.allocated': 80599777, 'allocation.large_pool.current': 1602, 'allocation.large_pool.freed': 80598175, 'allocation.large_pool.peak': 2103, 'allocation.small_pool.allocated': 50317004, 'allocation.small_pool.current': 5492, 'allocation.small_pool.freed': 50311512, 'allocation.small_pool.peak': 6070, 'inactive_split.all.allocated': 58172906, 'inactive_split.all.current': 479, 'inactive_split.all.freed': 58172427, 'inactive_split.all.peak': 752, 'inactive_split.large_pool.allocated': 42926459, 'inactive_split.large_pool.current': 360, 'inactive_split.large_pool.freed': 42926099, 'inactive_split.large_pool.peak': 471, 'inactive_split.small_pool.allocated': 15246447, 'inactive_split.small_pool.current': 119, 'inactive_split.small_pool.freed': 15246328, 'inactive_split.small_pool.peak': 282, 'inactive_split_bytes.all.allocated': 1140526108689408, 'inactive_split_bytes.all.current': 500158464, 'inactive_split_bytes.all.freed': 1140525608530944, 'inactive_split_bytes.all.peak': 2362310144, 'inactive_split_bytes.large_pool.allocated': 1133461438619648, 'inactive_split_bytes.large_pool.current': 498778112, 'inactive_split_bytes.large_pool.freed': 1133460939841536, 'inactive_split_bytes.large_pool.peak': 2348943360, 'inactive_split_bytes.small_pool.allocated': 7064670069760, 'inactive_split_bytes.small_pool.current': 1380352, 'inactive_split_bytes.small_pool.freed': 7064668689408, 'inactive_split_bytes.small_pool.peak': 35407872, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 2190, 'num_device_free': 1214, 'num_ooms': 0, 'num_sync_all_streams': 16, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 2006753052527122, 'requested_bytes.all.current': 21058445136, 'requested_bytes.all.freed': 2006731994081986, 'requested_bytes.all.peak': 34183987084, 'requested_bytes.large_pool.allocated': 2000428933304360, 'requested_bytes.large_pool.current': 20873297920, 'requested_bytes.large_pool.freed': 2000408060006440, 'requested_bytes.large_pool.peak': 33967390720, 'requested_bytes.small_pool.allocated': 6324119222762, 'requested_bytes.small_pool.current': 185147216, 'requested_bytes.small_pool.freed': 6323934075546, 'requested_bytes.small_pool.peak': 217663356, 'reserved_bytes.all.allocated': 124977676288, 'reserved_bytes.all.current': 22112370688, 'reserved_bytes.all.freed': 102865305600, 'reserved_bytes.all.peak': 36807114752, 'reserved_bytes.large_pool.allocated': 124566634496, 'reserved_bytes.large_pool.current': 21925724160, 'reserved_bytes.large_pool.freed': 102640910336, 'reserved_bytes.large_pool.peak': 36586913792, 'reserved_bytes.small_pool.allocated': 411041792, 'reserved_bytes.small_pool.current': 186646528, 'reserved_bytes.small_pool.freed': 224395264, 'reserved_bytes.small_pool.peak': 220200960, 'segment.all.allocated': 2190, 'segment.all.current': 976, 'segment.all.freed': 1214, 'segment.all.peak': 1150, 'segment.large_pool.allocated': 1994, 'segment.large_pool.current': 887, 'segment.large_pool.freed': 1107, 'segment.large_pool.peak': 1045, 'segment.small_pool.allocated': 196, 'segment.small_pool.current': 89, 'segment.small_pool.freed': 107, 'segment.small_pool.peak': 105})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 34:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.374676</td>\n",
       "      <td>0.938568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.153379</td>\n",
       "      <td>0.988521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.174418</td>\n",
       "      <td>0.988166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.112034</td>\n",
       "      <td>0.994616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.995378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.9953780125453946\n",
      "Best trial metric: 0.996622393783173\n",
      "Trial 9/10\n",
      "learning_rate:  0.000802\n",
      "OrderedDict({'active.all.allocated': 149619068, 'active.all.current': 7864, 'active.all.freed': 149611204, 'active.all.peak': 8843, 'active.large_pool.allocated': 92114002, 'active.large_pool.current': 1802, 'active.large_pool.freed': 92112200, 'active.large_pool.peak': 2303, 'active.small_pool.allocated': 57505066, 'active.small_pool.current': 6062, 'active.small_pool.freed': 57499004, 'active.small_pool.peak': 6640, 'active_bytes.all.allocated': 2293938916706304, 'active_bytes.all.current': 24307086336, 'active_bytes.all.freed': 2293914609619968, 'active_bytes.all.peak': 37432632320, 'active_bytes.large_pool.allocated': 2286703375338496, 'active_bytes.large_pool.current': 24103184384, 'active_bytes.large_pool.freed': 2286679272154112, 'active_bytes.large_pool.peak': 37197277184, 'active_bytes.small_pool.allocated': 7235541367808, 'active_bytes.small_pool.current': 203901952, 'active_bytes.small_pool.freed': 7235337465856, 'active_bytes.small_pool.peak': 236420096, 'allocated_bytes.all.allocated': 2293938916706304, 'allocated_bytes.all.current': 24307086336, 'allocated_bytes.all.freed': 2293914609619968, 'allocated_bytes.all.peak': 37432632320, 'allocated_bytes.large_pool.allocated': 2286703375338496, 'allocated_bytes.large_pool.current': 24103184384, 'allocated_bytes.large_pool.freed': 2286679272154112, 'allocated_bytes.large_pool.peak': 37197277184, 'allocated_bytes.small_pool.allocated': 7235541367808, 'allocated_bytes.small_pool.current': 203901952, 'allocated_bytes.small_pool.freed': 7235337465856, 'allocated_bytes.small_pool.peak': 236420096, 'allocation.all.allocated': 149619068, 'allocation.all.current': 7864, 'allocation.all.freed': 149611204, 'allocation.all.peak': 8843, 'allocation.large_pool.allocated': 92114002, 'allocation.large_pool.current': 1802, 'allocation.large_pool.freed': 92112200, 'allocation.large_pool.peak': 2303, 'allocation.small_pool.allocated': 57505066, 'allocation.small_pool.current': 6062, 'allocation.small_pool.freed': 57499004, 'allocation.small_pool.peak': 6640, 'inactive_split.all.allocated': 66729391, 'inactive_split.all.current': 536, 'inactive_split.all.freed': 66728855, 'inactive_split.all.peak': 801, 'inactive_split.large_pool.allocated': 49107600, 'inactive_split.large_pool.current': 404, 'inactive_split.large_pool.freed': 49107196, 'inactive_split.large_pool.peak': 515, 'inactive_split.small_pool.allocated': 17621791, 'inactive_split.small_pool.current': 132, 'inactive_split.small_pool.freed': 17621659, 'inactive_split.small_pool.peak': 288, 'inactive_split_bytes.all.allocated': 1301789704720384, 'inactive_split_bytes.all.current': 546262016, 'inactive_split_bytes.all.freed': 1301789158458368, 'inactive_split_bytes.all.peak': 2412608000, 'inactive_split_bytes.large_pool.allocated': 1293710660883456, 'inactive_split_bytes.large_pool.current': 544643072, 'inactive_split_bytes.large_pool.freed': 1293710116240384, 'inactive_split_bytes.large_pool.peak': 2394946560, 'inactive_split_bytes.small_pool.allocated': 8079043836928, 'inactive_split_bytes.small_pool.current': 1618944, 'inactive_split_bytes.small_pool.freed': 8079042217984, 'inactive_split_bytes.small_pool.peak': 37798912, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 2484, 'num_device_free': 1389, 'num_ooms': 0, 'num_sync_all_streams': 18, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 2293431682503448, 'requested_bytes.all.current': 23684098616, 'requested_bytes.all.freed': 2293407998404832, 'requested_bytes.all.peak': 36809640564, 'requested_bytes.large_pool.allocated': 2286204120337600, 'requested_bytes.large_pool.current': 23480330240, 'requested_bytes.large_pool.freed': 2286180640007360, 'requested_bytes.large_pool.peak': 36574423040, 'requested_bytes.small_pool.allocated': 7227562165848, 'requested_bytes.small_pool.current': 203768376, 'requested_bytes.small_pool.freed': 7227358397472, 'requested_bytes.small_pool.peak': 236284516, 'reserved_bytes.all.allocated': 142430175232, 'reserved_bytes.all.current': 24853348352, 'reserved_bytes.all.freed': 117576826880, 'reserved_bytes.all.peak': 39564869632, 'reserved_bytes.large_pool.allocated': 141966704640, 'reserved_bytes.large_pool.current': 24647827456, 'reserved_bytes.large_pool.freed': 117318877184, 'reserved_bytes.large_pool.peak': 39325794304, 'reserved_bytes.small_pool.allocated': 463470592, 'reserved_bytes.small_pool.current': 205520896, 'reserved_bytes.small_pool.freed': 257949696, 'reserved_bytes.small_pool.peak': 239075328, 'segment.all.allocated': 2484, 'segment.all.current': 1095, 'segment.all.freed': 1389, 'segment.all.peak': 1270, 'segment.large_pool.allocated': 2263, 'segment.large_pool.current': 997, 'segment.large_pool.freed': 1266, 'segment.large_pool.peak': 1156, 'segment.small_pool.allocated': 221, 'segment.small_pool.current': 98, 'segment.small_pool.freed': 123, 'segment.small_pool.peak': 114})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 34:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.319624</td>\n",
       "      <td>0.959723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.170412</td>\n",
       "      <td>0.986236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.182417</td>\n",
       "      <td>0.989562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.107225</td>\n",
       "      <td>0.994718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.110096</td>\n",
       "      <td>0.995175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.9951748482616756\n",
      "Best trial metric: 0.996622393783173\n",
      "Trial 10/10\n",
      "learning_rate:  0.000901\n",
      "OrderedDict({'active.all.allocated': 168321355, 'active.all.current': 8634, 'active.all.freed': 168312721, 'active.all.peak': 9613, 'active.large_pool.allocated': 103628227, 'active.large_pool.current': 2002, 'active.large_pool.freed': 103626225, 'active.large_pool.peak': 2503, 'active.small_pool.allocated': 64693128, 'active.small_pool.current': 6632, 'active.small_pool.freed': 64686496, 'active.small_pool.peak': 7210, 'active_bytes.all.allocated': 2580648204130304, 'active_bytes.all.current': 27001960448, 'active_bytes.all.freed': 2580621202169856, 'active_bytes.all.peak': 40127506432, 'active_bytes.large_pool.allocated': 2572508222420992, 'active_bytes.large_pool.current': 26779422720, 'active_bytes.large_pool.freed': 2572481442998272, 'active_bytes.large_pool.peak': 39873515520, 'active_bytes.small_pool.allocated': 8139981709312, 'active_bytes.small_pool.current': 222537728, 'active_bytes.small_pool.freed': 8139759171584, 'active_bytes.small_pool.peak': 255055872, 'allocated_bytes.all.allocated': 2580648204130304, 'allocated_bytes.all.current': 27001960448, 'allocated_bytes.all.freed': 2580621202169856, 'allocated_bytes.all.peak': 40127506432, 'allocated_bytes.large_pool.allocated': 2572508222420992, 'allocated_bytes.large_pool.current': 26779422720, 'allocated_bytes.large_pool.freed': 2572481442998272, 'allocated_bytes.large_pool.peak': 39873515520, 'allocated_bytes.small_pool.allocated': 8139981709312, 'allocated_bytes.small_pool.current': 222537728, 'allocated_bytes.small_pool.freed': 8139759171584, 'allocated_bytes.small_pool.peak': 255055872, 'allocation.all.allocated': 168321355, 'allocation.all.current': 8634, 'allocation.all.freed': 168312721, 'allocation.all.peak': 9613, 'allocation.large_pool.allocated': 103628227, 'allocation.large_pool.current': 2002, 'allocation.large_pool.freed': 103626225, 'allocation.large_pool.peak': 2503, 'allocation.small_pool.allocated': 64693128, 'allocation.small_pool.current': 6632, 'allocation.small_pool.freed': 64686496, 'allocation.small_pool.peak': 7210, 'inactive_split.all.allocated': 75269575, 'inactive_split.all.current': 593, 'inactive_split.all.freed': 75268982, 'inactive_split.all.peak': 864, 'inactive_split.large_pool.allocated': 55324573, 'inactive_split.large_pool.current': 449, 'inactive_split.large_pool.freed': 55324124, 'inactive_split.large_pool.peak': 559, 'inactive_split.small_pool.allocated': 19945002, 'inactive_split.small_pool.current': 144, 'inactive_split.small_pool.freed': 19944858, 'inactive_split.small_pool.peak': 305, 'inactive_split_bytes.all.allocated': 1464231751584768, 'inactive_split_bytes.all.current': 613337088, 'inactive_split_bytes.all.freed': 1464231138247680, 'inactive_split_bytes.all.peak': 2479683072, 'inactive_split_bytes.large_pool.allocated': 1455144032010240, 'inactive_split_bytes.large_pool.current': 611479552, 'inactive_split_bytes.large_pool.freed': 1455143420530688, 'inactive_split_bytes.large_pool.peak': 2461783040, 'inactive_split_bytes.small_pool.allocated': 9087719574528, 'inactive_split_bytes.small_pool.current': 1857536, 'inactive_split_bytes.small_pool.freed': 9087717716992, 'inactive_split_bytes.small_pool.peak': 38037504, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 2777, 'num_device_free': 1562, 'num_ooms': 0, 'num_sync_all_streams': 20, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 2580110312479774, 'requested_bytes.all.current': 26309752096, 'requested_bytes.all.freed': 2580084002727678, 'requested_bytes.all.peak': 39435294044, 'requested_bytes.large_pool.allocated': 2571979307370840, 'requested_bytes.large_pool.current': 26087362560, 'requested_bytes.large_pool.freed': 2571953220008280, 'requested_bytes.large_pool.peak': 39181455360, 'requested_bytes.small_pool.allocated': 8131005108934, 'requested_bytes.small_pool.current': 222389536, 'requested_bytes.small_pool.freed': 8130782719398, 'requested_bytes.small_pool.peak': 254905676, 'reserved_bytes.all.allocated': 159891062784, 'reserved_bytes.all.current': 27615297536, 'reserved_bytes.all.freed': 132275765248, 'reserved_bytes.all.peak': 42314235904, 'reserved_bytes.large_pool.allocated': 159377260544, 'reserved_bytes.large_pool.current': 27390902272, 'reserved_bytes.large_pool.freed': 131986358272, 'reserved_bytes.large_pool.peak': 42058383360, 'reserved_bytes.small_pool.allocated': 513802240, 'reserved_bytes.small_pool.current': 224395264, 'reserved_bytes.small_pool.freed': 289406976, 'reserved_bytes.small_pool.peak': 255852544, 'segment.all.allocated': 2777, 'segment.all.current': 1215, 'segment.all.freed': 1562, 'segment.all.peak': 1388, 'segment.large_pool.allocated': 2532, 'segment.large_pool.current': 1108, 'segment.large_pool.freed': 1424, 'segment.large_pool.peak': 1266, 'segment.small_pool.allocated': 245, 'segment.small_pool.current': 107, 'segment.small_pool.freed': 138, 'segment.small_pool.peak': 122})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 35:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.300386</td>\n",
       "      <td>0.968802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.179314</td>\n",
       "      <td>0.981537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.153933</td>\n",
       "      <td>0.991696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.995632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.096218</td>\n",
       "      <td>0.995632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7fb44b622900>\n",
      "Best current Metric: 0.9956319679000432\n",
      "Best trial metric: 0.996622393783173\n",
      "Best Trial: {'learning_rate': 0.000406, 'per_device_train_batch_size': 2, 0.996622393783173: 0.996622393783173}\n",
      "OrderedDict({'active.all.allocated': 187023642, 'active.all.current': 9404, 'active.all.freed': 187014238, 'active.all.peak': 10383, 'active.large_pool.allocated': 115142452, 'active.large_pool.current': 2202, 'active.large_pool.freed': 115140250, 'active.large_pool.peak': 2703, 'active.small_pool.allocated': 71881190, 'active.small_pool.current': 7202, 'active.small_pool.freed': 71873988, 'active.small_pool.peak': 7780, 'active_bytes.all.allocated': 2867444494961664, 'active_bytes.all.current': 29696834560, 'active_bytes.all.freed': 2867414798127104, 'active_bytes.all.peak': 42822380544, 'active_bytes.large_pool.allocated': 2858400072910848, 'active_bytes.large_pool.current': 29455661056, 'active_bytes.large_pool.freed': 2858370617249792, 'active_bytes.large_pool.peak': 42549753856, 'active_bytes.small_pool.allocated': 9044422050816, 'active_bytes.small_pool.current': 241173504, 'active_bytes.small_pool.freed': 9044180877312, 'active_bytes.small_pool.peak': 273691648, 'allocated_bytes.all.allocated': 2867444494961664, 'allocated_bytes.all.current': 29696834560, 'allocated_bytes.all.freed': 2867414798127104, 'allocated_bytes.all.peak': 42822380544, 'allocated_bytes.large_pool.allocated': 2858400072910848, 'allocated_bytes.large_pool.current': 29455661056, 'allocated_bytes.large_pool.freed': 2858370617249792, 'allocated_bytes.large_pool.peak': 42549753856, 'allocated_bytes.small_pool.allocated': 9044422050816, 'allocated_bytes.small_pool.current': 241173504, 'allocated_bytes.small_pool.freed': 9044180877312, 'allocated_bytes.small_pool.peak': 273691648, 'allocation.all.allocated': 187023642, 'allocation.all.current': 9404, 'allocation.all.freed': 187014238, 'allocation.all.peak': 10383, 'allocation.large_pool.allocated': 115142452, 'allocation.large_pool.current': 2202, 'allocation.large_pool.freed': 115140250, 'allocation.large_pool.peak': 2703, 'allocation.small_pool.allocated': 71881190, 'allocation.small_pool.current': 7202, 'allocation.small_pool.freed': 71873988, 'allocation.small_pool.peak': 7780, 'inactive_split.all.allocated': 83450461, 'inactive_split.all.current': 648, 'inactive_split.all.freed': 83449813, 'inactive_split.all.peak': 919, 'inactive_split.large_pool.allocated': 61356522, 'inactive_split.large_pool.current': 494, 'inactive_split.large_pool.freed': 61356028, 'inactive_split.large_pool.peak': 605, 'inactive_split.small_pool.allocated': 22093939, 'inactive_split.small_pool.current': 154, 'inactive_split.small_pool.freed': 22093785, 'inactive_split.small_pool.peak': 314, 'inactive_split_bytes.all.allocated': 1627440328704000, 'inactive_split_bytes.all.current': 680412160, 'inactive_split_bytes.all.freed': 1627439648291840, 'inactive_split_bytes.all.peak': 2546758144, 'inactive_split_bytes.large_pool.allocated': 1617333350380544, 'inactive_split_bytes.large_pool.current': 678316032, 'inactive_split_bytes.large_pool.freed': 1617332672064512, 'inactive_split_bytes.large_pool.peak': 2528481280, 'inactive_split_bytes.small_pool.allocated': 10106978323456, 'inactive_split_bytes.small_pool.current': 2096128, 'inactive_split_bytes.small_pool.freed': 10106976227328, 'inactive_split_bytes.small_pool.peak': 38276096, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 3070, 'num_device_free': 1735, 'num_ooms': 0, 'num_sync_all_streams': 22, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 2866788942456100, 'requested_bytes.all.current': 28935405576, 'requested_bytes.all.freed': 2866760007050524, 'requested_bytes.all.peak': 42060947524, 'requested_bytes.large_pool.allocated': 2857754494404080, 'requested_bytes.large_pool.current': 28694394880, 'requested_bytes.large_pool.freed': 2857725800009200, 'requested_bytes.large_pool.peak': 41788487680, 'requested_bytes.small_pool.allocated': 9034448052020, 'requested_bytes.small_pool.current': 241010696, 'requested_bytes.small_pool.freed': 9034207041324, 'requested_bytes.small_pool.peak': 273526836, 'reserved_bytes.all.allocated': 177345658880, 'reserved_bytes.all.current': 30377246720, 'reserved_bytes.all.freed': 146968412160, 'reserved_bytes.all.peak': 45069893632, 'reserved_bytes.large_pool.allocated': 176781524992, 'reserved_bytes.large_pool.current': 30133977088, 'reserved_bytes.large_pool.freed': 146647547904, 'reserved_bytes.large_pool.peak': 44795166720, 'reserved_bytes.small_pool.allocated': 564133888, 'reserved_bytes.small_pool.current': 243269632, 'reserved_bytes.small_pool.freed': 320864256, 'reserved_bytes.small_pool.peak': 274726912, 'segment.all.allocated': 3070, 'segment.all.current': 1335, 'segment.all.freed': 1735, 'segment.all.peak': 1508, 'segment.large_pool.allocated': 2801, 'segment.large_pool.current': 1219, 'segment.large_pool.freed': 1582, 'segment.large_pool.peak': 1377, 'segment.small_pool.allocated': 269, 'segment.small_pool.current': 116, 'segment.small_pool.freed': 153, 'segment.small_pool.peak': 131})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2845/2845 34:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.410185</td>\n",
       "      <td>0.949031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.174425</td>\n",
       "      <td>0.988496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.185568</td>\n",
       "      <td>0.991315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.117152</td>\n",
       "      <td>0.995759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.110293</td>\n",
       "      <td>0.996622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_protein_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering the exact data used for training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_dataset = pd.read_pickle('/home/kaustubh/RuBisCO_ML/ESM_LoRA/data/large_assay_dataset_wco2_wiptg_bimodal_activity_threshold.pkl')\n",
    "large_dataset = large_dataset[[\"LSU_id\", \"SSU_id\", \"lsu_seq\", \"ssu_seq\", \"activity_binary\"]]\n",
    "\n",
    "mutant_dataset = pd.read_pickle(\"/home/kaustubh/RuBisCO_ML/ESM_LoRA/data/form_III_IB_anc_variants_binary_activity_only_wrt_inactive_variant.pkl\")\n",
    "mutant_dataset.rename(columns={\"activity_binary_wrt_inactive_Anc\": \"activity_binary\"}, inplace=True)\n",
    "\n",
    "combined_dataset = pd.concat([large_dataset, mutant_dataset], ignore_index=True)\n",
    "combined_dataset = combined_dataset[combined_dataset['LSU_id'] != \"SUMO\"]\n",
    "combined_dataset = combined_dataset[combined_dataset['LSU_id'] != \"DEAD\"]\n",
    "combined_dataset['LSU_SSU_id'] = combined_dataset.apply(lambda x: x['LSU_id'] + \"-\" + x['SSU_id'] if pd.notna(x['SSU_id']) else x['LSU_id'] + \"-none\", axis=1)\n",
    "combined_dataset['LSU_SSU_seq'] = combined_dataset.apply(lambda x: x['lsu_seq'] + x['ssu_seq'] if pd.notna(x['ssu_seq']) else x['lsu_seq'], axis=1)\n",
    "\n",
    "sequences = combined_dataset['LSU_SSU_seq'].to_list()\n",
    "binary_activity = combined_dataset['activity_binary'].to_list()\n",
    "lsu_ssu_ids = combined_dataset['LSU_SSU_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, sequences, binary_activity, tokenizer, max_length=512):\n",
    "        self.sequences = sequences\n",
    "        self.binary_activity = binary_activity\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx][:self.max_length]\n",
    "        binding_site = self.binary_activity[idx]\n",
    "        encoding = self.tokenizer(sequence, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        encoding['labels'] = binding_site # + [-100] * (self.max_length - len(binding_site))  # Ignore extra padding tokens\n",
    "        return encoding\n",
    "\n",
    "dataset = ProteinDataset(sequences, binary_activity, tokenizer)\n",
    "train_size = int(0.85 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "train_dataset, val_dataset = accelerator.prepare(train_dataset, val_dataset)\n",
    "\n",
    "# Extract back the sequences and their binding sites info for the entries in the train_dataset & val_dataset\n",
    "train_sequences = [sequences[i] for i in train_dataset.indices]\n",
    "train_binary_activity = [binary_activity[i] for i in train_dataset.indices]\n",
    "\n",
    "val_sequences = [sequences[i] for i in val_dataset.indices]\n",
    "val_binary_activity = [binary_activity[i] for i in val_dataset.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2451, 433)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequences), len(val_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the finetuned model to the test set to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/kaustubh/RuBisCO_ML/ESM_LoRA/training_runs/esm2_t33_650M-finetuned-lora_2025-05-07_01-39-02\"\n",
    "base_model_path = \"facebook/esm2_t33_650M_UR50D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomModel(EsmPreTrainedModel):\n",
    "#     def __init__(self):\n",
    "#         super().__init__(EsmConfig.from_pretrained(\"facebook/esm2_t33_650M_UR50D\"))\n",
    "#         self.backbone = EsmModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "#         self.outputs = torch.nn.Linear(1280, 1)\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         input_ids,\n",
    "#         attention_mask=None,\n",
    "#         token_type_ids=None,\n",
    "#         position_ids=None,\n",
    "#         labels=None,\n",
    "#         inputs_embeds=None,\n",
    "#         output_attentions=False,\n",
    "#         output_hidden_states=False,\n",
    "#         return_dict=True\n",
    "#     ):\n",
    "#         outputs = self.backbone(\n",
    "#             input_ids,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "#             output_attentions=output_attentions,\n",
    "#             output_hidden_states=output_hidden_states,\n",
    "#             return_dict=return_dict\n",
    "#         )\n",
    "\n",
    "#         sequence_output = outputs.last_hidden_state # (B, L, 1280)\n",
    "#         bos_emb = sequence_output[:,0] # (B, L, 1280) -> (B, 1280)\n",
    "#         # outputs = [self.outputs[i](sequence_output) for i in range(5)]\n",
    "#         pred = self.outputs(bos_emb).squeeze(1) # (B,)\n",
    "\n",
    "#         # if labels, then we are training\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             assert pred.shape == labels.shape, f\"{pred}, {labels}\"\n",
    "#             loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "#             loss = loss_fn(pred, labels.float())\n",
    "#             # loss = sum(losses)/len(losses)\n",
    "\n",
    "#         return {\n",
    "#             \"loss\": loss,\n",
    "#             \"last_hidden_state\": sequence_output,\n",
    "#             \"logits\": pred\n",
    "#         }\n",
    "\n",
    "#     def get_embedding(\n",
    "#         self,\n",
    "#         input_ids,\n",
    "#         attention_mask=None,\n",
    "#         token_type_ids=None,\n",
    "#         position_ids=None,\n",
    "#         labels=None,\n",
    "#         inputs_embeds=None,\n",
    "#         output_attentions=False,\n",
    "#         output_hidden_states=False,\n",
    "#         return_dict=True\n",
    "#     ):\n",
    "#         outputs = self.backbone(\n",
    "#             input_ids,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "#             output_attentions=output_attentions,\n",
    "#             output_hidden_states=output_hidden_states,\n",
    "#             return_dict=return_dict\n",
    "#         )\n",
    "\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(EsmPreTrainedModel):\n",
    "    def __init__(self, model=None):\n",
    "        print(torch.cuda.memory_stats())\n",
    "        super().__init__(EsmConfig.from_pretrained(\"facebook/esm2_t33_650M_UR50D\"))\n",
    "        self.backbone = EsmModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "        self.outputs = torch.nn.Linear(1280, 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        labels=None,\n",
    "        inputs_embeds=None,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        return_dict=True\n",
    "    ):\n",
    "        outputs = self.backbone(\n",
    "            input_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs.last_hidden_state # (B, L, 1280)\n",
    "\n",
    "        ## Following for getting the BOS token embedding\n",
    "        # bos_emb = sequence_output[:,0] # (B, L, 1280) -> (B, 1280)\n",
    "        # # outputs = [self.outputs[i](sequence_output) for i in range(5)]\n",
    "        # outputs = self.outputs(bos_emb).squeeze(1) # (B,)\n",
    "\n",
    "        ## Following for getting the mean of the sequence embeddings\n",
    "        mask_sum = attention_mask.sum(dim=1, keepdim=True).float()\n",
    "        mean_emb = (sequence_output * attention_mask.unsqueeze(-1)).sum(dim=1) / mask_sum\n",
    "        outputs = self.outputs(mean_emb).squeeze(1) # (B,)\n",
    "\n",
    "        # if labels, then we are training\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            assert outputs.shape == labels.shape, f\"{outputs}, {labels}\"\n",
    "            loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            # loss = sum(losses)/len(losses)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"last_hidden_state\": sequence_output,\n",
    "            \"logits\": outputs\n",
    "        }\n",
    "\n",
    "    def get_embedding(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        labels=None,\n",
    "        inputs_embeds=None,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        return_dict=True\n",
    "    ):\n",
    "        outputs = self.backbone(\n",
    "            input_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict\n",
    "        )\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'active.all.allocated': 376097757, 'active.all.current': 2, 'active.all.freed': 376097755, 'active.all.peak': 12760, 'active.large_pool.allocated': 227432242, 'active.large_pool.current': 2, 'active.large_pool.freed': 227432240, 'active.large_pool.peak': 2903, 'active.small_pool.allocated': 148665515, 'active.small_pool.current': 0, 'active.small_pool.freed': 148665515, 'active.small_pool.peak': 10358, 'active_bytes.all.allocated': 6191673293955072, 'active_bytes.all.current': 17039360, 'active_bytes.all.freed': 6191673276915712, 'active_bytes.all.peak': 45727039488, 'active_bytes.large_pool.allocated': 6172497835046912, 'active_bytes.large_pool.current': 17039360, 'active_bytes.large_pool.freed': 6172497818007552, 'active_bytes.large_pool.peak': 45226637312, 'active_bytes.small_pool.allocated': 19175458908160, 'active_bytes.small_pool.current': 0, 'active_bytes.small_pool.freed': 19175458908160, 'active_bytes.small_pool.peak': 520622592, 'allocated_bytes.all.allocated': 6191673293955072, 'allocated_bytes.all.current': 17039360, 'allocated_bytes.all.freed': 6191673276915712, 'allocated_bytes.all.peak': 45727039488, 'allocated_bytes.large_pool.allocated': 6172497835046912, 'allocated_bytes.large_pool.current': 17039360, 'allocated_bytes.large_pool.freed': 6172497818007552, 'allocated_bytes.large_pool.peak': 45226637312, 'allocated_bytes.small_pool.allocated': 19175458908160, 'allocated_bytes.small_pool.current': 0, 'allocated_bytes.small_pool.freed': 19175458908160, 'allocated_bytes.small_pool.peak': 520622592, 'allocation.all.allocated': 376097757, 'allocation.all.current': 2, 'allocation.all.freed': 376097755, 'allocation.all.peak': 12760, 'allocation.large_pool.allocated': 227432242, 'allocation.large_pool.current': 2, 'allocation.large_pool.freed': 227432240, 'allocation.large_pool.peak': 2903, 'allocation.small_pool.allocated': 148665515, 'allocation.small_pool.current': 0, 'allocation.small_pool.freed': 148665515, 'allocation.small_pool.peak': 10358, 'inactive_split.all.allocated': 157869608, 'inactive_split.all.current': 3, 'inactive_split.all.freed': 157869605, 'inactive_split.all.peak': 1366, 'inactive_split.large_pool.allocated': 115597398, 'inactive_split.large_pool.current': 3, 'inactive_split.large_pool.freed': 115597395, 'inactive_split.large_pool.peak': 548, 'inactive_split.small_pool.allocated': 42272210, 'inactive_split.small_pool.current': 0, 'inactive_split.small_pool.freed': 42272210, 'inactive_split.small_pool.peak': 829, 'inactive_split_bytes.all.allocated': 3193432322286080, 'inactive_split_bytes.all.current': 14417920, 'inactive_split_bytes.all.freed': 3193432307868160, 'inactive_split_bytes.all.peak': 1966555136, 'inactive_split_bytes.large_pool.allocated': 3171732785141760, 'inactive_split_bytes.large_pool.current': 14417920, 'inactive_split_bytes.large_pool.freed': 3171732770723840, 'inactive_split_bytes.large_pool.peak': 1943029760, 'inactive_split_bytes.small_pool.allocated': 21699537144320, 'inactive_split_bytes.small_pool.current': 0, 'inactive_split_bytes.small_pool.freed': 21699537144320, 'inactive_split_bytes.small_pool.peak': 76681216, 'max_split_size': -1, 'num_alloc_retries': 1, 'num_device_alloc': 3585, 'num_device_free': 1866, 'num_ooms': 0, 'num_sync_all_streams': 24, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 6191644443238030, 'requested_bytes.all.current': 17039360, 'requested_bytes.all.freed': 6191644426198670, 'requested_bytes.all.peak': 44895740700, 'requested_bytes.large_pool.allocated': 6172492295168000, 'requested_bytes.large_pool.current': 17039360, 'requested_bytes.large_pool.freed': 6172492278128640, 'requested_bytes.large_pool.peak': 44395520000, 'requested_bytes.small_pool.allocated': 19152148070030, 'requested_bytes.small_pool.current': 0, 'requested_bytes.small_pool.freed': 19152148070030, 'requested_bytes.small_pool.peak': 520442640, 'reserved_bytes.all.allocated': 206470905856, 'reserved_bytes.all.current': 46724546560, 'reserved_bytes.all.freed': 159746359296, 'reserved_bytes.all.peak': 46724546560, 'reserved_bytes.large_pool.allocated': 205659308032, 'reserved_bytes.large_pool.current': 46181384192, 'reserved_bytes.large_pool.freed': 159477923840, 'reserved_bytes.large_pool.peak': 46181384192, 'reserved_bytes.small_pool.allocated': 811597824, 'reserved_bytes.small_pool.current': 543162368, 'reserved_bytes.small_pool.freed': 268435456, 'reserved_bytes.small_pool.peak': 543162368, 'segment.all.allocated': 3585, 'segment.all.current': 1719, 'segment.all.freed': 1866, 'segment.all.peak': 1747, 'segment.large_pool.allocated': 3198, 'segment.large_pool.current': 1460, 'segment.large_pool.freed': 1738, 'segment.large_pool.peak': 1488, 'segment.small_pool.allocated': 387, 'segment.small_pool.current': 259, 'segment.small_pool.freed': 128, 'segment.small_pool.peak': 259})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForTokenClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): CustomModel(\n",
       "      (backbone): EsmModel(\n",
       "        (embeddings): EsmEmbeddings(\n",
       "          (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "        )\n",
       "        (encoder): EsmEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-32): 33 x EsmLayer(\n",
       "              (attention): EsmAttention(\n",
       "                (self): EsmSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (rotary_embeddings): RotaryEmbedding()\n",
       "                )\n",
       "                (output): EsmSelfOutput(\n",
       "                  (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (intermediate): EsmIntermediate(\n",
       "                (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (output): EsmOutput(\n",
       "                (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pooler): EsmPooler(\n",
       "          (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "        (contact_head): EsmContactPredictionHead(\n",
       "          (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (outputs): Linear(in_features=1280, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = CustomModel()\n",
    "loaded_model = PeftModel.from_pretrained(base_model, model_path).to(torch.device(\"cuda:0\"))\n",
    "loaded_model.eval()\n",
    "# Load base_model_path to base_model\n",
    "# base_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "formIII_mutants = combined_dataset.query('LSU_id.str.startswith(\"Anc3\")')\n",
    "formIII_seqs = formIII_mutants['LSU_SSU_seq'].to_list()\n",
    "formIII_labels = formIII_mutants['activity_binary'].to_list()\n",
    "formIII_ids = formIII_mutants['LSU_SSU_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_formIII = []\n",
    "output_emb_formIII = []\n",
    "\n",
    "for i in range(len(formIII_seqs)):\n",
    "    inputs = loaded_tokenizer(formIII_seqs[i], truncation=True, padding='max_length', max_length=1024, return_tensors=\"pt\")\n",
    "    labels = [formIII_labels[i]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"].squeeze(0)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        # Sigmoid activation\n",
    "        outputs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        output_pred_formIII.append(outputs)\n",
    "        # print(outputs, labels)\n",
    "        outputs_emb = loaded_model(**inputs)[\"last_hidden_state\"].squeeze(0)[0]\n",
    "        outputs_emb = outputs_emb.cpu().numpy()\n",
    "\n",
    "        output_emb_formIII.append(outputs_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anc367_mutant_7-none 0.39452004 0\n",
      "Anc367_mutant_10-none 0.39413607 0\n",
      "Anc367_mutant_15-none 0.5660141 1\n",
      "Anc367_mutant_17-none 0.39281946 0\n",
      "Anc367_mutant_20-none 0.39457932 1\n",
      "Anc367_mutant_26-none 0.43341178 1\n",
      "Anc367_mutant_29-none 0.3943195 0\n",
      "Anc367_mutant_38-none 0.3946639 1\n",
      "Anc367_mutant_39-none 0.39664474 0\n",
      "Anc367_mutant_42-none 0.39815158 0\n",
      "Anc366-none 0.5675697 1\n",
      "Anc367-none 0.39563125 0\n",
      "Anc393_mutant_4-none 0.5494187 1\n",
      "Anc393_mutant_11-none 0.55009073 1\n",
      "Anc393_mutant_12-none 0.54990363 1\n",
      "Anc393_mutant_13-none 0.547416 0\n",
      "Anc393_mutant_14-none 0.551925 1\n",
      "Anc393_mutant_15-none 0.54683113 1\n",
      "Anc393_mutant_16-none 0.5454568 1\n",
      "Anc393_mutant_18-none 0.55009997 1\n",
      "Anc393_mutant_19-none 0.5475726 1\n",
      "Anc393_mutant_21-none 0.5477891 0\n",
      "Anc393_mutant_22-none 0.54851604 1\n",
      "Anc393_mutant_25-none 0.55237514 0\n",
      "Anc393_mutant_27-none 0.55394256 1\n",
      "Anc393_mutant_28-none 0.55300885 1\n",
      "Anc393_mutant_29-none 0.5450992 1\n",
      "Anc393_mutant_30-none 0.5522993 1\n",
      "Anc393_mutant_31-none 0.54972893 0\n",
      "Anc393_mutant_32-none 0.5499214 1\n",
      "Anc393_mutant_33-none 0.5506281 1\n",
      "Anc393_mutant_35-none 0.5458271 1\n",
      "Anc393_mutant_36-none 0.550998 0\n",
      "Anc393_mutant_38-none 0.5447293 1\n",
      "Anc393_mutant_41-none 0.5422887 1\n",
      "Anc393_mutant_42-none 0.55179524 1\n",
      "Anc393_mutant_43-none 0.55121505 1\n",
      "Anc393_mutant_46-none 0.55420226 1\n",
      "Anc393_mutant_47-none 0.54722315 1\n",
      "Anc393_mutant_49-none 0.5504571 1\n",
      "Anc365-none 0.5648255 1\n",
      "Anc393-none 0.5330075 0\n",
      "Anc367_mutant_0-none 0.40332586 0\n",
      "Anc367_mutant_1-none 0.5723642 1\n",
      "Anc367_mutant_2-none 0.39505202 0\n",
      "Anc367_mutant_3-none 0.39458796 0\n",
      "Anc367_mutant_4-none 0.39434353 0\n",
      "Anc367_mutant_5-none 0.54101586 1\n",
      "Anc367_mutant_6-none 0.39392382 0\n",
      "Anc367_mutant_8-none 0.39437854 0\n",
      "Anc367_mutant_9-none 0.39523163 1\n",
      "Anc367_mutant_11-none 0.39459655 1\n",
      "Anc367_mutant_12-none 0.39350465 0\n",
      "Anc367_mutant_13-none 0.39368075 1\n",
      "Anc367_mutant_14-none 0.39552772 0\n",
      "Anc367_mutant_16-none 0.39445212 1\n",
      "Anc367_mutant_18-none 0.39363936 1\n",
      "Anc367_mutant_19-none 0.5047309 0\n",
      "Anc367_mutant_21-none 0.3972884 0\n",
      "Anc367_mutant_22-none 0.3936747 0\n",
      "Anc367_mutant_23-none 0.39836788 0\n",
      "Anc367_mutant_24-none 0.3929273 0\n",
      "Anc367_mutant_25-none 0.5171405 1\n",
      "Anc367_mutant_27-none 0.42305666 1\n",
      "Anc367_mutant_28-none 0.39599586 0\n",
      "Anc367_mutant_30-none 0.3948435 1\n",
      "Anc367_mutant_31-none 0.39417106 0\n",
      "Anc367_mutant_32-none 0.39280534 0\n",
      "Anc367_mutant_33-none 0.39585793 0\n",
      "Anc367_mutant_34-none 0.5006044 1\n",
      "Anc367_mutant_35-none 0.39229006 0\n",
      "Anc367_mutant_36-none 0.39517808 0\n",
      "Anc367_mutant_37-none 0.39508668 0\n",
      "Anc367_mutant_40-none 0.500123 1\n",
      "Anc367_mutant_41-none 0.39392725 0\n",
      "Anc367_mutant_43-none 0.39448202 0\n",
      "Anc367_mutant_44-none 0.39500126 0\n",
      "Anc367_mutant_45-none 0.39652467 0\n",
      "Anc367_mutant_46-none 0.39938065 1\n",
      "Anc367_mutant_47-none 0.3930629 0\n",
      "Anc367_mutant_48-none 0.39398363 1\n",
      "Anc367_mutant_49-none 0.39440832 0\n",
      "Anc393_mutant_0-none 0.5509912 0\n",
      "Anc393_mutant_1-none 0.5454468 0\n",
      "Anc393_mutant_2-none 0.5531871 1\n",
      "Anc393_mutant_3-none 0.55219144 0\n",
      "Anc393_mutant_5-none 0.5522976 1\n",
      "Anc393_mutant_6-none 0.548946 0\n",
      "Anc393_mutant_7-none 0.54593784 1\n",
      "Anc393_mutant_8-none 0.5449565 0\n",
      "Anc393_mutant_9-none 0.54834914 0\n",
      "Anc393_mutant_10-none 0.55379885 0\n",
      "Anc393_mutant_17-none 0.5545241 1\n",
      "Anc393_mutant_20-none 0.5512623 1\n",
      "Anc393_mutant_23-none 0.5495259 1\n",
      "Anc393_mutant_24-none 0.5442112 0\n",
      "Anc393_mutant_26-none 0.54710597 1\n",
      "Anc393_mutant_34-none 0.549105 0\n",
      "Anc393_mutant_37-none 0.5532475 1\n",
      "Anc393_mutant_39-none 0.55024165 1\n",
      "Anc393_mutant_40-none 0.54661417 1\n",
      "Anc393_mutant_44-none 0.55030185 1\n",
      "Anc393_mutant_45-none 0.5441049 1\n",
      "Anc393_mutant_48-none 0.5521941 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_pred_formIII)):\n",
    "    print(formIII_ids[i], output_pred_formIII[i], formIII_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "# import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distance_matrix = pairwise_distances(output_emb_formIII, metric=\"cosine\")\n",
    "tsne = TSNE(n_components=2, metric=\"precomputed\", init=\"random\", random_state=42)\n",
    "tsne_embedding = tsne.fit_transform(distance_matrix)\n",
    "# umap_model = umap.UMAP(n_neighbors=5, min_dist=0.3, metric=\"cosine\")\n",
    "# tsne_embedding = umap_model.fit_transform(output_emb)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(tsne_embedding[:, 0], tsne_embedding[:, 1], c=output_pred_formIII, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred = []\n",
    "\n",
    "for i in range(len(val_sequences)):\n",
    "    inputs = loaded_tokenizer(train_sequences[i], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {key: inputs[key] for key in inputs}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"]\n",
    "\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred = []\n",
    "\n",
    "for i in range(len(train_sequences)):\n",
    "    inputs = loaded_tokenizer(train_sequences[i], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    labels = [train_binary_activity[i]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"].squeeze(0)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        # Sigmoid activation\n",
    "        outputs = 1 / (1 + np.exp(-outputs))\n",
    "        # print(outputs, labels)\n",
    "\n",
    "        output_pred.append(outputs)\n",
    "\n",
    "#Plot the values in output_pred with the labels from val_set_labels\n",
    "\n",
    "output_pred = np.array(output_pred)\n",
    "# val_set_labels = np.array(val_set_labels)\n",
    "\n",
    "plt.scatter(output_pred, train_binary_activity)\n",
    "plt.title(\"Predictions vs Labels for the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predictions vs Labels for the validation set')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_pred = []\n",
    "\n",
    "for i in range(len(val_sequences)):\n",
    "    inputs = loaded_tokenizer(val_sequences[i], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    labels = [val_binary_activity[i]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"].squeeze(0)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        # Sigmoid activation\n",
    "        outputs = 1 / (1 + np.exp(-outputs))\n",
    "        # print(outputs, labels)\n",
    "\n",
    "        output_pred.append(outputs)\n",
    "\n",
    "#Plot the values in output_pred with the labels from val_set_labels\n",
    "\n",
    "output_pred = np.array(output_pred)\n",
    "# val_set_labels = np.array(val_set_labels)\n",
    "\n",
    "plt.scatter(output_pred, val_binary_activity)\n",
    "plt.title(\"Predictions vs Labels for the validation set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: ðŸš€ View run \u001b[33m/home/kaustubh/RuBisCO_ML/ESM_LoRA/training_runs/esm2_t33_650M-finetuned-lora_2025-04-15_06-58-30\u001b[0m at: \u001b[34mhttps://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface/runs/hbgguq7j\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250415_070136-hbgguq7j/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "combined_seqs = train_sequences + val_sequences\n",
    "combined_labels = train_binary_activity + val_binary_activity\n",
    "\n",
    "output_pred_all = []\n",
    "output_emb_all = []\n",
    "\n",
    "for i in range(len(combined_seqs)):\n",
    "    inputs = loaded_tokenizer(combined_seqs[i], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    labels = [combined_labels[i]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"].squeeze(0)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        # Sigmoid activation\n",
    "        outputs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        output_pred_all.append(outputs)\n",
    "        # print(outputs, labels)\n",
    "        outputs_emb = loaded_model(**inputs)[\"last_hidden_state\"].squeeze(0)[0]\n",
    "        outputs_emb = outputs_emb.cpu().numpy()\n",
    "\n",
    "        output_emb_all.append(outputs_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the values in output_pred with the labels from val_set_labels\n",
    "\n",
    "output_pred_all = np.array(output_pred_all)\n",
    "combined_labels = np.array(combined_labels)\n",
    "\n",
    "plt.scatter(output_pred_all, combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "# import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distance_matrix = pairwise_distances(output_emb_all, metric=\"cosine\")\n",
    "tsne = TSNE(n_components=2, metric=\"precomputed\", init=\"random\", random_state=42)\n",
    "tsne_embedding = tsne.fit_transform(distance_matrix)\n",
    "# umap_model = umap.UMAP(n_neighbors=5, min_dist=0.3, metric=\"cosine\")\n",
    "# tsne_embedding = umap_model.fit_transform(output_emb)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(tsne_embedding[:, 0], tsne_embedding[:, 1], c=combined_labels, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
