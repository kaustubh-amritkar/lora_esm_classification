{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/RuBisCO_ML/ESM_LoRA/analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "%cd /home/kaustubh/RuBisCO_ML/ESM_LoRA/analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lora_esm2_script_updated import *\n",
    "# from lora_esm2_script_updated import CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "NVIDIA L40S\n",
      "OrderedDict({'active.all.allocated': 0, 'active.all.current': 0, 'active.all.freed': 0, 'active.all.peak': 0, 'active.large_pool.allocated': 0, 'active.large_pool.current': 0, 'active.large_pool.freed': 0, 'active.large_pool.peak': 0, 'active.small_pool.allocated': 0, 'active.small_pool.current': 0, 'active.small_pool.freed': 0, 'active.small_pool.peak': 0, 'active_bytes.all.allocated': 0, 'active_bytes.all.current': 0, 'active_bytes.all.freed': 0, 'active_bytes.all.peak': 0, 'active_bytes.large_pool.allocated': 0, 'active_bytes.large_pool.current': 0, 'active_bytes.large_pool.freed': 0, 'active_bytes.large_pool.peak': 0, 'active_bytes.small_pool.allocated': 0, 'active_bytes.small_pool.current': 0, 'active_bytes.small_pool.freed': 0, 'active_bytes.small_pool.peak': 0, 'allocated_bytes.all.allocated': 0, 'allocated_bytes.all.current': 0, 'allocated_bytes.all.freed': 0, 'allocated_bytes.all.peak': 0, 'allocated_bytes.large_pool.allocated': 0, 'allocated_bytes.large_pool.current': 0, 'allocated_bytes.large_pool.freed': 0, 'allocated_bytes.large_pool.peak': 0, 'allocated_bytes.small_pool.allocated': 0, 'allocated_bytes.small_pool.current': 0, 'allocated_bytes.small_pool.freed': 0, 'allocated_bytes.small_pool.peak': 0, 'allocation.all.allocated': 0, 'allocation.all.current': 0, 'allocation.all.freed': 0, 'allocation.all.peak': 0, 'allocation.large_pool.allocated': 0, 'allocation.large_pool.current': 0, 'allocation.large_pool.freed': 0, 'allocation.large_pool.peak': 0, 'allocation.small_pool.allocated': 0, 'allocation.small_pool.current': 0, 'allocation.small_pool.freed': 0, 'allocation.small_pool.peak': 0, 'inactive_split.all.allocated': 0, 'inactive_split.all.current': 0, 'inactive_split.all.freed': 0, 'inactive_split.all.peak': 0, 'inactive_split.large_pool.allocated': 0, 'inactive_split.large_pool.current': 0, 'inactive_split.large_pool.freed': 0, 'inactive_split.large_pool.peak': 0, 'inactive_split.small_pool.allocated': 0, 'inactive_split.small_pool.current': 0, 'inactive_split.small_pool.freed': 0, 'inactive_split.small_pool.peak': 0, 'inactive_split_bytes.all.allocated': 0, 'inactive_split_bytes.all.current': 0, 'inactive_split_bytes.all.freed': 0, 'inactive_split_bytes.all.peak': 0, 'inactive_split_bytes.large_pool.allocated': 0, 'inactive_split_bytes.large_pool.current': 0, 'inactive_split_bytes.large_pool.freed': 0, 'inactive_split_bytes.large_pool.peak': 0, 'inactive_split_bytes.small_pool.allocated': 0, 'inactive_split_bytes.small_pool.current': 0, 'inactive_split_bytes.small_pool.freed': 0, 'inactive_split_bytes.small_pool.peak': 0, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 0, 'num_device_free': 0, 'num_ooms': 0, 'num_sync_all_streams': 0, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 0, 'requested_bytes.all.current': 0, 'requested_bytes.all.freed': 0, 'requested_bytes.all.peak': 0, 'requested_bytes.large_pool.allocated': 0, 'requested_bytes.large_pool.current': 0, 'requested_bytes.large_pool.freed': 0, 'requested_bytes.large_pool.peak': 0, 'requested_bytes.small_pool.allocated': 0, 'requested_bytes.small_pool.current': 0, 'requested_bytes.small_pool.freed': 0, 'requested_bytes.small_pool.peak': 0, 'reserved_bytes.all.allocated': 0, 'reserved_bytes.all.current': 0, 'reserved_bytes.all.freed': 0, 'reserved_bytes.all.peak': 0, 'reserved_bytes.large_pool.allocated': 0, 'reserved_bytes.large_pool.current': 0, 'reserved_bytes.large_pool.freed': 0, 'reserved_bytes.large_pool.peak': 0, 'reserved_bytes.small_pool.allocated': 0, 'reserved_bytes.small_pool.current': 0, 'reserved_bytes.small_pool.freed': 0, 'reserved_bytes.small_pool.peak': 0, 'segment.all.allocated': 0, 'segment.all.current': 0, 'segment.all.freed': 0, 'segment.all.peak': 0, 'segment.large_pool.allocated': 0, 'segment.large_pool.current': 0, 'segment.large_pool.freed': 0, 'segment.large_pool.peak': 0, 'segment.small_pool.allocated': 0, 'segment.small_pool.current': 0, 'segment.small_pool.freed': 0, 'segment.small_pool.peak': 0})\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.memory_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'active.all.allocated': 0, 'active.all.current': 0, 'active.all.freed': 0, 'active.all.peak': 0, 'active.large_pool.allocated': 0, 'active.large_pool.current': 0, 'active.large_pool.freed': 0, 'active.large_pool.peak': 0, 'active.small_pool.allocated': 0, 'active.small_pool.current': 0, 'active.small_pool.freed': 0, 'active.small_pool.peak': 0, 'active_bytes.all.allocated': 0, 'active_bytes.all.current': 0, 'active_bytes.all.freed': 0, 'active_bytes.all.peak': 0, 'active_bytes.large_pool.allocated': 0, 'active_bytes.large_pool.current': 0, 'active_bytes.large_pool.freed': 0, 'active_bytes.large_pool.peak': 0, 'active_bytes.small_pool.allocated': 0, 'active_bytes.small_pool.current': 0, 'active_bytes.small_pool.freed': 0, 'active_bytes.small_pool.peak': 0, 'allocated_bytes.all.allocated': 0, 'allocated_bytes.all.current': 0, 'allocated_bytes.all.freed': 0, 'allocated_bytes.all.peak': 0, 'allocated_bytes.large_pool.allocated': 0, 'allocated_bytes.large_pool.current': 0, 'allocated_bytes.large_pool.freed': 0, 'allocated_bytes.large_pool.peak': 0, 'allocated_bytes.small_pool.allocated': 0, 'allocated_bytes.small_pool.current': 0, 'allocated_bytes.small_pool.freed': 0, 'allocated_bytes.small_pool.peak': 0, 'allocation.all.allocated': 0, 'allocation.all.current': 0, 'allocation.all.freed': 0, 'allocation.all.peak': 0, 'allocation.large_pool.allocated': 0, 'allocation.large_pool.current': 0, 'allocation.large_pool.freed': 0, 'allocation.large_pool.peak': 0, 'allocation.small_pool.allocated': 0, 'allocation.small_pool.current': 0, 'allocation.small_pool.freed': 0, 'allocation.small_pool.peak': 0, 'inactive_split.all.allocated': 0, 'inactive_split.all.current': 0, 'inactive_split.all.freed': 0, 'inactive_split.all.peak': 0, 'inactive_split.large_pool.allocated': 0, 'inactive_split.large_pool.current': 0, 'inactive_split.large_pool.freed': 0, 'inactive_split.large_pool.peak': 0, 'inactive_split.small_pool.allocated': 0, 'inactive_split.small_pool.current': 0, 'inactive_split.small_pool.freed': 0, 'inactive_split.small_pool.peak': 0, 'inactive_split_bytes.all.allocated': 0, 'inactive_split_bytes.all.current': 0, 'inactive_split_bytes.all.freed': 0, 'inactive_split_bytes.all.peak': 0, 'inactive_split_bytes.large_pool.allocated': 0, 'inactive_split_bytes.large_pool.current': 0, 'inactive_split_bytes.large_pool.freed': 0, 'inactive_split_bytes.large_pool.peak': 0, 'inactive_split_bytes.small_pool.allocated': 0, 'inactive_split_bytes.small_pool.current': 0, 'inactive_split_bytes.small_pool.freed': 0, 'inactive_split_bytes.small_pool.peak': 0, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 0, 'num_device_free': 0, 'num_ooms': 0, 'num_sync_all_streams': 1, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 0, 'requested_bytes.all.current': 0, 'requested_bytes.all.freed': 0, 'requested_bytes.all.peak': 0, 'requested_bytes.large_pool.allocated': 0, 'requested_bytes.large_pool.current': 0, 'requested_bytes.large_pool.freed': 0, 'requested_bytes.large_pool.peak': 0, 'requested_bytes.small_pool.allocated': 0, 'requested_bytes.small_pool.current': 0, 'requested_bytes.small_pool.freed': 0, 'requested_bytes.small_pool.peak': 0, 'reserved_bytes.all.allocated': 0, 'reserved_bytes.all.current': 0, 'reserved_bytes.all.freed': 0, 'reserved_bytes.all.peak': 0, 'reserved_bytes.large_pool.allocated': 0, 'reserved_bytes.large_pool.current': 0, 'reserved_bytes.large_pool.freed': 0, 'reserved_bytes.large_pool.peak': 0, 'reserved_bytes.small_pool.allocated': 0, 'reserved_bytes.small_pool.current': 0, 'reserved_bytes.small_pool.freed': 0, 'reserved_bytes.small_pool.peak': 0, 'segment.all.allocated': 0, 'segment.all.current': 0, 'segment.all.freed': 0, 'segment.all.peak': 0, 'segment.large_pool.allocated': 0, 'segment.large_pool.current': 0, 'segment.large_pool.freed': 0, 'segment.large_pool.peak': 0, 'segment.small_pool.allocated': 0, 'segment.small_pool.current': 0, 'segment.small_pool.freed': 0, 'segment.small_pool.peak': 0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['method', 'metric', 'parameters'])\n",
      "Trial 1/10\n",
      "learning_rate:  1e-05\n",
      "OrderedDict({'active.all.allocated': 770, 'active.all.current': 770, 'active.all.freed': 0, 'active.all.peak': 770, 'active.large_pool.allocated': 200, 'active.large_pool.current': 200, 'active.large_pool.freed': 0, 'active.large_pool.peak': 200, 'active.small_pool.allocated': 570, 'active.small_pool.current': 570, 'active.small_pool.freed': 0, 'active.small_pool.peak': 570, 'active_bytes.all.allocated': 2694874112, 'active_bytes.all.current': 2694874112, 'active_bytes.all.freed': 0, 'active_bytes.all.peak': 2694874112, 'active_bytes.large_pool.allocated': 2676238336, 'active_bytes.large_pool.current': 2676238336, 'active_bytes.large_pool.freed': 0, 'active_bytes.large_pool.peak': 2676238336, 'active_bytes.small_pool.allocated': 18635776, 'active_bytes.small_pool.current': 18635776, 'active_bytes.small_pool.freed': 0, 'active_bytes.small_pool.peak': 18635776, 'allocated_bytes.all.allocated': 2694874112, 'allocated_bytes.all.current': 2694874112, 'allocated_bytes.all.freed': 0, 'allocated_bytes.all.peak': 2694874112, 'allocated_bytes.large_pool.allocated': 2676238336, 'allocated_bytes.large_pool.current': 2676238336, 'allocated_bytes.large_pool.freed': 0, 'allocated_bytes.large_pool.peak': 2676238336, 'allocated_bytes.small_pool.allocated': 18635776, 'allocated_bytes.small_pool.current': 18635776, 'allocated_bytes.small_pool.freed': 0, 'allocated_bytes.small_pool.peak': 18635776, 'allocation.all.allocated': 770, 'allocation.all.current': 770, 'allocation.all.freed': 0, 'allocation.all.peak': 770, 'allocation.large_pool.allocated': 200, 'allocation.large_pool.current': 200, 'allocation.large_pool.freed': 0, 'allocation.large_pool.peak': 200, 'allocation.small_pool.allocated': 570, 'allocation.small_pool.current': 570, 'allocation.small_pool.freed': 0, 'allocation.small_pool.peak': 570, 'inactive_split.all.allocated': 54, 'inactive_split.all.current': 48, 'inactive_split.all.freed': 6, 'inactive_split.all.peak': 49, 'inactive_split.large_pool.allocated': 45, 'inactive_split.large_pool.current': 45, 'inactive_split.large_pool.freed': 0, 'inactive_split.large_pool.peak': 45, 'inactive_split.small_pool.allocated': 9, 'inactive_split.small_pool.current': 3, 'inactive_split.small_pool.freed': 6, 'inactive_split.small_pool.peak': 5, 'inactive_split_bytes.all.allocated': 668279808, 'inactive_split_bytes.all.current': 67075072, 'inactive_split_bytes.all.freed': 601204736, 'inactive_split_bytes.all.peak': 73704448, 'inactive_split_bytes.large_pool.allocated': 650106880, 'inactive_split_bytes.large_pool.current': 66836480, 'inactive_split_bytes.large_pool.freed': 583270400, 'inactive_split_bytes.large_pool.peak': 73390080, 'inactive_split_bytes.small_pool.allocated': 18172928, 'inactive_split_bytes.small_pool.current': 238592, 'inactive_split_bytes.small_pool.freed': 17934336, 'inactive_split_bytes.small_pool.peak': 2094592, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 120, 'num_device_free': 0, 'num_ooms': 0, 'num_sync_all_streams': 2, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 2625653480, 'requested_bytes.all.current': 2625653480, 'requested_bytes.all.freed': 0, 'requested_bytes.all.peak': 2625653480, 'requested_bytes.large_pool.allocated': 2607032320, 'requested_bytes.large_pool.current': 2607032320, 'requested_bytes.large_pool.freed': 0, 'requested_bytes.large_pool.peak': 2607032320, 'requested_bytes.small_pool.allocated': 18621160, 'requested_bytes.small_pool.current': 18621160, 'requested_bytes.small_pool.freed': 0, 'requested_bytes.small_pool.peak': 18621160, 'reserved_bytes.all.allocated': 2761949184, 'reserved_bytes.all.current': 2761949184, 'reserved_bytes.all.freed': 0, 'reserved_bytes.all.peak': 2761949184, 'reserved_bytes.large_pool.allocated': 2743074816, 'reserved_bytes.large_pool.current': 2743074816, 'reserved_bytes.large_pool.freed': 0, 'reserved_bytes.large_pool.peak': 2743074816, 'reserved_bytes.small_pool.allocated': 18874368, 'reserved_bytes.small_pool.current': 18874368, 'reserved_bytes.small_pool.freed': 0, 'reserved_bytes.small_pool.peak': 18874368, 'segment.all.allocated': 120, 'segment.all.current': 120, 'segment.all.freed': 0, 'segment.all.peak': 120, 'segment.large_pool.allocated': 111, 'segment.large_pool.current': 111, 'segment.large_pool.freed': 0, 'segment.large_pool.peak': 111, 'segment.small_pool.allocated': 9, 'segment.small_pool.current': 9, 'segment.small_pool.freed': 0, 'segment.small_pool.peak': 9})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkauamritkar\u001b[0m (\u001b[33mkauamritkar-university-of-wisconsin-madison\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kaustubh/RuBisCO_ML/ESM_LoRA/analysis/wandb/run-20250509_035621-0i3h9wws</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface/runs/0i3h9wws' target=\"_blank\">/home/kaustubh/RuBisCO_ML/ESM_LoRA/training_runs/esm2_t33_650M-finetuned-lora_2025-05-09_03-56-15</a></strong> to <a href='https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface' target=\"_blank\">https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface/runs/0i3h9wws' target=\"_blank\">https://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface/runs/0i3h9wws</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.695929</td>\n",
       "      <td>0.687177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.646700</td>\n",
       "      <td>0.687405</td>\n",
       "      <td>0.684483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.682806</td>\n",
       "      <td>0.733435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.628100</td>\n",
       "      <td>0.667353</td>\n",
       "      <td>0.751272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.564400</td>\n",
       "      <td>0.667686</td>\n",
       "      <td>0.757993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.7579931972789116\n",
      "Updating best trial\n",
      "Trial 2/10\n",
      "learning_rate:  0.00010899999999999999\n",
      "OrderedDict({'active.all.allocated': 8831523, 'active.all.current': 2474, 'active.all.freed': 8829049, 'active.all.peak': 3453, 'active.large_pool.allocated': 5440962, 'active.large_pool.current': 402, 'active.large_pool.freed': 5440560, 'active.large_pool.peak': 903, 'active.small_pool.allocated': 3390561, 'active.small_pool.current': 2072, 'active.small_pool.freed': 3388489, 'active.small_pool.peak': 2650, 'active_bytes.all.allocated': 138450370509312, 'active_bytes.all.current': 5442967552, 'active_bytes.all.freed': 138444927541760, 'active_bytes.all.peak': 18568579072, 'active_bytes.large_pool.allocated': 138018572360704, 'active_bytes.large_pool.current': 5369516032, 'active_bytes.large_pool.freed': 138013202844672, 'active_bytes.large_pool.peak': 18463608832, 'active_bytes.small_pool.allocated': 431798148608, 'active_bytes.small_pool.current': 73451520, 'active_bytes.small_pool.freed': 431724697088, 'active_bytes.small_pool.peak': 106035200, 'allocated_bytes.all.allocated': 138450370509312, 'allocated_bytes.all.current': 5442967552, 'allocated_bytes.all.freed': 138444927541760, 'allocated_bytes.all.peak': 18568579072, 'allocated_bytes.large_pool.allocated': 138018572360704, 'allocated_bytes.large_pool.current': 5369516032, 'allocated_bytes.large_pool.freed': 138013202844672, 'allocated_bytes.large_pool.peak': 18463608832, 'allocated_bytes.small_pool.allocated': 431798148608, 'allocated_bytes.small_pool.current': 73451520, 'allocated_bytes.small_pool.freed': 431724697088, 'allocated_bytes.small_pool.peak': 106035200, 'allocation.all.allocated': 8831523, 'allocation.all.current': 2474, 'allocation.all.freed': 8829049, 'allocation.all.peak': 3453, 'allocation.large_pool.allocated': 5440962, 'allocation.large_pool.current': 402, 'allocation.large_pool.freed': 5440560, 'allocation.large_pool.peak': 903, 'allocation.small_pool.allocated': 3390561, 'allocation.small_pool.current': 2072, 'allocation.small_pool.freed': 3388489, 'allocation.small_pool.peak': 2650, 'inactive_split.all.allocated': 3829112, 'inactive_split.all.current': 134, 'inactive_split.all.freed': 3828978, 'inactive_split.all.peak': 407, 'inactive_split.large_pool.allocated': 2847413, 'inactive_split.large_pool.current': 93, 'inactive_split.large_pool.freed': 2847320, 'inactive_split.large_pool.peak': 203, 'inactive_split.small_pool.allocated': 981699, 'inactive_split.small_pool.current': 41, 'inactive_split.small_pool.freed': 981658, 'inactive_split.small_pool.peak': 206, 'inactive_split_bytes.all.allocated': 78278927247872, 'inactive_split_bytes.all.current': 162719744, 'inactive_split_bytes.all.freed': 78278764528128, 'inactive_split_bytes.all.peak': 2029373440, 'inactive_split_bytes.large_pool.allocated': 77794875237376, 'inactive_split_bytes.large_pool.current': 160673792, 'inactive_split_bytes.large_pool.freed': 77794714563584, 'inactive_split_bytes.large_pool.peak': 2017576960, 'inactive_split_bytes.small_pool.allocated': 484052010496, 'inactive_split_bytes.small_pool.current': 2045952, 'inactive_split_bytes.small_pool.freed': 484049964544, 'inactive_split_bytes.small_pool.peak': 20984832, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 432, 'num_device_free': 172, 'num_ooms': 0, 'num_sync_all_streams': 4, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 138393862077852, 'requested_bytes.all.current': 5304524256, 'requested_bytes.all.freed': 138388557553596, 'requested_bytes.all.peak': 18430131772, 'requested_bytes.large_pool.allocated': 137962532071920, 'requested_bytes.large_pool.current': 5231104000, 'requested_bytes.large_pool.freed': 137957300967920, 'requested_bytes.large_pool.peak': 18325196800, 'requested_bytes.small_pool.allocated': 431330005932, 'requested_bytes.small_pool.current': 73420256, 'requested_bytes.small_pool.freed': 431256585676, 'requested_bytes.small_pool.peak': 106001964, 'reserved_bytes.all.allocated': 20264779776, 'reserved_bytes.all.current': 5605687296, 'reserved_bytes.all.freed': 14659092480, 'reserved_bytes.all.peak': 20264779776, 'reserved_bytes.large_pool.allocated': 20157825024, 'reserved_bytes.large_pool.current': 5530189824, 'reserved_bytes.large_pool.freed': 14627635200, 'reserved_bytes.large_pool.peak': 20157825024, 'reserved_bytes.small_pool.allocated': 106954752, 'reserved_bytes.small_pool.current': 75497472, 'reserved_bytes.small_pool.freed': 31457280, 'reserved_bytes.small_pool.peak': 106954752, 'segment.all.allocated': 432, 'segment.all.current': 260, 'segment.all.freed': 172, 'segment.all.peak': 432, 'segment.large_pool.allocated': 381, 'segment.large_pool.current': 224, 'segment.large_pool.freed': 157, 'segment.large_pool.peak': 381, 'segment.small_pool.allocated': 51, 'segment.small_pool.current': 36, 'segment.small_pool.freed': 15, 'segment.small_pool.peak': 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.629130</td>\n",
       "      <td>0.819939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.396332</td>\n",
       "      <td>0.879694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.346002</td>\n",
       "      <td>0.888769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.349431</td>\n",
       "      <td>0.868565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.228900</td>\n",
       "      <td>0.351629</td>\n",
       "      <td>0.867830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.8887687074829932\n",
      "Best trial metric: 0.7579931972789116\n",
      "Updating best trial\n",
      "Trial 3/10\n",
      "learning_rate:  0.000208\n",
      "OrderedDict({'active.all.allocated': 17662274, 'active.all.current': 3244, 'active.all.freed': 17659030, 'active.all.peak': 4223, 'active.large_pool.allocated': 10881722, 'active.large_pool.current': 602, 'active.large_pool.freed': 10881120, 'active.large_pool.peak': 1103, 'active.small_pool.allocated': 6780552, 'active.small_pool.current': 2642, 'active.small_pool.freed': 6777910, 'active.small_pool.peak': 3220, 'active_bytes.all.allocated': 276856041594880, 'active_bytes.all.current': 8137841664, 'active_bytes.all.freed': 276847903753216, 'active_bytes.all.peak': 21263453184, 'active_bytes.large_pool.allocated': 275992463933440, 'active_bytes.large_pool.current': 8045754368, 'active_bytes.large_pool.freed': 275984418179072, 'active_bytes.large_pool.peak': 21139847168, 'active_bytes.small_pool.allocated': 863577661440, 'active_bytes.small_pool.current': 92087296, 'active_bytes.small_pool.freed': 863485574144, 'active_bytes.small_pool.peak': 124670976, 'allocated_bytes.all.allocated': 276856041594880, 'allocated_bytes.all.current': 8137841664, 'allocated_bytes.all.freed': 276847903753216, 'allocated_bytes.all.peak': 21263453184, 'allocated_bytes.large_pool.allocated': 275992463933440, 'allocated_bytes.large_pool.current': 8045754368, 'allocated_bytes.large_pool.freed': 275984418179072, 'allocated_bytes.large_pool.peak': 21139847168, 'allocated_bytes.small_pool.allocated': 863577661440, 'allocated_bytes.small_pool.current': 92087296, 'allocated_bytes.small_pool.freed': 863485574144, 'allocated_bytes.small_pool.peak': 124670976, 'allocation.all.allocated': 17662274, 'allocation.all.current': 3244, 'allocation.all.freed': 17659030, 'allocation.all.peak': 4223, 'allocation.large_pool.allocated': 10881722, 'allocation.large_pool.current': 602, 'allocation.large_pool.freed': 10881120, 'allocation.large_pool.peak': 1103, 'allocation.small_pool.allocated': 6780552, 'allocation.small_pool.current': 2642, 'allocation.small_pool.freed': 6777910, 'allocation.small_pool.peak': 3220, 'inactive_split.all.allocated': 7759903, 'inactive_split.all.current': 192, 'inactive_split.all.freed': 7759711, 'inactive_split.all.peak': 468, 'inactive_split.large_pool.allocated': 5748132, 'inactive_split.large_pool.current': 136, 'inactive_split.large_pool.freed': 5747996, 'inactive_split.large_pool.peak': 247, 'inactive_split.small_pool.allocated': 2011771, 'inactive_split.small_pool.current': 56, 'inactive_split.small_pool.freed': 2011715, 'inactive_split.small_pool.peak': 222, 'inactive_split_bytes.all.allocated': 153928453331968, 'inactive_split_bytes.all.current': 187851776, 'inactive_split_bytes.all.freed': 153928265480192, 'inactive_split_bytes.all.peak': 2045808640, 'inactive_split_bytes.large_pool.allocated': 152962974109696, 'inactive_split_bytes.large_pool.current': 185567232, 'inactive_split_bytes.large_pool.freed': 152962788542464, 'inactive_split_bytes.large_pool.peak': 2035870720, 'inactive_split_bytes.small_pool.allocated': 965479222272, 'inactive_split_bytes.small_pool.current': 2284544, 'inactive_split_bytes.small_pool.freed': 965476937728, 'inactive_split_bytes.small_pool.peak': 32945152, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 724, 'num_device_free': 346, 'num_ooms': 0, 'num_sync_all_streams': 6, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 276785081462864, 'requested_bytes.all.current': 7930177736, 'requested_bytes.all.freed': 276777151285128, 'requested_bytes.all.peak': 21055785252, 'requested_bytes.large_pool.allocated': 275922440072160, 'requested_bytes.large_pool.current': 7838136320, 'requested_bytes.large_pool.freed': 275914601935840, 'requested_bytes.large_pool.peak': 20932229120, 'requested_bytes.small_pool.allocated': 862641390704, 'requested_bytes.small_pool.current': 92041416, 'requested_bytes.small_pool.freed': 862549349288, 'requested_bytes.small_pool.peak': 124623124, 'reserved_bytes.all.allocated': 37694210048, 'reserved_bytes.all.current': 8325693440, 'reserved_bytes.all.freed': 29368516608, 'reserved_bytes.all.peak': 23035117568, 'reserved_bytes.large_pool.allocated': 37536923648, 'reserved_bytes.large_pool.current': 8231321600, 'reserved_bytes.large_pool.freed': 29305602048, 'reserved_bytes.large_pool.peak': 22909288448, 'reserved_bytes.small_pool.allocated': 157286400, 'reserved_bytes.small_pool.current': 94371840, 'reserved_bytes.small_pool.freed': 62914560, 'reserved_bytes.small_pool.peak': 125829120, 'segment.all.allocated': 724, 'segment.all.current': 378, 'segment.all.freed': 346, 'segment.all.peak': 552, 'segment.large_pool.allocated': 649, 'segment.large_pool.current': 333, 'segment.large_pool.freed': 316, 'segment.large_pool.peak': 492, 'segment.small_pool.allocated': 75, 'segment.small_pool.current': 45, 'segment.small_pool.freed': 30, 'segment.small_pool.peak': 60})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.479700</td>\n",
       "      <td>0.475909</td>\n",
       "      <td>0.868007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>0.455744</td>\n",
       "      <td>0.911871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.370581</td>\n",
       "      <td>0.928986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.383660</td>\n",
       "      <td>0.925803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.386506</td>\n",
       "      <td>0.917789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.9289863945578232\n",
      "Best trial metric: 0.8887687074829932\n",
      "Updating best trial\n",
      "Trial 4/10\n",
      "learning_rate:  0.000307\n",
      "OrderedDict({'active.all.allocated': 26493025, 'active.all.current': 4014, 'active.all.freed': 26489011, 'active.all.peak': 4993, 'active.large_pool.allocated': 16322482, 'active.large_pool.current': 802, 'active.large_pool.freed': 16321680, 'active.large_pool.peak': 1303, 'active.small_pool.allocated': 10170543, 'active.small_pool.current': 3212, 'active.small_pool.freed': 10167331, 'active.small_pool.peak': 3790, 'active_bytes.all.allocated': 415261712680448, 'active_bytes.all.current': 10832715776, 'active_bytes.all.freed': 415250879964672, 'active_bytes.all.peak': 23958327296, 'active_bytes.large_pool.allocated': 413966355506176, 'active_bytes.large_pool.current': 10721992704, 'active_bytes.large_pool.freed': 413955633513472, 'active_bytes.large_pool.peak': 23816085504, 'active_bytes.small_pool.allocated': 1295357174272, 'active_bytes.small_pool.current': 110723072, 'active_bytes.small_pool.freed': 1295246451200, 'active_bytes.small_pool.peak': 143306752, 'allocated_bytes.all.allocated': 415261712680448, 'allocated_bytes.all.current': 10832715776, 'allocated_bytes.all.freed': 415250879964672, 'allocated_bytes.all.peak': 23958327296, 'allocated_bytes.large_pool.allocated': 413966355506176, 'allocated_bytes.large_pool.current': 10721992704, 'allocated_bytes.large_pool.freed': 413955633513472, 'allocated_bytes.large_pool.peak': 23816085504, 'allocated_bytes.small_pool.allocated': 1295357174272, 'allocated_bytes.small_pool.current': 110723072, 'allocated_bytes.small_pool.freed': 1295246451200, 'allocated_bytes.small_pool.peak': 143306752, 'allocation.all.allocated': 26493025, 'allocation.all.current': 4014, 'allocation.all.freed': 26489011, 'allocation.all.peak': 4993, 'allocation.large_pool.allocated': 16322482, 'allocation.large_pool.current': 802, 'allocation.large_pool.freed': 16321680, 'allocation.large_pool.peak': 1303, 'allocation.small_pool.allocated': 10170543, 'allocation.small_pool.current': 3212, 'allocation.small_pool.freed': 10167331, 'allocation.small_pool.peak': 3790, 'inactive_split.all.allocated': 11738486, 'inactive_split.all.current': 255, 'inactive_split.all.freed': 11738231, 'inactive_split.all.peak': 520, 'inactive_split.large_pool.allocated': 8666055, 'inactive_split.large_pool.current': 181, 'inactive_split.large_pool.freed': 8665874, 'inactive_split.large_pool.peak': 291, 'inactive_split.small_pool.allocated': 3072431, 'inactive_split.small_pool.current': 74, 'inactive_split.small_pool.freed': 3072357, 'inactive_split.small_pool.peak': 230, 'inactive_split_bytes.all.allocated': 230132984016384, 'inactive_split_bytes.all.current': 254926848, 'inactive_split_bytes.all.freed': 230132729089536, 'inactive_split_bytes.all.peak': 2112883712, 'inactive_split_bytes.large_pool.allocated': 228686470874112, 'inactive_split_bytes.large_pool.current': 252403712, 'inactive_split_bytes.large_pool.freed': 228686218470400, 'inactive_split_bytes.large_pool.peak': 2102707200, 'inactive_split_bytes.small_pool.allocated': 1446513142272, 'inactive_split_bytes.small_pool.current': 2523136, 'inactive_split_bytes.small_pool.freed': 1446510619136, 'inactive_split_bytes.small_pool.peak': 33414144, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 1017, 'num_device_free': 519, 'num_ooms': 0, 'num_sync_all_streams': 8, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 415176300847876, 'requested_bytes.all.current': 10555831216, 'requested_bytes.all.freed': 415165745016660, 'requested_bytes.all.peak': 23681438732, 'requested_bytes.large_pool.allocated': 413882348072400, 'requested_bytes.large_pool.current': 10445168640, 'requested_bytes.large_pool.freed': 413871902903760, 'requested_bytes.large_pool.peak': 23539261440, 'requested_bytes.small_pool.allocated': 1293952775476, 'requested_bytes.small_pool.current': 110662576, 'requested_bytes.small_pool.freed': 1293842112900, 'requested_bytes.small_pool.peak': 143244284, 'reserved_bytes.all.allocated': 55155097600, 'reserved_bytes.all.current': 11087642624, 'reserved_bytes.all.freed': 44067454976, 'reserved_bytes.all.peak': 25786580992, 'reserved_bytes.large_pool.allocated': 54947479552, 'reserved_bytes.large_pool.current': 10974396416, 'reserved_bytes.large_pool.freed': 43973083136, 'reserved_bytes.large_pool.peak': 25641877504, 'reserved_bytes.small_pool.allocated': 207618048, 'reserved_bytes.small_pool.current': 113246208, 'reserved_bytes.small_pool.freed': 94371840, 'reserved_bytes.small_pool.peak': 144703488, 'segment.all.allocated': 1017, 'segment.all.current': 498, 'segment.all.freed': 519, 'segment.all.peak': 671, 'segment.large_pool.allocated': 918, 'segment.large_pool.current': 444, 'segment.large_pool.freed': 474, 'segment.large_pool.peak': 602, 'segment.small_pool.allocated': 99, 'segment.small_pool.current': 54, 'segment.small_pool.freed': 45, 'segment.small_pool.peak': 69})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.568192</td>\n",
       "      <td>0.940156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.255700</td>\n",
       "      <td>0.362876</td>\n",
       "      <td>0.903381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>0.533944</td>\n",
       "      <td>0.911939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.527704</td>\n",
       "      <td>0.902796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.544033</td>\n",
       "      <td>0.899163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.9401564625850339\n",
      "Best trial metric: 0.9289863945578232\n",
      "Updating best trial\n",
      "Trial 5/10\n",
      "learning_rate:  0.000406\n",
      "OrderedDict({'active.all.allocated': 35323776, 'active.all.current': 4784, 'active.all.freed': 35318992, 'active.all.peak': 5763, 'active.large_pool.allocated': 21763242, 'active.large_pool.current': 1002, 'active.large_pool.freed': 21762240, 'active.large_pool.peak': 1503, 'active.small_pool.allocated': 13560534, 'active.small_pool.current': 3782, 'active.small_pool.freed': 13556752, 'active.small_pool.peak': 4360, 'active_bytes.all.allocated': 553708965446656, 'active_bytes.all.current': 13527589888, 'active_bytes.all.freed': 553695437856768, 'active_bytes.all.peak': 26653201408, 'active_bytes.large_pool.allocated': 551981828759552, 'active_bytes.large_pool.current': 13398231040, 'active_bytes.large_pool.freed': 551968430528512, 'active_bytes.large_pool.peak': 26492323840, 'active_bytes.small_pool.allocated': 1727136687104, 'active_bytes.small_pool.current': 129358848, 'active_bytes.small_pool.freed': 1727007328256, 'active_bytes.small_pool.peak': 161942528, 'allocated_bytes.all.allocated': 553708965446656, 'allocated_bytes.all.current': 13527589888, 'allocated_bytes.all.freed': 553695437856768, 'allocated_bytes.all.peak': 26653201408, 'allocated_bytes.large_pool.allocated': 551981828759552, 'allocated_bytes.large_pool.current': 13398231040, 'allocated_bytes.large_pool.freed': 551968430528512, 'allocated_bytes.large_pool.peak': 26492323840, 'allocated_bytes.small_pool.allocated': 1727136687104, 'allocated_bytes.small_pool.current': 129358848, 'allocated_bytes.small_pool.freed': 1727007328256, 'allocated_bytes.small_pool.peak': 161942528, 'allocation.all.allocated': 35323776, 'allocation.all.current': 4784, 'allocation.all.freed': 35318992, 'allocation.all.peak': 5763, 'allocation.large_pool.allocated': 21763242, 'allocation.large_pool.current': 1002, 'allocation.large_pool.freed': 21762240, 'allocation.large_pool.peak': 1503, 'allocation.small_pool.allocated': 13560534, 'allocation.small_pool.current': 3782, 'allocation.small_pool.freed': 13556752, 'allocation.small_pool.peak': 4360, 'inactive_split.all.allocated': 15653931, 'inactive_split.all.current': 316, 'inactive_split.all.freed': 15653615, 'inactive_split.all.peak': 591, 'inactive_split.large_pool.allocated': 11497371, 'inactive_split.large_pool.current': 226, 'inactive_split.large_pool.freed': 11497145, 'inactive_split.large_pool.peak': 337, 'inactive_split.small_pool.allocated': 4156560, 'inactive_split.small_pool.current': 90, 'inactive_split.small_pool.freed': 4156470, 'inactive_split.small_pool.peak': 256, 'inactive_split_bytes.all.allocated': 306740533883904, 'inactive_split_bytes.all.current': 322001920, 'inactive_split_bytes.all.freed': 306740211881984, 'inactive_split_bytes.all.peak': 2179820544, 'inactive_split_bytes.large_pool.allocated': 304813337619456, 'inactive_split_bytes.large_pool.current': 319240192, 'inactive_split_bytes.large_pool.freed': 304813018379264, 'inactive_split_bytes.large_pool.peak': 2169405440, 'inactive_split_bytes.small_pool.allocated': 1927196264448, 'inactive_split_bytes.small_pool.current': 2761728, 'inactive_split_bytes.small_pool.freed': 1927193502720, 'inactive_split_bytes.small_pool.peak': 33965056, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 1310, 'num_device_free': 692, 'num_ooms': 0, 'num_sync_all_streams': 10, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 553567520232888, 'requested_bytes.all.current': 13181484696, 'requested_bytes.all.freed': 553554338748192, 'requested_bytes.all.peak': 26307092212, 'requested_bytes.large_pool.allocated': 551842256072640, 'requested_bytes.large_pool.current': 13052200960, 'requested_bytes.large_pool.freed': 551829203871680, 'requested_bytes.large_pool.peak': 26146293760, 'requested_bytes.small_pool.allocated': 1725264160248, 'requested_bytes.small_pool.current': 129283736, 'requested_bytes.small_pool.freed': 1725134876512, 'requested_bytes.small_pool.peak': 161865444, 'reserved_bytes.all.allocated': 72609693696, 'reserved_bytes.all.current': 13849591808, 'reserved_bytes.all.freed': 58760101888, 'reserved_bytes.all.peak': 28542238720, 'reserved_bytes.large_pool.allocated': 72351744000, 'reserved_bytes.large_pool.current': 13717471232, 'reserved_bytes.large_pool.freed': 58634272768, 'reserved_bytes.large_pool.peak': 28378660864, 'reserved_bytes.small_pool.allocated': 257949696, 'reserved_bytes.small_pool.current': 132120576, 'reserved_bytes.small_pool.freed': 125829120, 'reserved_bytes.small_pool.peak': 163577856, 'segment.all.allocated': 1310, 'segment.all.current': 618, 'segment.all.freed': 692, 'segment.all.peak': 791, 'segment.large_pool.allocated': 1187, 'segment.large_pool.current': 555, 'segment.large_pool.freed': 632, 'segment.large_pool.peak': 713, 'segment.small_pool.allocated': 123, 'segment.small_pool.current': 63, 'segment.small_pool.freed': 60, 'segment.small_pool.peak': 78})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.513300</td>\n",
       "      <td>0.601424</td>\n",
       "      <td>0.898483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.338764</td>\n",
       "      <td>0.917095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.365733</td>\n",
       "      <td>0.933109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.342664</td>\n",
       "      <td>0.937531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.345706</td>\n",
       "      <td>0.934374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.937530612244898\n",
      "Best trial metric: 0.9401564625850339\n",
      "Trial 6/10\n",
      "learning_rate:  0.000505\n",
      "OrderedDict({'active.all.allocated': 44154527, 'active.all.current': 5554, 'active.all.freed': 44148973, 'active.all.peak': 6533, 'active.large_pool.allocated': 27204002, 'active.large_pool.current': 1202, 'active.large_pool.freed': 27202800, 'active.large_pool.peak': 1703, 'active.small_pool.allocated': 16950525, 'active.small_pool.current': 4352, 'active.small_pool.freed': 16946173, 'active.small_pool.peak': 4930, 'active_bytes.all.allocated': 692114636532224, 'active_bytes.all.current': 16222464000, 'active_bytes.all.freed': 692098414068224, 'active_bytes.all.peak': 29348075520, 'active_bytes.large_pool.allocated': 689955720332288, 'active_bytes.large_pool.current': 16074469376, 'active_bytes.large_pool.freed': 689939645862912, 'active_bytes.large_pool.peak': 29168562176, 'active_bytes.small_pool.allocated': 2158916199936, 'active_bytes.small_pool.current': 147994624, 'active_bytes.small_pool.freed': 2158768205312, 'active_bytes.small_pool.peak': 180578304, 'allocated_bytes.all.allocated': 692114636532224, 'allocated_bytes.all.current': 16222464000, 'allocated_bytes.all.freed': 692098414068224, 'allocated_bytes.all.peak': 29348075520, 'allocated_bytes.large_pool.allocated': 689955720332288, 'allocated_bytes.large_pool.current': 16074469376, 'allocated_bytes.large_pool.freed': 689939645862912, 'allocated_bytes.large_pool.peak': 29168562176, 'allocated_bytes.small_pool.allocated': 2158916199936, 'allocated_bytes.small_pool.current': 147994624, 'allocated_bytes.small_pool.freed': 2158768205312, 'allocated_bytes.small_pool.peak': 180578304, 'allocation.all.allocated': 44154527, 'allocation.all.current': 5554, 'allocation.all.freed': 44148973, 'allocation.all.peak': 6533, 'allocation.large_pool.allocated': 27204002, 'allocation.large_pool.current': 1202, 'allocation.large_pool.freed': 27202800, 'allocation.large_pool.peak': 1703, 'allocation.small_pool.allocated': 16950525, 'allocation.small_pool.current': 4352, 'allocation.small_pool.freed': 16946173, 'allocation.small_pool.peak': 4930, 'inactive_split.all.allocated': 19456462, 'inactive_split.all.current': 373, 'inactive_split.all.freed': 19456089, 'inactive_split.all.peak': 643, 'inactive_split.large_pool.allocated': 14398108, 'inactive_split.large_pool.current': 270, 'inactive_split.large_pool.freed': 14397838, 'inactive_split.large_pool.peak': 381, 'inactive_split.small_pool.allocated': 5058354, 'inactive_split.small_pool.current': 103, 'inactive_split.small_pool.freed': 5058251, 'inactive_split.small_pool.peak': 263, 'inactive_split_bytes.all.allocated': 382390305588736, 'inactive_split_bytes.all.current': 368105472, 'inactive_split_bytes.all.freed': 382389937483264, 'inactive_split_bytes.all.peak': 2226029568, 'inactive_split_bytes.large_pool.allocated': 379981689985024, 'inactive_split_bytes.large_pool.current': 365105152, 'inactive_split_bytes.large_pool.freed': 379981324879872, 'inactive_split_bytes.large_pool.peak': 2215408640, 'inactive_split_bytes.small_pool.allocated': 2408615603712, 'inactive_split_bytes.small_pool.current': 3000320, 'inactive_split_bytes.small_pool.freed': 2408612603392, 'inactive_split_bytes.small_pool.peak': 34387968, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 1603, 'num_device_free': 866, 'num_ooms': 0, 'num_sync_all_streams': 12, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 691958739617900, 'requested_bytes.all.current': 15807138176, 'requested_bytes.all.freed': 691942932479724, 'requested_bytes.all.peak': 28932745692, 'requested_bytes.large_pool.allocated': 689802164072880, 'requested_bytes.large_pool.current': 15659233280, 'requested_bytes.large_pool.freed': 689786504839600, 'requested_bytes.large_pool.peak': 28753326080, 'requested_bytes.small_pool.allocated': 2156575545020, 'requested_bytes.small_pool.current': 147904896, 'requested_bytes.small_pool.freed': 2156427640124, 'requested_bytes.small_pool.peak': 180486604, 'reserved_bytes.all.allocated': 90060095488, 'reserved_bytes.all.current': 16590569472, 'reserved_bytes.all.freed': 73469526016, 'reserved_bytes.all.peak': 31299993600, 'reserved_bytes.large_pool.allocated': 89751814144, 'reserved_bytes.large_pool.current': 16439574528, 'reserved_bytes.large_pool.freed': 73312239616, 'reserved_bytes.large_pool.peak': 31117541376, 'reserved_bytes.small_pool.allocated': 308281344, 'reserved_bytes.small_pool.current': 150994944, 'reserved_bytes.small_pool.freed': 157286400, 'reserved_bytes.small_pool.peak': 182452224, 'segment.all.allocated': 1603, 'segment.all.current': 737, 'segment.all.freed': 866, 'segment.all.peak': 911, 'segment.large_pool.allocated': 1456, 'segment.large_pool.current': 665, 'segment.large_pool.freed': 791, 'segment.large_pool.peak': 824, 'segment.small_pool.allocated': 147, 'segment.small_pool.current': 72, 'segment.small_pool.freed': 75, 'segment.small_pool.peak': 87})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.252100</td>\n",
       "      <td>0.445495</td>\n",
       "      <td>0.955857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.335730</td>\n",
       "      <td>0.925408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.396333</td>\n",
       "      <td>0.919748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.451695</td>\n",
       "      <td>0.890633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.602004</td>\n",
       "      <td>0.889585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.9558571428571428\n",
      "Best trial metric: 0.9401564625850339\n",
      "Updating best trial\n",
      "Trial 7/10\n",
      "learning_rate:  0.0006039999999999999\n",
      "OrderedDict({'active.all.allocated': 52985278, 'active.all.current': 6324, 'active.all.freed': 52978954, 'active.all.peak': 7303, 'active.large_pool.allocated': 32644762, 'active.large_pool.current': 1402, 'active.large_pool.freed': 32643360, 'active.large_pool.peak': 1903, 'active.small_pool.allocated': 20340516, 'active.small_pool.current': 4922, 'active.small_pool.freed': 20335594, 'active.small_pool.peak': 5500, 'active_bytes.all.allocated': 830520307617792, 'active_bytes.all.current': 18917338112, 'active_bytes.all.freed': 830501390279680, 'active_bytes.all.peak': 32042949632, 'active_bytes.large_pool.allocated': 827929611905024, 'active_bytes.large_pool.current': 18750707712, 'active_bytes.large_pool.freed': 827910861197312, 'active_bytes.large_pool.peak': 31844800512, 'active_bytes.small_pool.allocated': 2590695712768, 'active_bytes.small_pool.current': 166630400, 'active_bytes.small_pool.freed': 2590529082368, 'active_bytes.small_pool.peak': 199214080, 'allocated_bytes.all.allocated': 830520307617792, 'allocated_bytes.all.current': 18917338112, 'allocated_bytes.all.freed': 830501390279680, 'allocated_bytes.all.peak': 32042949632, 'allocated_bytes.large_pool.allocated': 827929611905024, 'allocated_bytes.large_pool.current': 18750707712, 'allocated_bytes.large_pool.freed': 827910861197312, 'allocated_bytes.large_pool.peak': 31844800512, 'allocated_bytes.small_pool.allocated': 2590695712768, 'allocated_bytes.small_pool.current': 166630400, 'allocated_bytes.small_pool.freed': 2590529082368, 'allocated_bytes.small_pool.peak': 199214080, 'allocation.all.allocated': 52985278, 'allocation.all.current': 6324, 'allocation.all.freed': 52978954, 'allocation.all.peak': 7303, 'allocation.large_pool.allocated': 32644762, 'allocation.large_pool.current': 1402, 'allocation.large_pool.freed': 32643360, 'allocation.large_pool.peak': 1903, 'allocation.small_pool.allocated': 20340516, 'allocation.small_pool.current': 4922, 'allocation.small_pool.freed': 20335594, 'allocation.small_pool.peak': 5500, 'inactive_split.all.allocated': 23437640, 'inactive_split.all.current': 429, 'inactive_split.all.freed': 23437211, 'inactive_split.all.peak': 708, 'inactive_split.large_pool.allocated': 17316089, 'inactive_split.large_pool.current': 315, 'inactive_split.large_pool.freed': 17315774, 'inactive_split.large_pool.peak': 425, 'inactive_split.small_pool.allocated': 6121551, 'inactive_split.small_pool.current': 114, 'inactive_split.small_pool.freed': 6121437, 'inactive_split.small_pool.peak': 283, 'inactive_split_bytes.all.allocated': 458596539732992, 'inactive_split_bytes.all.current': 433083392, 'inactive_split_bytes.all.freed': 458596106649600, 'inactive_split_bytes.all.peak': 2293137408, 'inactive_split_bytes.large_pool.allocated': 455705412717568, 'inactive_split_bytes.large_pool.current': 431941632, 'inactive_split_bytes.large_pool.freed': 455704980775936, 'inactive_split_bytes.large_pool.peak': 2282245120, 'inactive_split_bytes.small_pool.allocated': 2891127015424, 'inactive_split_bytes.small_pool.current': 1141760, 'inactive_split_bytes.small_pool.freed': 2891125873664, 'inactive_split_bytes.small_pool.peak': 35031040, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 1896, 'num_device_free': 1040, 'num_ooms': 0, 'num_sync_all_streams': 14, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 830349959002912, 'requested_bytes.all.current': 18432791656, 'requested_bytes.all.freed': 830331526211256, 'requested_bytes.all.peak': 31558399172, 'requested_bytes.large_pool.allocated': 827762072073120, 'requested_bytes.large_pool.current': 18266265600, 'requested_bytes.large_pool.freed': 827743805807520, 'requested_bytes.large_pool.peak': 31360358400, 'requested_bytes.small_pool.allocated': 2587886929792, 'requested_bytes.small_pool.current': 166526056, 'requested_bytes.small_pool.freed': 2587720403736, 'requested_bytes.small_pool.peak': 199107764, 'reserved_bytes.all.allocated': 107520983040, 'reserved_bytes.all.current': 19350421504, 'reserved_bytes.all.freed': 88170561536, 'reserved_bytes.all.peak': 34051457024, 'reserved_bytes.large_pool.allocated': 107162370048, 'reserved_bytes.large_pool.current': 19182649344, 'reserved_bytes.large_pool.freed': 87979720704, 'reserved_bytes.large_pool.peak': 33850130432, 'reserved_bytes.small_pool.allocated': 358612992, 'reserved_bytes.small_pool.current': 167772160, 'reserved_bytes.small_pool.freed': 190840832, 'reserved_bytes.small_pool.peak': 201326592, 'segment.all.allocated': 1896, 'segment.all.current': 856, 'segment.all.freed': 1040, 'segment.all.peak': 1030, 'segment.large_pool.allocated': 1725, 'segment.large_pool.current': 776, 'segment.large_pool.freed': 949, 'segment.large_pool.peak': 934, 'segment.small_pool.allocated': 171, 'segment.small_pool.current': 80, 'segment.small_pool.freed': 91, 'segment.small_pool.peak': 96})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.446513</td>\n",
       "      <td>0.943503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.330047</td>\n",
       "      <td>0.948211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>0.957340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.312380</td>\n",
       "      <td>0.954129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>0.302057</td>\n",
       "      <td>0.949912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.9573401360544218\n",
      "Best trial metric: 0.9558571428571428\n",
      "Updating best trial\n",
      "Trial 8/10\n",
      "learning_rate:  0.000703\n",
      "OrderedDict({'active.all.allocated': 61816029, 'active.all.current': 7094, 'active.all.freed': 61808935, 'active.all.peak': 8073, 'active.large_pool.allocated': 38085522, 'active.large_pool.current': 1602, 'active.large_pool.freed': 38083920, 'active.large_pool.peak': 2103, 'active.small_pool.allocated': 23730507, 'active.small_pool.current': 5492, 'active.small_pool.freed': 23725015, 'active.small_pool.peak': 6070, 'active_bytes.all.allocated': 968967560384000, 'active_bytes.all.current': 21612212224, 'active_bytes.all.freed': 968945948171776, 'active_bytes.all.peak': 34737823744, 'active_bytes.large_pool.allocated': 965945085158400, 'active_bytes.large_pool.current': 21426946048, 'active_bytes.large_pool.freed': 965923658212352, 'active_bytes.large_pool.peak': 34521038848, 'active_bytes.small_pool.allocated': 3022475225600, 'active_bytes.small_pool.current': 185266176, 'active_bytes.small_pool.freed': 3022289959424, 'active_bytes.small_pool.peak': 217849856, 'allocated_bytes.all.allocated': 968967560384000, 'allocated_bytes.all.current': 21612212224, 'allocated_bytes.all.freed': 968945948171776, 'allocated_bytes.all.peak': 34737823744, 'allocated_bytes.large_pool.allocated': 965945085158400, 'allocated_bytes.large_pool.current': 21426946048, 'allocated_bytes.large_pool.freed': 965923658212352, 'allocated_bytes.large_pool.peak': 34521038848, 'allocated_bytes.small_pool.allocated': 3022475225600, 'allocated_bytes.small_pool.current': 185266176, 'allocated_bytes.small_pool.freed': 3022289959424, 'allocated_bytes.small_pool.peak': 217849856, 'allocation.all.allocated': 61816029, 'allocation.all.current': 7094, 'allocation.all.freed': 61808935, 'allocation.all.peak': 8073, 'allocation.large_pool.allocated': 38085522, 'allocation.large_pool.current': 1602, 'allocation.large_pool.freed': 38083920, 'allocation.large_pool.peak': 2103, 'allocation.small_pool.allocated': 23730507, 'allocation.small_pool.current': 5492, 'allocation.small_pool.freed': 23725015, 'allocation.small_pool.peak': 6070, 'inactive_split.all.allocated': 27378535, 'inactive_split.all.current': 485, 'inactive_split.all.freed': 27378050, 'inactive_split.all.peak': 755, 'inactive_split.large_pool.allocated': 20147363, 'inactive_split.large_pool.current': 360, 'inactive_split.large_pool.freed': 20147003, 'inactive_split.large_pool.peak': 471, 'inactive_split.small_pool.allocated': 7231172, 'inactive_split.small_pool.current': 125, 'inactive_split.small_pool.freed': 7231047, 'inactive_split.small_pool.peak': 285, 'inactive_split_bytes.all.allocated': 535206720195072, 'inactive_split_bytes.all.current': 500158464, 'inactive_split_bytes.all.freed': 535206220036608, 'inactive_split_bytes.all.peak': 2362244608, 'inactive_split_bytes.large_pool.allocated': 531831810225152, 'inactive_split_bytes.large_pool.current': 498778112, 'inactive_split_bytes.large_pool.freed': 531831311447040, 'inactive_split_bytes.large_pool.peak': 2348943360, 'inactive_split_bytes.small_pool.allocated': 3374909969920, 'inactive_split_bytes.small_pool.current': 1380352, 'inactive_split_bytes.small_pool.freed': 3374908589568, 'inactive_split_bytes.small_pool.peak': 35525632, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 2190, 'num_device_free': 1214, 'num_ooms': 0, 'num_sync_all_streams': 16, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 968741178387924, 'requested_bytes.all.current': 21058445136, 'requested_bytes.all.freed': 968720119942788, 'requested_bytes.all.peak': 34184052652, 'requested_bytes.large_pool.allocated': 965721980073360, 'requested_bytes.large_pool.current': 20873297920, 'requested_bytes.large_pool.freed': 965701106775440, 'requested_bytes.large_pool.peak': 33967390720, 'requested_bytes.small_pool.allocated': 3019198314564, 'requested_bytes.small_pool.current': 185147216, 'requested_bytes.small_pool.freed': 3019013167348, 'requested_bytes.small_pool.peak': 217728924, 'reserved_bytes.all.allocated': 124977676288, 'reserved_bytes.all.current': 22112370688, 'reserved_bytes.all.freed': 102865305600, 'reserved_bytes.all.peak': 36807114752, 'reserved_bytes.large_pool.allocated': 124566634496, 'reserved_bytes.large_pool.current': 21925724160, 'reserved_bytes.large_pool.freed': 102640910336, 'reserved_bytes.large_pool.peak': 36586913792, 'reserved_bytes.small_pool.allocated': 411041792, 'reserved_bytes.small_pool.current': 186646528, 'reserved_bytes.small_pool.freed': 224395264, 'reserved_bytes.small_pool.peak': 220200960, 'segment.all.allocated': 2190, 'segment.all.current': 976, 'segment.all.freed': 1214, 'segment.all.peak': 1150, 'segment.large_pool.allocated': 1994, 'segment.large_pool.current': 887, 'segment.large_pool.freed': 1107, 'segment.large_pool.peak': 1045, 'segment.small_pool.allocated': 196, 'segment.small_pool.current': 89, 'segment.small_pool.freed': 107, 'segment.small_pool.peak': 105})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.481479</td>\n",
       "      <td>0.904551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.267927</td>\n",
       "      <td>0.963844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.243577</td>\n",
       "      <td>0.966782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.171775</td>\n",
       "      <td>0.964592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.203544</td>\n",
       "      <td>0.964878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.96678231292517\n",
      "Best trial metric: 0.9573401360544218\n",
      "Updating best trial\n",
      "Trial 9/10\n",
      "learning_rate:  0.000802\n",
      "OrderedDict({'active.all.allocated': 70646780, 'active.all.current': 7864, 'active.all.freed': 70638916, 'active.all.peak': 8843, 'active.large_pool.allocated': 43526282, 'active.large_pool.current': 1802, 'active.large_pool.freed': 43524480, 'active.large_pool.peak': 2303, 'active.small_pool.allocated': 27120498, 'active.small_pool.current': 6062, 'active.small_pool.freed': 27114436, 'active.small_pool.peak': 6640, 'active_bytes.all.allocated': 1107373231469568, 'active_bytes.all.current': 24307086336, 'active_bytes.all.freed': 1107348924383232, 'active_bytes.all.peak': 37432697856, 'active_bytes.large_pool.allocated': 1103918976731136, 'active_bytes.large_pool.current': 24103184384, 'active_bytes.large_pool.freed': 1103894873546752, 'active_bytes.large_pool.peak': 37197277184, 'active_bytes.small_pool.allocated': 3454254738432, 'active_bytes.small_pool.current': 203901952, 'active_bytes.small_pool.freed': 3454050836480, 'active_bytes.small_pool.peak': 236485632, 'allocated_bytes.all.allocated': 1107373231469568, 'allocated_bytes.all.current': 24307086336, 'allocated_bytes.all.freed': 1107348924383232, 'allocated_bytes.all.peak': 37432697856, 'allocated_bytes.large_pool.allocated': 1103918976731136, 'allocated_bytes.large_pool.current': 24103184384, 'allocated_bytes.large_pool.freed': 1103894873546752, 'allocated_bytes.large_pool.peak': 37197277184, 'allocated_bytes.small_pool.allocated': 3454254738432, 'allocated_bytes.small_pool.current': 203901952, 'allocated_bytes.small_pool.freed': 3454050836480, 'allocated_bytes.small_pool.peak': 236485632, 'allocation.all.allocated': 70646780, 'allocation.all.current': 7864, 'allocation.all.freed': 70638916, 'allocation.all.peak': 8843, 'allocation.large_pool.allocated': 43526282, 'allocation.large_pool.current': 1802, 'allocation.large_pool.freed': 43524480, 'allocation.large_pool.peak': 2303, 'allocation.small_pool.allocated': 27120498, 'allocation.small_pool.current': 6062, 'allocation.small_pool.freed': 27114436, 'allocation.small_pool.peak': 6640, 'inactive_split.all.allocated': 31403902, 'inactive_split.all.current': 549, 'inactive_split.all.freed': 31403353, 'inactive_split.all.peak': 812, 'inactive_split.large_pool.allocated': 23048399, 'inactive_split.large_pool.current': 404, 'inactive_split.large_pool.freed': 23047995, 'inactive_split.large_pool.peak': 515, 'inactive_split.small_pool.allocated': 8355503, 'inactive_split.small_pool.current': 145, 'inactive_split.small_pool.freed': 8355358, 'inactive_split.small_pool.peak': 299, 'inactive_split_bytes.all.allocated': 610862575896576, 'inactive_split_bytes.all.current': 546262016, 'inactive_split_bytes.all.freed': 610862029634560, 'inactive_split_bytes.all.peak': 2412542464, 'inactive_split_bytes.large_pool.allocated': 607003656970240, 'inactive_split_bytes.large_pool.current': 544643072, 'inactive_split_bytes.large_pool.freed': 607003112327168, 'inactive_split_bytes.large_pool.peak': 2394946560, 'inactive_split_bytes.small_pool.allocated': 3858918926336, 'inactive_split_bytes.small_pool.current': 1618944, 'inactive_split_bytes.small_pool.freed': 3858917307392, 'inactive_split_bytes.small_pool.peak': 37798912, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 2484, 'num_device_free': 1389, 'num_ooms': 0, 'num_sync_all_streams': 18, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 1107132397772936, 'requested_bytes.all.current': 23684098616, 'requested_bytes.all.freed': 1107108713674320, 'requested_bytes.all.peak': 36809706132, 'requested_bytes.large_pool.allocated': 1103681888073600, 'requested_bytes.large_pool.current': 23480330240, 'requested_bytes.large_pool.freed': 1103658407743360, 'requested_bytes.large_pool.peak': 36574423040, 'requested_bytes.small_pool.allocated': 3450509699336, 'requested_bytes.small_pool.current': 203768376, 'requested_bytes.small_pool.freed': 3450305930960, 'requested_bytes.small_pool.peak': 236350084, 'reserved_bytes.all.allocated': 142430175232, 'reserved_bytes.all.current': 24853348352, 'reserved_bytes.all.freed': 117576826880, 'reserved_bytes.all.peak': 39564869632, 'reserved_bytes.large_pool.allocated': 141966704640, 'reserved_bytes.large_pool.current': 24647827456, 'reserved_bytes.large_pool.freed': 117318877184, 'reserved_bytes.large_pool.peak': 39325794304, 'reserved_bytes.small_pool.allocated': 463470592, 'reserved_bytes.small_pool.current': 205520896, 'reserved_bytes.small_pool.freed': 257949696, 'reserved_bytes.small_pool.peak': 239075328, 'segment.all.allocated': 2484, 'segment.all.current': 1095, 'segment.all.freed': 1389, 'segment.all.peak': 1270, 'segment.large_pool.allocated': 2263, 'segment.large_pool.current': 997, 'segment.large_pool.freed': 1266, 'segment.large_pool.peak': 1156, 'segment.small_pool.allocated': 221, 'segment.small_pool.current': 98, 'segment.small_pool.freed': 123, 'segment.small_pool.peak': 114})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.649327</td>\n",
       "      <td>0.881218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.263200</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.928116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.431217</td>\n",
       "      <td>0.907789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.583324</td>\n",
       "      <td>0.868347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.864429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.9281156462585034\n",
      "Best trial metric: 0.96678231292517\n",
      "Trial 10/10\n",
      "learning_rate:  0.000901\n",
      "OrderedDict({'active.all.allocated': 79477531, 'active.all.current': 8634, 'active.all.freed': 79468897, 'active.all.peak': 9613, 'active.large_pool.allocated': 48967042, 'active.large_pool.current': 2002, 'active.large_pool.freed': 48965040, 'active.large_pool.peak': 2503, 'active.small_pool.allocated': 30510489, 'active.small_pool.current': 6632, 'active.small_pool.freed': 30503857, 'active.small_pool.peak': 7210, 'active_bytes.all.allocated': 1245778902555136, 'active_bytes.all.current': 27001960448, 'active_bytes.all.freed': 1245751900594688, 'active_bytes.all.peak': 40127571968, 'active_bytes.large_pool.allocated': 1241892868303872, 'active_bytes.large_pool.current': 26779422720, 'active_bytes.large_pool.freed': 1241866088881152, 'active_bytes.large_pool.peak': 39873515520, 'active_bytes.small_pool.allocated': 3886034251264, 'active_bytes.small_pool.current': 222537728, 'active_bytes.small_pool.freed': 3885811713536, 'active_bytes.small_pool.peak': 255121408, 'allocated_bytes.all.allocated': 1245778902555136, 'allocated_bytes.all.current': 27001960448, 'allocated_bytes.all.freed': 1245751900594688, 'allocated_bytes.all.peak': 40127571968, 'allocated_bytes.large_pool.allocated': 1241892868303872, 'allocated_bytes.large_pool.current': 26779422720, 'allocated_bytes.large_pool.freed': 1241866088881152, 'allocated_bytes.large_pool.peak': 39873515520, 'allocated_bytes.small_pool.allocated': 3886034251264, 'allocated_bytes.small_pool.current': 222537728, 'allocated_bytes.small_pool.freed': 3885811713536, 'allocated_bytes.small_pool.peak': 255121408, 'allocation.all.allocated': 79477531, 'allocation.all.current': 8634, 'allocation.all.freed': 79468897, 'allocation.all.peak': 9613, 'allocation.large_pool.allocated': 48967042, 'allocation.large_pool.current': 2002, 'allocation.large_pool.freed': 48965040, 'allocation.large_pool.peak': 2503, 'allocation.small_pool.allocated': 30510489, 'allocation.small_pool.current': 6632, 'allocation.small_pool.freed': 30503857, 'allocation.small_pool.peak': 7210, 'inactive_split.all.allocated': 35293223, 'inactive_split.all.current': 601, 'inactive_split.all.freed': 35292622, 'inactive_split.all.peak': 873, 'inactive_split.large_pool.allocated': 25966359, 'inactive_split.large_pool.current': 449, 'inactive_split.large_pool.freed': 25965910, 'inactive_split.large_pool.peak': 559, 'inactive_split.small_pool.allocated': 9326864, 'inactive_split.small_pool.current': 152, 'inactive_split.small_pool.freed': 9326712, 'inactive_split.small_pool.peak': 316, 'inactive_split_bytes.all.allocated': 687068780019200, 'inactive_split_bytes.all.current': 613337088, 'inactive_split_bytes.all.freed': 687068166682112, 'inactive_split_bytes.all.peak': 2479617536, 'inactive_split_bytes.large_pool.allocated': 682727557960704, 'inactive_split_bytes.large_pool.current': 611479552, 'inactive_split_bytes.large_pool.freed': 682726946481152, 'inactive_split_bytes.large_pool.peak': 2461783040, 'inactive_split_bytes.small_pool.allocated': 4341222058496, 'inactive_split_bytes.small_pool.current': 1857536, 'inactive_split_bytes.small_pool.freed': 4341220200960, 'inactive_split_bytes.small_pool.peak': 38037504, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 2778, 'num_device_free': 1563, 'num_ooms': 0, 'num_sync_all_streams': 20, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 1245523617157948, 'requested_bytes.all.current': 26309752096, 'requested_bytes.all.freed': 1245497307405852, 'requested_bytes.all.peak': 39435359612, 'requested_bytes.large_pool.allocated': 1241641796073840, 'requested_bytes.large_pool.current': 26087362560, 'requested_bytes.large_pool.freed': 1241615708711280, 'requested_bytes.large_pool.peak': 39181455360, 'requested_bytes.small_pool.allocated': 3881821084108, 'requested_bytes.small_pool.current': 222389536, 'requested_bytes.small_pool.freed': 3881598694572, 'requested_bytes.small_pool.peak': 254971244, 'reserved_bytes.all.allocated': 159893159936, 'reserved_bytes.all.current': 27615297536, 'reserved_bytes.all.freed': 132277862400, 'reserved_bytes.all.peak': 42316333056, 'reserved_bytes.large_pool.allocated': 159377260544, 'reserved_bytes.large_pool.current': 27390902272, 'reserved_bytes.large_pool.freed': 131986358272, 'reserved_bytes.large_pool.peak': 42058383360, 'reserved_bytes.small_pool.allocated': 515899392, 'reserved_bytes.small_pool.current': 224395264, 'reserved_bytes.small_pool.freed': 291504128, 'reserved_bytes.small_pool.peak': 257949696, 'segment.all.allocated': 2778, 'segment.all.current': 1215, 'segment.all.freed': 1563, 'segment.all.peak': 1389, 'segment.large_pool.allocated': 2532, 'segment.large_pool.current': 1108, 'segment.large_pool.freed': 1424, 'segment.large_pool.peak': 1266, 'segment.small_pool.allocated': 246, 'segment.small_pool.current': 107, 'segment.small_pool.freed': 139, 'segment.small_pool.peak': 123})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.446363</td>\n",
       "      <td>0.935367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.446967</td>\n",
       "      <td>0.867354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.326108</td>\n",
       "      <td>0.951558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.355001</td>\n",
       "      <td>0.935803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.334997</td>\n",
       "      <td>0.949585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer: <transformers.trainer.Trainer object at 0x7f11685f7a10>\n",
      "Best current Metric: 0.9515578231292515\n",
      "Best trial metric: 0.96678231292517\n",
      "Best Trial: {'learning_rate': 0.000703, 'per_device_train_batch_size': 2, 0.96678231292517: 0.96678231292517}\n",
      "OrderedDict({'active.all.allocated': 88308282, 'active.all.current': 9404, 'active.all.freed': 88298878, 'active.all.peak': 10383, 'active.large_pool.allocated': 54407802, 'active.large_pool.current': 2202, 'active.large_pool.freed': 54405600, 'active.large_pool.peak': 2703, 'active.small_pool.allocated': 33900480, 'active.small_pool.current': 7202, 'active.small_pool.freed': 33893278, 'active.small_pool.peak': 7780, 'active_bytes.all.allocated': 1384226155321344, 'active_bytes.all.current': 29696834560, 'active_bytes.all.freed': 1384196458486784, 'active_bytes.all.peak': 42822446080, 'active_bytes.large_pool.allocated': 1379908341557248, 'active_bytes.large_pool.current': 29455661056, 'active_bytes.large_pool.freed': 1379878885896192, 'active_bytes.large_pool.peak': 42549753856, 'active_bytes.small_pool.allocated': 4317813764096, 'active_bytes.small_pool.current': 241173504, 'active_bytes.small_pool.freed': 4317572590592, 'active_bytes.small_pool.peak': 273757184, 'allocated_bytes.all.allocated': 1384226155321344, 'allocated_bytes.all.current': 29696834560, 'allocated_bytes.all.freed': 1384196458486784, 'allocated_bytes.all.peak': 42822446080, 'allocated_bytes.large_pool.allocated': 1379908341557248, 'allocated_bytes.large_pool.current': 29455661056, 'allocated_bytes.large_pool.freed': 1379878885896192, 'allocated_bytes.large_pool.peak': 42549753856, 'allocated_bytes.small_pool.allocated': 4317813764096, 'allocated_bytes.small_pool.current': 241173504, 'allocated_bytes.small_pool.freed': 4317572590592, 'allocated_bytes.small_pool.peak': 273757184, 'allocation.all.allocated': 88308282, 'allocation.all.current': 9404, 'allocation.all.freed': 88298878, 'allocation.all.peak': 10383, 'allocation.large_pool.allocated': 54407802, 'allocation.large_pool.current': 2202, 'allocation.large_pool.freed': 54405600, 'allocation.large_pool.peak': 2703, 'allocation.small_pool.allocated': 33900480, 'allocation.small_pool.current': 7202, 'allocation.small_pool.freed': 33893278, 'allocation.small_pool.peak': 7780, 'inactive_split.all.allocated': 39151546, 'inactive_split.all.current': 666, 'inactive_split.all.freed': 39150880, 'inactive_split.all.peak': 937, 'inactive_split.large_pool.allocated': 28797646, 'inactive_split.large_pool.current': 494, 'inactive_split.large_pool.freed': 28797152, 'inactive_split.large_pool.peak': 605, 'inactive_split.small_pool.allocated': 10353900, 'inactive_split.small_pool.current': 172, 'inactive_split.small_pool.freed': 10353728, 'inactive_split.small_pool.peak': 334, 'inactive_split_bytes.all.allocated': 763676965339136, 'inactive_split_bytes.all.current': 680412160, 'inactive_split_bytes.all.freed': 763676284926976, 'inactive_split_bytes.all.peak': 2546692608, 'inactive_split_bytes.large_pool.allocated': 758854123240448, 'inactive_split_bytes.large_pool.current': 678316032, 'inactive_split_bytes.large_pool.freed': 758853444924416, 'inactive_split_bytes.large_pool.peak': 2528481280, 'inactive_split_bytes.small_pool.allocated': 4822842098688, 'inactive_split_bytes.small_pool.current': 2096128, 'inactive_split_bytes.small_pool.freed': 4822840002560, 'inactive_split_bytes.small_pool.peak': 38276096, 'max_split_size': -1, 'num_alloc_retries': 0, 'num_device_alloc': 3071, 'num_device_free': 1736, 'num_ooms': 0, 'num_sync_all_streams': 22, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 1383914836542960, 'requested_bytes.all.current': 28935405576, 'requested_bytes.all.freed': 1383885901137384, 'requested_bytes.all.peak': 42061013092, 'requested_bytes.large_pool.allocated': 1379601704074080, 'requested_bytes.large_pool.current': 28694394880, 'requested_bytes.large_pool.freed': 1379573009679200, 'requested_bytes.large_pool.peak': 41788487680, 'requested_bytes.small_pool.allocated': 4313132468880, 'requested_bytes.small_pool.current': 241010696, 'requested_bytes.small_pool.freed': 4312891458184, 'requested_bytes.small_pool.peak': 273592404, 'reserved_bytes.all.allocated': 177347756032, 'reserved_bytes.all.current': 30377246720, 'reserved_bytes.all.freed': 146970509312, 'reserved_bytes.all.peak': 45069893632, 'reserved_bytes.large_pool.allocated': 176781524992, 'reserved_bytes.large_pool.current': 30133977088, 'reserved_bytes.large_pool.freed': 146647547904, 'reserved_bytes.large_pool.peak': 44795166720, 'reserved_bytes.small_pool.allocated': 566231040, 'reserved_bytes.small_pool.current': 243269632, 'reserved_bytes.small_pool.freed': 322961408, 'reserved_bytes.small_pool.peak': 274726912, 'segment.all.allocated': 3071, 'segment.all.current': 1335, 'segment.all.freed': 1736, 'segment.all.peak': 1508, 'segment.large_pool.allocated': 2801, 'segment.large_pool.current': 1219, 'segment.large_pool.freed': 1582, 'segment.large_pool.peak': 1377, 'segment.small_pool.allocated': 270, 'segment.small_pool.current': 116, 'segment.small_pool.freed': 154, 'segment.small_pool.peak': 131})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1335' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1335/1335 20:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.481479</td>\n",
       "      <td>0.904551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.267927</td>\n",
       "      <td>0.963844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.243577</td>\n",
       "      <td>0.966782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.171775</td>\n",
       "      <td>0.964592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.203544</td>\n",
       "      <td>0.964878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/kaustubh/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_protein_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering the exact data used for training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_dataset = pd.read_pickle('/home/kaustubh/RuBisCO_ML/ESM_LoRA/data/large_assay_dataset_wco2_wiptg_bimodal_activity_threshold.pkl')\n",
    "large_dataset = large_dataset[[\"LSU_id\", \"SSU_id\", \"lsu_seq\", \"ssu_seq\", \"activity_binary\"]]\n",
    "\n",
    "mutant_dataset = pd.read_pickle(\"/home/kaustubh/RuBisCO_ML/ESM_LoRA/data/form_III_IB_anc_variants_binary_activity_only_wrt_inactive_variant.pkl\")\n",
    "mutant_dataset.rename(columns={\"activity_binary_wrt_inactive_Anc\": \"activity_binary\"}, inplace=True)\n",
    "\n",
    "combined_dataset = pd.concat([large_dataset, mutant_dataset], ignore_index=True)\n",
    "combined_dataset = combined_dataset[combined_dataset['LSU_id'] != \"SUMO\"]\n",
    "combined_dataset = combined_dataset[combined_dataset['LSU_id'] != \"DEAD\"]\n",
    "combined_dataset['LSU_SSU_id'] = combined_dataset.apply(lambda x: x['LSU_id'] + \"-\" + x['SSU_id'] if pd.notna(x['SSU_id']) else x['LSU_id'] + \"-none\", axis=1)\n",
    "combined_dataset['LSU_SSU_seq'] = combined_dataset.apply(lambda x: x['lsu_seq'] + x['ssu_seq'] if (pd.notna(x['ssu_seq']) and x[\"SSU_id\"] != \"SUMO\") else x['lsu_seq'], axis=1)\n",
    "\n",
    "combined_dataset_large_subet = combined_dataset[~combined_dataset['LSU_id'].str.startswith(\"Anc\")]\n",
    "combined_dataset_mutant_subet = combined_dataset[combined_dataset['LSU_id'].str.startswith(\"Anc\")]\n",
    "\n",
    "sequences = combined_dataset_large_subet['LSU_SSU_seq'].to_list()\n",
    "binary_activity = combined_dataset_large_subet['activity_binary'].to_list()\n",
    "lsu_ssu_ids = combined_dataset_large_subet['LSU_SSU_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LSU_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SSU_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lsu_seq",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ssu_seq",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activity_binary",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LSU_SSU_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LSU_SSU_seq",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cfbf3719-4999-45e5-9638-8a4218ead5c5",
       "rows": [
        [
         "246",
         "337",
         "SUMO",
         "MAQQKEYVDLNLKDEDLVKNGNHLLAVFHLKPAGGLDLLEAASEVAAESSTGTNVEVSTATEFSKSLDALVYKIDEAKNLVKIAYPWDIFDRGGNVQNILTYIAGNIFGMSDIKALKLLDVWFPPEMLKQFDGPSYNIDDMRKLLGVYDRPILGTIIKPKIGLKPEEFAEVCYQFWVGGGDFIKNDEPQANQPFCPFEKMVDAVREAMDKAEEETGKKKVYSFNITAADFDEMIKRAEYVIDKMKPGSYAFLVDGITAGWTAVQTLRREYPNVFIHFHRAGHGAFTRPENPMGYSVLVLTKLARLAGASGIHTGTAGVGKMEGDAEEDVTVAHMLRRDKAKGPFFEQDWYGMKPTCPIVSGGLNPVLLPPFIDVLGHVDVITTAGGGVHGHPDGTKAGAKALRQACEAWKKGIDIEEYAKDHKELAQAIESYSKKKEKVHKL",
         null,
         "0",
         "337-SUMO",
         "MAQQKEYVDLNLKDEDLVKNGNHLLAVFHLKPAGGLDLLEAASEVAAESSTGTNVEVSTATEFSKSLDALVYKIDEAKNLVKIAYPWDIFDRGGNVQNILTYIAGNIFGMSDIKALKLLDVWFPPEMLKQFDGPSYNIDDMRKLLGVYDRPILGTIIKPKIGLKPEEFAEVCYQFWVGGGDFIKNDEPQANQPFCPFEKMVDAVREAMDKAEEETGKKKVYSFNITAADFDEMIKRAEYVIDKMKPGSYAFLVDGITAGWTAVQTLRREYPNVFIHFHRAGHGAFTRPENPMGYSVLVLTKLARLAGASGIHTGTAGVGKMEGDAEEDVTVAHMLRRDKAKGPFFEQDWYGMKPTCPIVSGGLNPVLLPPFIDVLGHVDVITTAGGGVHGHPDGTKAGAKALRQACEAWKKGIDIEEYAKDHKELAQAIESYSKKKEKVHKL"
        ],
        [
         "594",
         "435",
         "SUMO",
         "MQTNSQTKAQFQAGVREYRETYYDPGYTPKDTDILAAFRVTPQPGVPPEEAAAAVAAESSTGTWTTVWTDLLTDLERYQARCYRIEPVPGQEDQYIAYIAYPLDLFEEGSIVNLMSSIVGNVFGFKALRALRLEDMRIPVAYVKTFQGPPHGIQVERDRLNKYGRPLLGATIKPKLGLSAKNYGRVVYECLRGGLDFTKDDENINSQPFMRWRDRFLFVMEAVHKAEAETGERKGHYLNVTAPTMEEMYERAEFAKELGSPIIMVDYLTVGFTAHTSLSKWCRKNGMLLHVHRAMHAVIDRQKNHGISFRVLAKWLRLAGGDHLHTGTVVGKLEGDRAATLGIVDLLREDYVPADPSRGIYFDQDWASLPAVFPVASGGIHVGHMPALVSIFGDDAVLQFGGGTLGHPWGNAAGATANRVALEAVVQARNEGRDLVAEGQEILKEAARHSPELRAALETWKDIKFDFETVDTLDVVAAKS",
         null,
         "1",
         "435-SUMO",
         "MQTNSQTKAQFQAGVREYRETYYDPGYTPKDTDILAAFRVTPQPGVPPEEAAAAVAAESSTGTWTTVWTDLLTDLERYQARCYRIEPVPGQEDQYIAYIAYPLDLFEEGSIVNLMSSIVGNVFGFKALRALRLEDMRIPVAYVKTFQGPPHGIQVERDRLNKYGRPLLGATIKPKLGLSAKNYGRVVYECLRGGLDFTKDDENINSQPFMRWRDRFLFVMEAVHKAEAETGERKGHYLNVTAPTMEEMYERAEFAKELGSPIIMVDYLTVGFTAHTSLSKWCRKNGMLLHVHRAMHAVIDRQKNHGISFRVLAKWLRLAGGDHLHTGTVVGKLEGDRAATLGIVDLLREDYVPADPSRGIYFDQDWASLPAVFPVASGGIHVGHMPALVSIFGDDAVLQFGGGTLGHPWGNAAGATANRVALEAVVQARNEGRDLVAEGQEILKEAARHSPELRAALETWKDIKFDFETVDTLDVVAAKS"
        ],
        [
         "660",
         "495",
         "SUMO",
         "MQTNSQTKALFDAGVREYRETYYDPGYVPKDTDVLAAFRVTPQPGVPPEEAAAAVAAESSTGTWTTVWTDLLTDLERYQARCYRIEPVPGQEDQFIAYIAYPLDLFEEGSIVNLMSSIVGNVFGFKALRALRLEDLRIPVAYLKTFQGPPHGIQVERDRLNKYGRPLLGATIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENINSQPFMRWRDRYLFVMEAVHKAEAETGERKGHYLNVTAPTMEEMYERAEFAKELGSPIIMVDYLTVGFTAHTSLSKWCRKNGMLLHVHRAMHAVIDRQKNHGIHWRVLAKWLRMAGGDHLHNGTVVGKLEGDRASTLGINDLLREDYVPADPSRGIYFDQPWASLPAVFPVASGGIHVWHMPELVSIFGDDAVLQFGGGTLGHPWGNAAGATANRVALEAVVQARNEGRDLVAEGQEILKEAARHSPELRAALETWKDIAFDFETVDTLDPVAAKA",
         null,
         "1",
         "495-SUMO",
         "MQTNSQTKALFDAGVREYRETYYDPGYVPKDTDVLAAFRVTPQPGVPPEEAAAAVAAESSTGTWTTVWTDLLTDLERYQARCYRIEPVPGQEDQFIAYIAYPLDLFEEGSIVNLMSSIVGNVFGFKALRALRLEDLRIPVAYLKTFQGPPHGIQVERDRLNKYGRPLLGATIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENINSQPFMRWRDRYLFVMEAVHKAEAETGERKGHYLNVTAPTMEEMYERAEFAKELGSPIIMVDYLTVGFTAHTSLSKWCRKNGMLLHVHRAMHAVIDRQKNHGIHWRVLAKWLRMAGGDHLHNGTVVGKLEGDRASTLGINDLLREDYVPADPSRGIYFDQPWASLPAVFPVASGGIHVWHMPELVSIFGDDAVLQFGGGTLGHPWGNAAGATANRVALEAVVQARNEGRDLVAEGQEILKEAARHSPELRAALETWKDIAFDFETVDTLDPVAAKA"
        ],
        [
         "787",
         "348",
         "SUMO",
         "MQKEYLNLGDQSVNNGQYLLAVFHIVPAGGLNLADAATEIAAESSTGSNIKVSTATEFSKSLNALVYKIDEDKNLVWIAYPWRIFDRGGNVQNILTFIAGNIFGMSEIKACKLLDVWFPPEMLVQYDGPSYTLDDMRKYLGVYDSPILGTIIKPKIGLTSTEYAELCYDFWVGGGHFVKNDEPQANQDFCPYEKMVDAIRIAMDKAEKETGKKKVHSFNVSAADFDTMIRRCEYIINKMKPGSYAFLIDGITAGWMAVQTLRRRYPDVFIHFHRAGHGAFTRTENPIGYSVAVLTKFARLAGASGIHTGTAGVGKMAGDPEEDITAAHMALRLKAKGPFFEQVWTKIPEKDPDIVNMVEEEEAHNVVYENDSWRFIKKTCPIVSGGLNPVLLKEFIDVMGTIDFITTMGGGVHSHPEGTKAGAKALVQAYEAWKAGIDIEEYAKDNKELALAIEFYTKNRTNAHKL",
         null,
         "1",
         "348-SUMO",
         "MQKEYLNLGDQSVNNGQYLLAVFHIVPAGGLNLADAATEIAAESSTGSNIKVSTATEFSKSLNALVYKIDEDKNLVWIAYPWRIFDRGGNVQNILTFIAGNIFGMSEIKACKLLDVWFPPEMLVQYDGPSYTLDDMRKYLGVYDSPILGTIIKPKIGLTSTEYAELCYDFWVGGGHFVKNDEPQANQDFCPYEKMVDAIRIAMDKAEKETGKKKVHSFNVSAADFDTMIRRCEYIINKMKPGSYAFLIDGITAGWMAVQTLRRRYPDVFIHFHRAGHGAFTRTENPIGYSVAVLTKFARLAGASGIHTGTAGVGKMAGDPEEDITAAHMALRLKAKGPFFEQVWTKIPEKDPDIVNMVEEEEAHNVVYENDSWRFIKKTCPIVSGGLNPVLLKEFIDVMGTIDFITTMGGGVHSHPEGTKAGAKALVQAYEAWKAGIDIEEYAKDNKELALAIEFYTKNRTNAHKL"
        ],
        [
         "861",
         "366",
         "SUMO",
         "MSERYTDFVDLNYTPGENDLICTFRIEPADGISLEEAAGRVASESSTGTWTTLSTMPERVKKLKAKVFEIDGNIVKIAYPLDLFEPGNIPQILSSIAGNIFGMKAVKNLRLLDIHFPEELLKSFKGPQFGIEGVRELLGVHDRPLTATVPKPKVGLSAEEHAEVAYEAWVGGIDLIKDDENLTSQPFNPFEERVKKVMEARDKAEEETGEKKAYLVNITAPTEEMLRRAELVADYGGEYVMIDIITAGWSAVQTLRERCEDLGLAIHAHRAMHAAFTRNPKHGISMLVLAKLARLVGVDQLHTGTGVGKMEGDKEEVLAIADMLRQDWYNIKPVFPVASGGLHPGLVPDLIEIFGKDIIIQAGGGVHGHPDGTRAGAKALRQAIEAVMEGISLEEYAKEHPELAKALEKWGHVRPK",
         null,
         "1",
         "366-SUMO",
         "MSERYTDFVDLNYTPGENDLICTFRIEPADGISLEEAAGRVASESSTGTWTTLSTMPERVKKLKAKVFEIDGNIVKIAYPLDLFEPGNIPQILSSIAGNIFGMKAVKNLRLLDIHFPEELLKSFKGPQFGIEGVRELLGVHDRPLTATVPKPKVGLSAEEHAEVAYEAWVGGIDLIKDDENLTSQPFNPFEERVKKVMEARDKAEEETGEKKAYLVNITAPTEEMLRRAELVADYGGEYVMIDIITAGWSAVQTLRERCEDLGLAIHAHRAMHAAFTRNPKHGISMLVLAKLARLVGVDQLHTGTGVGKMEGDKEEVLAIADMLRQDWYNIKPVFPVASGGLHPGLVPDLIEIFGKDIIIQAGGGVHGHPDGTRAGAKALRQAIEAVMEGISLEEYAKEHPELAKALEKWGHVRPK"
        ],
        [
         "916",
         "380",
         "SUMO",
         "MSEWYTDFVDLNYTPGENELICVFRVEPADGISMEEAAGRVASESSTGTWTTLSTLPERIKRLMAKVFEIDGNIVKIAYPLDLFEEGNIPQLLSSIAGNIFGMKAIKNLRLLDIHFPAEYLKHFKGPQFGIEGVRELMGVHDRPLTATVPKPKVGFSAEEYAEVAYEAWVGGIDLIKDDENLTSQPFNRFEERVKKVMKARDKAEKETGEKKAYLVNITAPTEEMEKRAELVADYGGEYVMIDIVTAGWSAVQTLRERCEDLGLAIHAHRAMHAAFTRNPKHGISMLVLAKLARLVGVDQLHVGTGVGKMEGDKEEVMRIADILRQDWHNIKPVFPVSSGGLHPGLVPDLIEIFGKDIIIQAGGGVHGHPDGTRAGAKALRQAIEAVMEGISLEEYAKEHPELARALEKWGYVRPK",
         null,
         "1",
         "380-SUMO",
         "MSEWYTDFVDLNYTPGENELICVFRVEPADGISMEEAAGRVASESSTGTWTTLSTLPERIKRLMAKVFEIDGNIVKIAYPLDLFEEGNIPQLLSSIAGNIFGMKAIKNLRLLDIHFPAEYLKHFKGPQFGIEGVRELMGVHDRPLTATVPKPKVGFSAEEYAEVAYEAWVGGIDLIKDDENLTSQPFNRFEERVKKVMKARDKAEKETGEKKAYLVNITAPTEEMEKRAELVADYGGEYVMIDIVTAGWSAVQTLRERCEDLGLAIHAHRAMHAAFTRNPKHGISMLVLAKLARLVGVDQLHVGTGVGKMEGDKEEVMRIADILRQDWHNIKPVFPVSSGGLHPGLVPDLIEIFGKDIIIQAGGGVHGHPDGTRAGAKALRQAIEAVMEGISLEEYAKEHPELARALEKWGYVRPK"
        ],
        [
         "938",
         "382",
         "SUMO",
         "MSKVEWYLDFVDLDYTPGRDELIVEYYFEPNGVSPEEAAGRIASESSIGTWTTLWKLPEMAKRSMAKVFSLEKSGEGYIAKIAYPLTLFEEGNLVQLFSAIAGNIFGMKALKNLRLLDFHPPYEYLRHFKGPQFGVKGIMGVKDRPLTATVPKPKMGWSVEEYAEIAYELWSGGIDLLKDDENFTSFPFNRFEERVRKLYRVRDRVEAETGETKEYLINITGPAHVMEKRAELVAAEGGQYVMIDIVVVGWSALQYMREVAEDLGLAIHAHRAMHAAFTRNPRHGISMLVLAKAARMVGVDQIHTGTAVGKMAGDYEEVKRINDFLLSEWEHIKPVFPVASGGLHPGLMPELIRLFGKDLVIQAGGGVMGHPDGPRAGAKALRDAIEAAIEGVSLEEKAKESPELKKALEKWGYLKPK",
         null,
         "1",
         "382-SUMO",
         "MSKVEWYLDFVDLDYTPGRDELIVEYYFEPNGVSPEEAAGRIASESSIGTWTTLWKLPEMAKRSMAKVFSLEKSGEGYIAKIAYPLTLFEEGNLVQLFSAIAGNIFGMKALKNLRLLDFHPPYEYLRHFKGPQFGVKGIMGVKDRPLTATVPKPKMGWSVEEYAEIAYELWSGGIDLLKDDENFTSFPFNRFEERVRKLYRVRDRVEAETGETKEYLINITGPAHVMEKRAELVAAEGGQYVMIDIVVVGWSALQYMREVAEDLGLAIHAHRAMHAAFTRNPRHGISMLVLAKAARMVGVDQIHTGTAVGKMAGDYEEVKRINDFLLSEWEHIKPVFPVASGGLHPGLMPELIRLFGKDLVIQAGGGVMGHPDGPRAGAKALRDAIEAAIEGVSLEEKAKESPELKKALEKWGYLKPK"
        ],
        [
         "1020",
         "408",
         "SUMO",
         "TTAEETKKYQAGVRPYAETYYEPDYTPLDTDLLCAFRIQPKPGVDMVEAAAAVAAESSTGTWTEVWSNQLTDLDFYKARVYRIEGDIAYIAYPMDLFEEGSIVNIMSSIVGNVFGFKAVAALRLEDMRIPVALVKTFPGPNVGIYDERVRLNKWDRPLLGGTVKPKLGLSAKDYSTIIYECLVGGLDTTKDDENMNSQPFNRWRDRFLYVMEAVKKAEAETGEAKGHWLNVTAGSTEEMLRRTEYAAQLGSRYIMVDFLTAGFAASADVFKRAGELGLIVHCHRAMHAVFTRQKNHGIHFRVVAKWLRLAGGDHLHTGTVVGKLEGSWAETLDIVDLLRERYVPAGPTRGLYFDQDWAGLKTVWPVASGGIHVHHIPDLYKIYGNDAFWLFGGGTHGHPKGSRAGARANRVATEAIASGRTLEQAARDCPELRDAMELWRDIRFDVSE",
         null,
         "1",
         "408-SUMO",
         "TTAEETKKYQAGVRPYAETYYEPDYTPLDTDLLCAFRIQPKPGVDMVEAAAAVAAESSTGTWTEVWSNQLTDLDFYKARVYRIEGDIAYIAYPMDLFEEGSIVNIMSSIVGNVFGFKAVAALRLEDMRIPVALVKTFPGPNVGIYDERVRLNKWDRPLLGGTVKPKLGLSAKDYSTIIYECLVGGLDTTKDDENMNSQPFNRWRDRFLYVMEAVKKAEAETGEAKGHWLNVTAGSTEEMLRRTEYAAQLGSRYIMVDFLTAGFAASADVFKRAGELGLIVHCHRAMHAVFTRQKNHGIHFRVVAKWLRLAGGDHLHTGTVVGKLEGSWAETLDIVDLLRERYVPAGPTRGLYFDQDWAGLKTVWPVASGGIHVHHIPDLYKIYGNDAFWLFGGGTHGHPKGSRAGARANRVATEAIASGRTLEQAARDCPELRDAMELWRDIRFDVSE"
        ],
        [
         "1067",
         "424",
         "SUMO",
         "VTTLTAAPTAELSEKYKAGVRPYAADYYVPDYVPLDTDLLCAFRIQPKPGVDMIEAAAAVAAESSTGTWTEVWSNQLTDLDFYKAKVYRIEGDIAYIAYPMDLFEENSVVNIMSSIVGNVFGFKAVSALRLEDMRIPVALVKTFPGPNVGIYDERVWSNKWDRPLLGGTVKPKLGLSPKAYSTIIYECLVGGLDTTKDDENMNSQPFSRWRDRFMYGQEAVEKAMAETGEFKGHWHNVTAGSTEESLRRLEYVAELGSRMCMFDFLTAGFAASADVFKRAGELGLIVHCHRAMHAVFTRQKNHGIHMRVVAKWLRLAGGDHLHTGTVVGKLEGSWNETLGIIDLLRERVVPANPERGLYFEQDFAGLKTTWPVASGGIHVHHIPDLYKIYGNDAFWLFGGGTHGHPRGSRAGARANRVATEAIASGKTLEQAARTCPELREAMELWGNVKFEVSE",
         null,
         "1",
         "424-SUMO",
         "VTTLTAAPTAELSEKYKAGVRPYAADYYVPDYVPLDTDLLCAFRIQPKPGVDMIEAAAAVAAESSTGTWTEVWSNQLTDLDFYKAKVYRIEGDIAYIAYPMDLFEENSVVNIMSSIVGNVFGFKAVSALRLEDMRIPVALVKTFPGPNVGIYDERVWSNKWDRPLLGGTVKPKLGLSPKAYSTIIYECLVGGLDTTKDDENMNSQPFSRWRDRFMYGQEAVEKAMAETGEFKGHWHNVTAGSTEESLRRLEYVAELGSRMCMFDFLTAGFAASADVFKRAGELGLIVHCHRAMHAVFTRQKNHGIHMRVVAKWLRLAGGDHLHTGTVVGKLEGSWNETLGIIDLLRERVVPANPERGLYFEQDFAGLKTTWPVASGGIHVHHIPDLYKIYGNDAFWLFGGGTHGHPRGSRAGARANRVATEAIASGKTLEQAARTCPELREAMELWGNVKFEVSE"
        ],
        [
         "1152",
         "501",
         "SUMO",
         "MSKANSNSKSQEKALFDAGVKEYSEAGRYYYDIGYQPSDTQVLAAFRITPQEGVPWEEAAAAVAAESSFATWTTVWSDYLVDPSRYCARTYEIKPVPGRDDQFMAYIAYPLDLFEEGSMPNLMSSLVGNVFGFKPLRALRLEDIYFPPALLKTFQGPPHGIQVERDRLNKYGRPLLGATMKPKLGLSAKNYGRLVYEALRGGLDFTKDDENITSQPFMRWRDRYEFVMEAVHKAEAETGERKGHYLNVTAGTMEEMYRRAEFAKELGSRIIMVDYLIVGFTAFTSLSKWCRENGMLLHAHRAMHSVIDRQPNHGIHWRVLAKWCRIVGADHLHNGTVVGKLEGDRASTIGINEMLREDYVKKEECPGFHFDQPWLSMPGVFPVASGGIHVWHMPELVSIFGDDSILQFGGGTVGHPWGSAAGATANRVALEAVVQARNEGRDLVAEGPDILKEAARHSPELRAAMETWKGITFDYETVDKLAVV",
         null,
         "1",
         "501-SUMO",
         "MSKANSNSKSQEKALFDAGVKEYSEAGRYYYDIGYQPSDTQVLAAFRITPQEGVPWEEAAAAVAAESSFATWTTVWSDYLVDPSRYCARTYEIKPVPGRDDQFMAYIAYPLDLFEEGSMPNLMSSLVGNVFGFKPLRALRLEDIYFPPALLKTFQGPPHGIQVERDRLNKYGRPLLGATMKPKLGLSAKNYGRLVYEALRGGLDFTKDDENITSQPFMRWRDRYEFVMEAVHKAEAETGERKGHYLNVTAGTMEEMYRRAEFAKELGSRIIMVDYLIVGFTAFTSLSKWCRENGMLLHAHRAMHSVIDRQPNHGIHWRVLAKWCRIVGADHLHNGTVVGKLEGDRASTIGINEMLREDYVKKEECPGFHFDQPWLSMPGVFPVASGGIHVWHMPELVSIFGDDSILQFGGGTVGHPWGSAAGATANRVALEAVVQARNEGRDLVAEGPDILKEAARHSPELRAAMETWKGITFDYETVDKLAVV"
        ],
        [
         "1171",
         "509",
         "SUMO",
         "MQTQTQTKAMYQAGVKDYRETYYDPDYTPKDTDILAAFRVTPQPGVPPEEAAAAVAAESSTGTWTTVWTDLLTDLDRYKGRCYRIEPVPGEDDQYIAYVAYPLDLFEEGSVVNLLTSIVGNVFGFKALRALRLEDLRIPVAYVKTFQGPPHGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFLFVAEAIHKAEAETGERKGHYLNVTAPTCEEMYKRAEFAKELGMPIIMHDYLTGGFTANTSLAKWCRDNGMLLHIHRAMHAVIDRQKNHGIHFRVLAKCLRLSGGDHLHSGTVVGKLEGDREATLGFVDLMREDYIPQDRSRGIYFDQDWASMPGVFPVASGGIHVWHMPALVSIFGDDSVLQFGGGTLGHPWGNAAGATANRVALEACVQARNEGRDLAREGKDILREAARHSPELAAALETWKEIKFEFETVDTLDVASK",
         null,
         "1",
         "509-SUMO",
         "MQTQTQTKAMYQAGVKDYRETYYDPDYTPKDTDILAAFRVTPQPGVPPEEAAAAVAAESSTGTWTTVWTDLLTDLDRYKGRCYRIEPVPGEDDQYIAYVAYPLDLFEEGSVVNLLTSIVGNVFGFKALRALRLEDLRIPVAYVKTFQGPPHGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFLFVAEAIHKAEAETGERKGHYLNVTAPTCEEMYKRAEFAKELGMPIIMHDYLTGGFTANTSLAKWCRDNGMLLHIHRAMHAVIDRQKNHGIHFRVLAKCLRLSGGDHLHSGTVVGKLEGDREATLGFVDLMREDYIPQDRSRGIYFDQDWASMPGVFPVASGGIHVWHMPALVSIFGDDSVLQFGGGTLGHPWGNAAGATANRVALEACVQARNEGRDLAREGKDILREAARHSPELAAALETWKEIKFEFETVDTLDVASK"
        ],
        [
         "1229",
         "603",
         "SUMO",
         "MMAKTYNAGVKEYRQTYWMPDYTPLDTDILACFKITPQPGVPREEAAAAVAAESSTGTWTTVWTDLLTDMDYYKGRAYRIEDVPGDDTCFYAFIAYPIDLFEEGSVVNVFTSLVGNVFGFKAVRALRLEDVRFPIAYVKTCGGPPNGIQVERDIMNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRQRFDFVMEAIHKAERETGERKGHYLNVTAPTPEEMYKRAEYAKEIGAPIIMHDYITGGFCANTGLANWCRDNGMLLHIHRAMHAVIDRNPHHGIHFRVLAKILRLSGGDHLHTGTVVGKLEGDREATLGWIDLLRESFIPEDRSRGIFFDQDWGSMPGVFAVASGGIHVWHMPALVTIFGDDSVLQFGGGTLGHPWGNAAGAAANRVALEACVKARNEGRELEKEGKEILTKAAQHSPELKIAMETWKEIKFEFDTVDKLDVAHK",
         null,
         "1",
         "603-SUMO",
         "MMAKTYNAGVKEYRQTYWMPDYTPLDTDILACFKITPQPGVPREEAAAAVAAESSTGTWTTVWTDLLTDMDYYKGRAYRIEDVPGDDTCFYAFIAYPIDLFEEGSVVNVFTSLVGNVFGFKAVRALRLEDVRFPIAYVKTCGGPPNGIQVERDIMNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRQRFDFVMEAIHKAERETGERKGHYLNVTAPTPEEMYKRAEYAKEIGAPIIMHDYITGGFCANTGLANWCRDNGMLLHIHRAMHAVIDRNPHHGIHFRVLAKILRLSGGDHLHTGTVVGKLEGDREATLGWIDLLRESFIPEDRSRGIFFDQDWGSMPGVFAVASGGIHVWHMPALVTIFGDDSVLQFGGGTLGHPWGNAAGAAANRVALEACVKARNEGRELEKEGKEILTKAAQHSPELKIAMETWKEIKFEFDTVDKLDVAHK"
        ],
        [
         "1278",
         "340",
         "SUMO",
         "MIIEELVQSLNPKQQAYVNLDLPDPRNGEYLLAVFHLIPGGGLNILQAAAEVAAESSTGTNFKVNTETPFSRTMNALVYKIDLEKNLVWIAYPWRLFDRGGNVQNILTYIVGNILGMKEIKALKLLDVWFPPSMLEQYDGPSYTLDDMRKYLGVYDRPILGTIIKPKMGLTSAEYAEVCYDFWVGGGDFVKNDEPQANQDFCPYDKMVKHVKEAMDKAVKETGKKKVHSFNVSAADFDTMIERCEMIRNAGFEPGSYAFLIDGITAGWMAVQTLRRRYPDVFIHFHRAGHGAFTRPENPIGFSVLVLSKFARLAGASGIHTGTAGVGKMAGSPEEDVTAAHNILKLKAKGHFFEQSWSKIPETDKDAINMVQEDTAHHVILEDDSWRGMKKCCPIVSGGLNPVLLKPFIDVMGNVDFITTMGAGVHAHPGGTKAGAKALVQACEAYKKGIDIEEYAKDHKELAQAIEFFSKKKKKA",
         null,
         "1",
         "340-SUMO",
         "MIIEELVQSLNPKQQAYVNLDLPDPRNGEYLLAVFHLIPGGGLNILQAAAEVAAESSTGTNFKVNTETPFSRTMNALVYKIDLEKNLVWIAYPWRLFDRGGNVQNILTYIVGNILGMKEIKALKLLDVWFPPSMLEQYDGPSYTLDDMRKYLGVYDRPILGTIIKPKMGLTSAEYAEVCYDFWVGGGDFVKNDEPQANQDFCPYDKMVKHVKEAMDKAVKETGKKKVHSFNVSAADFDTMIERCEMIRNAGFEPGSYAFLIDGITAGWMAVQTLRRRYPDVFIHFHRAGHGAFTRPENPIGFSVLVLSKFARLAGASGIHTGTAGVGKMAGSPEEDVTAAHNILKLKAKGHFFEQSWSKIPETDKDAINMVQEDTAHHVILEDDSWRGMKKCCPIVSGGLNPVLLKPFIDVMGNVDFITTMGAGVHAHPGGTKAGAKALVQACEAYKKGIDIEEYAKDHKELAQAIEFFSKKKKKA"
        ],
        [
         "1379",
         "365",
         "SUMO",
         "MSKRYTDFVDLNYTPKENDLICTFHIEPADGVDLEEAAGRVAAESSTGTWTDVSTMPEIVEKLKARVYEIDESGNIVKIAYPLDLFEPGNIPQILSSIAGNIFGMKAVKNLRLLDIHFPEELVKSFKGPKFGIEGVRELLGVYDRPLVGTIVKPKVGLSAEEHAEVAYEAWVGGIDLIKDDENLTSQPFNPFEERVKKVMEARDKAEEETGEKKVYLVNITAPTEEMIRRAELVADLGGKYVMIDIITAGFSAVQSLREEDLGLAIHAHRAMHAAFTRNPKHGISMLVLAKLARLVGVDQLHIGTGVGKMEGDKEEVLAIRDALRQDWYNIKPVFPVASGGLHPGLVPDLIDIFGKDIIIQAGGGVHGHPDGTRAGAKALRQAIEAVMEGISLEEYAKEHPELAKALEKWGHVRPK",
         null,
         "1",
         "365-SUMO",
         "MSKRYTDFVDLNYTPKENDLICTFHIEPADGVDLEEAAGRVAAESSTGTWTDVSTMPEIVEKLKARVYEIDESGNIVKIAYPLDLFEPGNIPQILSSIAGNIFGMKAVKNLRLLDIHFPEELVKSFKGPKFGIEGVRELLGVYDRPLVGTIVKPKVGLSAEEHAEVAYEAWVGGIDLIKDDENLTSQPFNPFEERVKKVMEARDKAEEETGEKKVYLVNITAPTEEMIRRAELVADLGGKYVMIDIITAGFSAVQSLREEDLGLAIHAHRAMHAAFTRNPKHGISMLVLAKLARLVGVDQLHIGTGVGKMEGDKEEVLAIRDALRQDWYNIKPVFPVASGGLHPGLVPDLIDIFGKDIIIQAGGGVHGHPDGTRAGAKALRQAIEAVMEGISLEEYAKEHPELAKALEKWGHVRPK"
        ],
        [
         "1447",
         "387",
         "SUMO",
         "MSEKFDEIYLEFVDKNYKPGKDEIIAVFRVTPAEGISIEDAAGRVAAESSVGTWTTLSTLPERVKKLKAKAYEFHDLGDGSWIVRIAYPVELFEEGNIPNLLSSIAGNIFGMKAIKGLRLEDIYFPPKYLKNFKGPNKGIEGVREILGVKDRPIVATVPKPKVGYSPEEYAKVAYELLVGGIDLIKDDENLTSQPFCRFEERLKKVMKAIDKAEKETGEKKAYLANITAPIREMEKRLKLVADYGNKYVMIDVLTAGWSALQHIRELAEEYGLAIHGHRAMHAAFTRNPKHGISMFVLAKLARMVGVDQLHVGTAGVGKMEGGKREVLRHARILREQYYRPDEGDLFHLEQEWHNIKPVFPVSSGGLHPGTLPEVIEVLGKDIILQVGGGVLGHPDGPRAGARAVRQAIEAVMKGISLDEYAKEHRELARALEKWGYVRPV",
         null,
         "1",
         "387-SUMO",
         "MSEKFDEIYLEFVDKNYKPGKDEIIAVFRVTPAEGISIEDAAGRVAAESSVGTWTTLSTLPERVKKLKAKAYEFHDLGDGSWIVRIAYPVELFEEGNIPNLLSSIAGNIFGMKAIKGLRLEDIYFPPKYLKNFKGPNKGIEGVREILGVKDRPIVATVPKPKVGYSPEEYAKVAYELLVGGIDLIKDDENLTSQPFCRFEERLKKVMKAIDKAEKETGEKKAYLANITAPIREMEKRLKLVADYGNKYVMIDVLTAGWSALQHIRELAEEYGLAIHGHRAMHAAFTRNPKHGISMFVLAKLARMVGVDQLHVGTAGVGKMEGGKREVLRHARILREQYYRPDEGDLFHLEQEWHNIKPVFPVSSGGLHPGTLPEVIEVLGKDIILQVGGGVLGHPDGPRAGARAVRQAIEAVMKGISLDEYAKEHRELARALEKWGYVRPV"
        ],
        [
         "1565",
         "436",
         "SUMO",
         "MSQTTDEQKAQFSAGVREYREMGYYDPNYTPKDTDILAAFRVTPQPGVPPEEAAAAVAGESSTATWTVVWTDLLTNLERYQAKCYRIEPVPGTEDQYIAYIAYDLDLFEEGSIANLTSSIVGNVFGFKALKALRLEDMRIPVAYVKTFQGPPHGIQVERDLLNKYGRPLLGATVKPKLGLSAKNYGRVVYEALRGGLDFTKDDENINSQPFMRWRDRFLYCMEAVHKAEAETGERKGHYLNVTAPTMEEMYERAEFAKELGSPIIMVDFLTVGFTAHTSLSKWCRKNGMLLHVHRAMHATIDRQKNHGISFRVLAKWLRLAGGDHLHTGTVVGKLEGDRNMTQGYVDLLREDYVPADPSRGLYFDQDWASLPAVMPVASGGIHVGHMPQLVDIFGDDVVLQFGGGTIGHPWGIAAGATANRVALEAVVQARNEGRDLLAEGQEILKEAAKHSPELRAALDTWKDITFDYESTDTPDVVATPST",
         null,
         "1",
         "436-SUMO",
         "MSQTTDEQKAQFSAGVREYREMGYYDPNYTPKDTDILAAFRVTPQPGVPPEEAAAAVAGESSTATWTVVWTDLLTNLERYQAKCYRIEPVPGTEDQYIAYIAYDLDLFEEGSIANLTSSIVGNVFGFKALKALRLEDMRIPVAYVKTFQGPPHGIQVERDLLNKYGRPLLGATVKPKLGLSAKNYGRVVYEALRGGLDFTKDDENINSQPFMRWRDRFLYCMEAVHKAEAETGERKGHYLNVTAPTMEEMYERAEFAKELGSPIIMVDFLTVGFTAHTSLSKWCRKNGMLLHVHRAMHATIDRQKNHGISFRVLAKWLRLAGGDHLHTGTVVGKLEGDRNMTQGYVDLLREDYVPADPSRGLYFDQDWASLPAVMPVASGGIHVGHMPQLVDIFGDDVVLQFGGGTIGHPWGIAAGATANRVALEAVVQARNEGRDLLAEGQEILKEAAKHSPELRAALDTWKDITFDYESTDTPDVVATPST"
        ],
        [
         "1594",
         "607",
         "SUMO",
         "MATKTYDAGVKDYALTYWTPDYVPLDSDLLACFKVTPQPGVPREEAAAAVAAESSTGTWTTVWSDLLTDLDYYKGRAYRIEDVPGDKESFYAFVAYPIDLFEEGSIVNVLTSLVGNVFGFKAVRHLRLEDIRFPLHYVKTCGGPPNGIQVERDRMDKYGRPFLGATVKPKLGLSAKNYGRAVYEMLRGGLDFTKDDENVNSQPFMRWQNRFEFVMEAVRKAQEETGERKGHYLNVTAPTCEEMFKRAEFAKELGAPIIMHDFLTGGFTANTSLANWCRDNGMLLHIHRAMHAVIDRHPKHGIHFRVLAKCLRLSGGDHLHTGTVVGKLEGDRQSTLGFVDLLRESFVPEDRSRGLFFDQDWGGMPGVMAVASGGIHVWHIPALVTIFGDDSVLQFGGGTQGHPWGNAAGAAANRVATEACVKARNEGVEVEKEAREILTEAARHSPELAAAMETWKEIKFEFDVVDKLDVA",
         null,
         "1",
         "607-SUMO",
         "MATKTYDAGVKDYALTYWTPDYVPLDSDLLACFKVTPQPGVPREEAAAAVAAESSTGTWTTVWSDLLTDLDYYKGRAYRIEDVPGDKESFYAFVAYPIDLFEEGSIVNVLTSLVGNVFGFKAVRHLRLEDIRFPLHYVKTCGGPPNGIQVERDRMDKYGRPFLGATVKPKLGLSAKNYGRAVYEMLRGGLDFTKDDENVNSQPFMRWQNRFEFVMEAVRKAQEETGERKGHYLNVTAPTCEEMFKRAEFAKELGAPIIMHDFLTGGFTANTSLANWCRDNGMLLHIHRAMHAVIDRHPKHGIHFRVLAKCLRLSGGDHLHTGTVVGKLEGDRQSTLGFVDLLRESFVPEDRSRGLFFDQDWGGMPGVMAVASGGIHVWHIPALVTIFGDDSVLQFGGGTQGHPWGNAAGAAANRVATEACVKARNEGVEVEKEAREILTEAARHSPELAAAMETWKEIKFEFDVVDKLDVA"
        ],
        [
         "1612",
         "E7",
         "SUMO",
         "MHEHFDSIYLEFVDESYKPGKDEVIAVFRVTPAQGISIKDAAGRIAAESSVGTWTTLSVKPSWFEKLKAKAYRFHDLGDGSWLVWVAYPVELFEEGSIPNFASSILGNIFGMKAIAGLRVEDVYFPPSYLETFPGPNKGIQGVREILGIKDRPILATVPKPKLGYTPEEYGRVAYEILIGGIDLVKDDENFASQPFCRFEARLKEVMKAIDRAEKETGERKGYLANVTAPIREMEKRIKLVADYGNKFIMIDFLTAGWAALQHARELAEEYDLAIHGHRAFHAAFTRNPKHGVSMFLVAKLARMAGVDHVHVGTPGVGKMDAKTREVLEHTRIVREQYYRPKEGDLFHLEQPWSNIKPVFPVASGGLHPGTLPEVIRVMGKDIIMQVGGGVLGHPDGPEAGARAVRQAVEAAMKGISLDEYAREHRELARALEKWGYVRPV",
         null,
         "1",
         "E7-SUMO",
         "MHEHFDSIYLEFVDESYKPGKDEVIAVFRVTPAQGISIKDAAGRIAAESSVGTWTTLSVKPSWFEKLKAKAYRFHDLGDGSWLVWVAYPVELFEEGSIPNFASSILGNIFGMKAIAGLRVEDVYFPPSYLETFPGPNKGIQGVREILGIKDRPILATVPKPKLGYTPEEYGRVAYEILIGGIDLVKDDENFASQPFCRFEARLKEVMKAIDRAEKETGERKGYLANVTAPIREMEKRIKLVADYGNKFIMIDFLTAGWAALQHARELAEEYDLAIHGHRAFHAAFTRNPKHGVSMFLVAKLARMAGVDHVHVGTPGVGKMDAKTREVLEHTRIVREQYYRPKEGDLFHLEQPWSNIKPVFPVASGGLHPGTLPEVIRVMGKDIIMQVGGGVLGHPDGPEAGARAVRQAVEAAMKGISLDEYAREHRELARALEKWGYVRPV"
        ],
        [
         "1656",
         "361",
         "SUMO",
         "MDQSNRYADLSLKEADLIKGGRHVLCAYIMKPKAGYGYLETAAHFAAESSTGTNVEVSTTDDFTKGVDALVYEIDEAKELMKIAYPVELFDRNIIDGRAMIASFLTLTIGNNQGMGDVEYAKMYDFYVPPSYLRLFDGPAVNIADMWRILGRPVVNGGMVVGTIIKPKLGLRPKPFAEACYQFWLGGDFIKNDEPQGNQVFCPMKETIPLVADAMRRAQDETGEAKLFSANITADDPAEMIARGEYILETFGPNASHVAFLVDGYVAGPTAVTTARRNFPKQFLHYHRAGHGAVTSPQSKRGYTAFVHTKMSRLLGASGIHVGTMGYGKMEGDASDKIIAYMLERDSADGPYYHQEWAGMKPTTPIISGGMNALRLPGFFENLGHSNVIQTAGGGSFGHKDGPAAGAVSLRQAHEAWKQGADLVEYAKEHKEFARAFESFPKDADKIYPGWREKLGVHA",
         null,
         "1",
         "361-SUMO",
         "MDQSNRYADLSLKEADLIKGGRHVLCAYIMKPKAGYGYLETAAHFAAESSTGTNVEVSTTDDFTKGVDALVYEIDEAKELMKIAYPVELFDRNIIDGRAMIASFLTLTIGNNQGMGDVEYAKMYDFYVPPSYLRLFDGPAVNIADMWRILGRPVVNGGMVVGTIIKPKLGLRPKPFAEACYQFWLGGDFIKNDEPQGNQVFCPMKETIPLVADAMRRAQDETGEAKLFSANITADDPAEMIARGEYILETFGPNASHVAFLVDGYVAGPTAVTTARRNFPKQFLHYHRAGHGAVTSPQSKRGYTAFVHTKMSRLLGASGIHVGTMGYGKMEGDASDKIIAYMLERDSADGPYYHQEWAGMKPTTPIISGGMNALRLPGFFENLGHSNVIQTAGGGSFGHKDGPAAGAVSLRQAHEAWKQGADLVEYAKEHKEFARAFESFPKDADKIYPGWREKLGVHA"
        ],
        [
         "1803",
         "650",
         "SUMO",
         "MAEDRLTATYHIEGGADIEKAAQAIAAEQSTGTWTRVPAETEELRERHAARVEDIEELGGGGGRVTIAYPLENFGPNLPQLLSTLMGNLFGMSALKGVRLLDIQFPPSFLKSFPGPKFGIEGVRKLTGVYDRPLIGTIIKPKIGLSPEELAEVAHQLAEGGIDFIKDDEILADPPFCPFEERVKAVMEALDKAEEETGKKTLYAVNITAEADEMLRRAELAVDLGATAVMINVLTVGLSALQALREHVNLPIHAHRAGHGAFTRNPEHGISFRVLAKLMRLAGADHLHVGTFGGKMAEPEDEVLQTAHALRQPWYDLKPVFPVFSGGMHPGMVPPLLKRFGTDIILAAGGGIHGHPDGPRAGARAFRQALEAAMEGVPLEEYAKDHPELARALEKWGPAR",
         null,
         "0",
         "650-SUMO",
         "MAEDRLTATYHIEGGADIEKAAQAIAAEQSTGTWTRVPAETEELRERHAARVEDIEELGGGGGRVTIAYPLENFGPNLPQLLSTLMGNLFGMSALKGVRLLDIQFPPSFLKSFPGPKFGIEGVRKLTGVYDRPLIGTIIKPKIGLSPEELAEVAHQLAEGGIDFIKDDEILADPPFCPFEERVKAVMEALDKAEEETGKKTLYAVNITAEADEMLRRAELAVDLGATAVMINVLTVGLSALQALREHVNLPIHAHRAGHGAFTRNPEHGISFRVLAKLMRLAGADHLHVGTFGGKMAEPEDEVLQTAHALRQPWYDLKPVFPVFSGGMHPGMVPPLLKRFGTDIILAAGGGIHGHPDGPRAGARAFRQALEAAMEGVPLEEYAKDHPELARALEKWGPAR"
        ],
        [
         "1896",
         "494",
         "SUMO",
         "MQTNSQTKAMFQAGVREYRETYYDPGYTPKDTDILAAFRVTPQPGVPPEEAAAAVAAESSTGTWTTVWTDLLTDLERYQARCYRIEPVPGQEDQYIAYIAYPLDLFEEGSIVNLMSSIVGNVFGFKALRALRLEDLRIPVAYVKTFQGPPHGIQVERDRLNKYGRPLLGATIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENINSQPFMRWRDRFLFVMEAVHKAEAETGERKGHYLNVTAPTMEEMYERAEFAKELGSPIIMVDYLTVGFTAHTSLSKWCRKNGMLLHVHRAMHAVIDRQKNHGIHFRVLAKWLRLAGGDHLHTGTVVGKLEGDRAATLGIVDLLREDYVPADPSRGIYFDQDWASLPAVFPVASGGIHVWHMPALVSIFGDDAVLQFGGGTLGHPWGNAAGATANRVALEAVVQARNEGRDLVAEGQEILKEAARHSPELRAALETWKDIKFDFETVDTLDVVAAKA",
         null,
         "1",
         "494-SUMO",
         "MQTNSQTKAMFQAGVREYRETYYDPGYTPKDTDILAAFRVTPQPGVPPEEAAAAVAAESSTGTWTTVWTDLLTDLERYQARCYRIEPVPGQEDQYIAYIAYPLDLFEEGSIVNLMSSIVGNVFGFKALRALRLEDLRIPVAYVKTFQGPPHGIQVERDRLNKYGRPLLGATIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENINSQPFMRWRDRFLFVMEAVHKAEAETGERKGHYLNVTAPTMEEMYERAEFAKELGSPIIMVDYLTVGFTAHTSLSKWCRKNGMLLHVHRAMHAVIDRQKNHGIHFRVLAKWLRLAGGDHLHTGTVVGKLEGDRAATLGIVDLLREDYVPADPSRGIYFDQDWASLPAVFPVASGGIHVWHMPALVSIFGDDAVLQFGGGTLGHPWGNAAGATANRVALEAVVQARNEGRDLVAEGQEILKEAARHSPELRAALETWKDIKFDFETVDTLDVVAAKA"
        ],
        [
         "1947",
         "E1",
         "SUMO",
         "MAVKKYSAGVKEYRQTYWMPEYTPLDSDILACFKITPQPGVDREEAAAAVAAESSTGTWTTVWTDLLTDMDYYKGRAYRIEDVPGDDAAFYAFIAYPIDLFEEGSVVNVFTSLVGNVFGFKAVRGLRLEDVRFPLAYVKTCGGPPHGIQVERDKMNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENINSQPFMRWRDRFLFVQDATETAEAQTGERKGHYLNVTAPTPEEMYKRAEFAKEIGAPIIMHDYITGGFTANTGLAKWCQDNGVLLHIHRAMHAVIDRNPNHGIHFRVLTKILRLSGGDHLHTGTVVGKLEGDRASTLGWIDLLRESFIPEDRSRGIFFDQDWGSMPGVFAVASGGIHVWHMPALVNIFGDDSVLQFGGGTLGHPWGNAAGAAANRVALEACVEARNQGRDIEKEGKEILTAAAQHSPELKIAMETWKEIKFEFDTVDKLDTQNR",
         null,
         "0",
         "E1-SUMO",
         "MAVKKYSAGVKEYRQTYWMPEYTPLDSDILACFKITPQPGVDREEAAAAVAAESSTGTWTTVWTDLLTDMDYYKGRAYRIEDVPGDDAAFYAFIAYPIDLFEEGSVVNVFTSLVGNVFGFKAVRGLRLEDVRFPLAYVKTCGGPPHGIQVERDKMNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENINSQPFMRWRDRFLFVQDATETAEAQTGERKGHYLNVTAPTPEEMYKRAEFAKEIGAPIIMHDYITGGFTANTGLAKWCQDNGVLLHIHRAMHAVIDRNPNHGIHFRVLTKILRLSGGDHLHTGTVVGKLEGDRASTLGWIDLLRESFIPEDRSRGIFFDQDWGSMPGVFAVASGGIHVWHMPALVNIFGDDSVLQFGGGTLGHPWGNAAGAAANRVALEACVEARNQGRDIEKEGKEILTAAAQHSPELKIAMETWKEIKFEFDTVDKLDTQNR"
        ],
        [
         "1975",
         "406",
         "SUMO",
         "MPAVQPSATAAEARPQFQAGVRPYRETYYDPDYTPRETDILCAFRIQPKPGVDLVEAAAAVAAESSTGTWTEVWSNALTDLERYKARCYRIEGDIAYIAYPLDLFEEGSIVNIMSSIVGNVFGFKAVAALRLEDMRIPVALVKTFPGPPTGIENERARLNKYGRPLLGGTVKPKLGLSAKDYARVVYECLVGGLDTTKDDENMNSQPFNRWRDRFLFVMEAVKKAEAETGEAKGHWLNVTAATTEEMLERAEYAAQLGSRYIMTDYLTMGFAAHQSVVKRAAKLGLMVHVHRAMHAVIDRQKNHGISFRVLAKWLRLAGGDHLHTGTVVGKLEGDRAATMAIADMLREDFVPANPAVGLYFDQDWASLKTVFPVASGGIHVHHIPALYEIYGNDAFWLFGGGTHGHPGGSRAGARANRVATEAVAQGRTLEQAARDCPELREAMELWKDIRFDD",
         null,
         "1",
         "406-SUMO",
         "MPAVQPSATAAEARPQFQAGVRPYRETYYDPDYTPRETDILCAFRIQPKPGVDLVEAAAAVAAESSTGTWTEVWSNALTDLERYKARCYRIEGDIAYIAYPLDLFEEGSIVNIMSSIVGNVFGFKAVAALRLEDMRIPVALVKTFPGPPTGIENERARLNKYGRPLLGGTVKPKLGLSAKDYARVVYECLVGGLDTTKDDENMNSQPFNRWRDRFLFVMEAVKKAEAETGEAKGHWLNVTAATTEEMLERAEYAAQLGSRYIMTDYLTMGFAAHQSVVKRAAKLGLMVHVHRAMHAVIDRQKNHGISFRVLAKWLRLAGGDHLHTGTVVGKLEGDRAATMAIADMLREDFVPANPAVGLYFDQDWASLKTVFPVASGGIHVHHIPALYEIYGNDAFWLFGGGTHGHPGGSRAGARANRVATEAVAQGRTLEQAARDCPELREAMELWKDIRFDD"
        ],
        [
         "1985",
         "411",
         "SUMO",
         "MTTITAAPTAEVSEKYKAGVRPYAADYYVPDYVPLDTDLLCAFRIQPKPGVDMIEAAAAVAAESSTGTWTEVWSNQLTDLDFYKAKVYRIEGDIAYIAYPMDLFEENSIVNIMSSIVGNVFGFKAVSALRLEDMRIPVALVKTFPGPNVGIYDERVRLNKWDRPLLGGTVKPKLGLSAKDYSTIIYECLVGGLDTTKDDENMNSQPFNRWRDRFLYGMEAVKKAEAETGEAKGHWFNVTAGSTEESLRRLEYVAALGSRYIMFDFLTAGFAASADVFKRAGELGLIVHCHRAMHAVFTRQKNHGIHMRVVAKWLRLAGGDHLHTGTVVGKLEGSWNETLGIIDLLRERVIPANPERGLYFEQDFAGLKTVWPVASGGIHVHHIPDLYKIYGNDAFWLFGGGTHGHPRGSRAGARANRVATEAIASGKTLEQAARTCPELREAMELWGNVKFEVSE",
         null,
         "1",
         "411-SUMO",
         "MTTITAAPTAEVSEKYKAGVRPYAADYYVPDYVPLDTDLLCAFRIQPKPGVDMIEAAAAVAAESSTGTWTEVWSNQLTDLDFYKAKVYRIEGDIAYIAYPMDLFEENSIVNIMSSIVGNVFGFKAVSALRLEDMRIPVALVKTFPGPNVGIYDERVRLNKWDRPLLGGTVKPKLGLSAKDYSTIIYECLVGGLDTTKDDENMNSQPFNRWRDRFLYGMEAVKKAEAETGEAKGHWFNVTAGSTEESLRRLEYVAALGSRYIMFDFLTAGFAASADVFKRAGELGLIVHCHRAMHAVFTRQKNHGIHMRVVAKWLRLAGGDHLHTGTVVGKLEGSWNETLGIIDLLRERVIPANPERGLYFEQDFAGLKTVWPVASGGIHVHHIPDLYKIYGNDAFWLFGGGTHGHPRGSRAGARANRVATEAIASGKTLEQAARTCPELREAMELWGNVKFEVSE"
        ],
        [
         "2016",
         "338",
         "SUMO",
         "MQKEYINLKLKDPKNGEYLLAVFHLVPAGGLDLLDAASEVAAESSTGSNVKVSTATEFSKSLNALVYKIDKEKNLVWIAYPWRIFDRGGNVQNILTYIAGNIFGMSDIKALKLLDVWFPPEMLKQYDGPSYTIDDMRKYLGVYDRPILGTIIKPKIGLKPEEFAEVCYQFWVGGGDFVKNDEPQANQDFCPYEKMVDAIREAMDKAEKETGKKKVHSFNISAADFDTMIKRAEYIINKMKPGSYAFLIDGITAGWTAVQTLRRRYPDVFIHFHRAGHGAFTRPENPIGYSVLVLTKFARLAGASGIHTGTAGVGKMAGDAEEDVTAAHMALRAKAKGPFFEQDWYGMKPTCPIVSGGLNPVLLKPFIDVMGNVDFITTMGGGVHSHPGGTKAGAKALVQACEAWKKGIDIEEYAKDHKELAQAIEFYSKKKEKTHKY",
         null,
         "1",
         "338-SUMO",
         "MQKEYINLKLKDPKNGEYLLAVFHLVPAGGLDLLDAASEVAAESSTGSNVKVSTATEFSKSLNALVYKIDKEKNLVWIAYPWRIFDRGGNVQNILTYIAGNIFGMSDIKALKLLDVWFPPEMLKQYDGPSYTIDDMRKYLGVYDRPILGTIIKPKIGLKPEEFAEVCYQFWVGGGDFVKNDEPQANQDFCPYEKMVDAIREAMDKAEKETGKKKVHSFNISAADFDTMIKRAEYIINKMKPGSYAFLIDGITAGWTAVQTLRRRYPDVFIHFHRAGHGAFTRPENPIGYSVLVLTKFARLAGASGIHTGTAGVGKMAGDAEEDVTAAHMALRAKAKGPFFEQDWYGMKPTCPIVSGGLNPVLLKPFIDVMGNVDFITTMGGGVHSHPGGTKAGAKALVQACEAWKKGIDIEEYAKDHKELAQAIEFYSKKKEKTHKY"
        ],
        [
         "2027",
         "500",
         "SUMO",
         "MSKGKSNSNSQQKALFDAGVKEYSEAGRYYYDPGYVPKDTEVLAAFRITPQPGVPWEEAAAAVAAESSSGTWTTVWSDLLTDQARYAARTYKIEPVPGREDQFMAYIAYPLDLFEEGSLPNLMSSIVGNVFGFKALRALRLEDIYIPPALLKTFQGPPHGIQVERDRLNKYGRPLLGATMKPKLGLSAKNYGRVVYEALRGGLDFTKDDENITSQPFMRWRDRYMFVMEAVHKAEAETGERKGHYLNVTAGTMEEMYRRAEFAKELGSRIIMVDYLTVGFTAFTSLSKWCRENGMLLHAHRAMHAVIDRQKNHGIHWRVLAKWCRMVGGDHLHNGTVVGKLEGDRASTLGINDLLREDYVKRDPSRGIYFDQPWVSMPGVFPVASGGIHVWHMPELVSIFGDDAVLQFGGGTLGHPWGNAAGATANRVALEAVVQARNEGRDLVAEGPDILKEAARHSPELRAAMETWKDITFDFETVDKLDQV",
         null,
         "1",
         "500-SUMO",
         "MSKGKSNSNSQQKALFDAGVKEYSEAGRYYYDPGYVPKDTEVLAAFRITPQPGVPWEEAAAAVAAESSSGTWTTVWSDLLTDQARYAARTYKIEPVPGREDQFMAYIAYPLDLFEEGSLPNLMSSIVGNVFGFKALRALRLEDIYIPPALLKTFQGPPHGIQVERDRLNKYGRPLLGATMKPKLGLSAKNYGRVVYEALRGGLDFTKDDENITSQPFMRWRDRYMFVMEAVHKAEAETGERKGHYLNVTAGTMEEMYRRAEFAKELGSRIIMVDYLTVGFTAFTSLSKWCRENGMLLHAHRAMHAVIDRQKNHGIHWRVLAKWCRMVGGDHLHNGTVVGKLEGDRASTLGINDLLREDYVKRDPSRGIYFDQPWVSMPGVFPVASGGIHVWHMPELVSIFGDDAVLQFGGGTLGHPWGNAAGATANRVALEAVVQARNEGRDLVAEGPDILKEAARHSPELRAAMETWKDITFDFETVDKLDQV"
        ],
        [
         "2039",
         "576",
         "SUMO",
         "MTTKTYDAGVKDYRETYWDPDYTPKDTDILACFKITPQPGVPREEAAAAVAAESSTGTWTTVWTDLLTDLDHYKGRAYRIEDVPGDDECFYAFVAYPIDLFEEGSVVNVLTSLVGNVFGFKAIRALRLEDIRFPLHYVMTCGGPPNGITVERDKLNKYGRPMLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRQRFEFVAEAVHKAEAETGERKGHYLNVTAPTVEEMYKRAEFAKELGMPIIMHDFLTAGFTANTSLANWCRDNGMLLHIHRAMHAVIDRNPHHGIHFRVLAKCLRLSGGDHLHSGTVVGKLEGDREATLGWIDLMRESFIPENRSRGIFFDQDFGHMPGMFPVASGGIHVWHMPALVSIFGDDAVLQFGGGTLGHPWGNAAGAAANRVALEACVQARNEGRNLEKEGRDILTEAAKHSPELAVAMETWKEIKFEFDTVDKLDAASG",
         null,
         "1",
         "576-SUMO",
         "MTTKTYDAGVKDYRETYWDPDYTPKDTDILACFKITPQPGVPREEAAAAVAAESSTGTWTTVWTDLLTDLDHYKGRAYRIEDVPGDDECFYAFVAYPIDLFEEGSVVNVLTSLVGNVFGFKAIRALRLEDIRFPLHYVMTCGGPPNGITVERDKLNKYGRPMLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRQRFEFVAEAVHKAEAETGERKGHYLNVTAPTVEEMYKRAEFAKELGMPIIMHDFLTAGFTANTSLANWCRDNGMLLHIHRAMHAVIDRNPHHGIHFRVLAKCLRLSGGDHLHSGTVVGKLEGDREATLGWIDLMRESFIPENRSRGIFFDQDFGHMPGMFPVASGGIHVWHMPALVSIFGDDAVLQFGGGTLGHPWGNAAGAAANRVALEACVQARNEGRNLEKEGRDILTEAAKHSPELAVAMETWKEIKFEFDTVDKLDAASG"
        ],
        [
         "2046",
         "588",
         "SUMO",
         "MASKKYDAGVKEYRETYWTPDYTPLDTDLLACFKVTPQPGVPREEAAAAVAAESSTGTWTTVWSDLLTDLEFYKGRAYRIEDVPGDDEAFYAFIAYPIDLFEEGSVVNVLTSLVGNVFGFKAVRALRLEDIRFPIAYIKTCGGPPNGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFEFVAEAIHKAEAETGERKGHYLNVTAPTPEEMYKRAEFAKELGMPIIMHDFLTGGFTANTGLANWCRKNGMLLHIHRAMHAVIDRNPKHGIHFRVLAKCLRLSGGDHLHTGTVVGKLEGDRASTLGFVDQLRESFVPEDRSRGIFFDQDWGSMPGVFAVASGGIHVWHMPALVSIFGDDSVLQFGGGTQGHPWGNAAGAAANRVALEACVKARNEGRELEKEGKDILTEAAKHSPELAIAMETWKEIKFEFDTVDKLDVQ",
         null,
         "1",
         "588-SUMO",
         "MASKKYDAGVKEYRETYWTPDYTPLDTDLLACFKVTPQPGVPREEAAAAVAAESSTGTWTTVWSDLLTDLEFYKGRAYRIEDVPGDDEAFYAFIAYPIDLFEEGSVVNVLTSLVGNVFGFKAVRALRLEDIRFPIAYIKTCGGPPNGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFEFVAEAIHKAEAETGERKGHYLNVTAPTPEEMYKRAEFAKELGMPIIMHDFLTGGFTANTGLANWCRKNGMLLHIHRAMHAVIDRNPKHGIHFRVLAKCLRLSGGDHLHTGTVVGKLEGDRASTLGFVDQLRESFVPEDRSRGIFFDQDWGSMPGVFAVASGGIHVWHMPALVSIFGDDSVLQFGGGTQGHPWGNAAGAAANRVALEACVKARNEGRELEKEGKDILTEAAKHSPELAIAMETWKEIKFEFDTVDKLDVQ"
        ],
        [
         "2100",
         "354",
         "SUMO",
         "MDQSNRYADLSLKEEDLIKGGNHILVAYTMKPAAGYGYLEAAAHIAAESSTGTNVEVSTTDDFTKGVDALVYEIDEAKGLMKIAYPVDLFDRNIIDGRAMIASFLTLTIGNNQGMGDIENLKMLDFYVPPKMLRLFDGPAVNISDMWRILGRPVENGGYIAGTIIKPKLGLRPEPFAEACYQFWLGGDFIKNDEPQGNQVFCPMKKVIPLVADAMKRAQDETGQAKLFSANITADDHAEMIARGEYVLETFGPDASQVAFLVDGYVAGPAAVTTARRNFPNQFLHYHRAGHGAVTSPQSKRGYTAFVLMKMSRLMGASGIHVGTMGYGKMEGDASDKIIAYMIERDSCQGPFYHQEWYGMKPTTPIISGGMNALRLPGFFENLGHGNVINTAGGGSYGHIDSPAAGAVSLRQAYECWKSGADPIEYAKEHKEFARAFESFPKDADKIFPGWREKLGVHK",
         null,
         "1",
         "354-SUMO",
         "MDQSNRYADLSLKEEDLIKGGNHILVAYTMKPAAGYGYLEAAAHIAAESSTGTNVEVSTTDDFTKGVDALVYEIDEAKGLMKIAYPVDLFDRNIIDGRAMIASFLTLTIGNNQGMGDIENLKMLDFYVPPKMLRLFDGPAVNISDMWRILGRPVENGGYIAGTIIKPKLGLRPEPFAEACYQFWLGGDFIKNDEPQGNQVFCPMKKVIPLVADAMKRAQDETGQAKLFSANITADDHAEMIARGEYVLETFGPDASQVAFLVDGYVAGPAAVTTARRNFPNQFLHYHRAGHGAVTSPQSKRGYTAFVLMKMSRLMGASGIHVGTMGYGKMEGDASDKIIAYMIERDSCQGPFYHQEWYGMKPTTPIISGGMNALRLPGFFENLGHGNVINTAGGGSYGHIDSPAAGAVSLRQAYECWKSGADPIEYAKEHKEFARAFESFPKDADKIFPGWREKLGVHK"
        ],
        [
         "2122",
         "388",
         "SUMO",
         "MSGKFEEIYHEYVDKNYEPDKNDIIAVFRVTPAEGFTIEDAAGAVAAESSTGTWTTLYPWDTERVKKLSAKAYDFKDLGDGSWIVRIAYPVELFEEGNMPGLLASIAGNVFGMKRVKGLRLEDIYLPKKFLKNFKGPSKGIEGVRKIFGVKDRPIVGTVPKPKVGYSPEEVEKLAYELLSGGMDYIKDDENLTSPSFCRFEERAKRIMKVIDKVEKETGEKKTWFANITADIREMEKRLKLVADYGNPYVMVDVVITGWSALEYIRDLAEEYGLAIHGHRAMHAAFTRNPYHGISMFVLAKLYRIIGIDQLHIGTAGAGKLEGGKWDVIQYARILREKHYKPDEDDVFHLEQEFHHIKPAMPVSSGGLHPGNLPPVIEALGKDIVLQVGGGVLGHPDGPRAGARAVRQALEAIMKGIPLDEYAKTHRELARALEKWGYVKPI",
         null,
         "1",
         "388-SUMO",
         "MSGKFEEIYHEYVDKNYEPDKNDIIAVFRVTPAEGFTIEDAAGAVAAESSTGTWTTLYPWDTERVKKLSAKAYDFKDLGDGSWIVRIAYPVELFEEGNMPGLLASIAGNVFGMKRVKGLRLEDIYLPKKFLKNFKGPSKGIEGVRKIFGVKDRPIVGTVPKPKVGYSPEEVEKLAYELLSGGMDYIKDDENLTSPSFCRFEERAKRIMKVIDKVEKETGEKKTWFANITADIREMEKRLKLVADYGNPYVMVDVVITGWSALEYIRDLAEEYGLAIHGHRAMHAAFTRNPYHGISMFVLAKLYRIIGIDQLHIGTAGAGKLEGGKWDVIQYARILREKHYKPDEDDVFHLEQEFHHIKPAMPVSSGGLHPGNLPPVIEALGKDIVLQVGGGVLGHPDGPRAGARAVRQALEAIMKGIPLDEYAKTHRELARALEKWGYVKPI"
        ],
        [
         "2163",
         "605",
         "SUMO",
         "MMAKTYNAGVKEYRETYWTPDYTPKDTDLLACFKVTPQPGVPREEAAAAVAAESSTGTWTTVWTDLLTDLDYYKGRAYRIEDVPGDDESFYAFIAYPIDLFEEGSVVNVFTSLVGNVFGFKAVRALRLEDVRFPIAYVKTCGGPPHGIQVERDKMNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFEFVMEAIEKAQRETGERKGHYLNVTAPTPEEMYKRAEYAKELGAPIIMHDYLTGGFCANTGLANWCRDNGMLLHIHRAMHAVIDRHPKHGIHFRVLAKCLRLSGGDHLHTGTVVGKLEGDRQATLGWIDLLRDSFVPEDRSRGLFFDQDWGSMPGVFAVASGGIHVWHMPALVTIFGDDSVLQFGGGTLGHPWGNAAGAAANRVALEACVKARNEGRELEKEGKEILTEAARHSPELKIAMETWKEIKFEFDTVDKLDVAHK",
         null,
         "1",
         "605-SUMO",
         "MMAKTYNAGVKEYRETYWTPDYTPKDTDLLACFKVTPQPGVPREEAAAAVAAESSTGTWTTVWTDLLTDLDYYKGRAYRIEDVPGDDESFYAFIAYPIDLFEEGSVVNVFTSLVGNVFGFKAVRALRLEDVRFPIAYVKTCGGPPHGIQVERDKMNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFEFVMEAIEKAQRETGERKGHYLNVTAPTPEEMYKRAEYAKELGAPIIMHDYLTGGFCANTGLANWCRDNGMLLHIHRAMHAVIDRHPKHGIHFRVLAKCLRLSGGDHLHTGTVVGKLEGDRQATLGWIDLLRDSFVPEDRSRGLFFDQDWGSMPGVFAVASGGIHVWHMPALVTIFGDDSVLQFGGGTLGHPWGNAAGAAANRVALEACVKARNEGRELEKEGKEILTEAARHSPELKIAMETWKEIKFEFDTVDKLDVAHK"
        ],
        [
         "2198",
         "400",
         "SUMO",
         "MSTDYIDLNYTPKENDLICCFHIEPADGVDLEEAAGRVAAESSIGTWTDVSTMKPEIWEKLKARVYEIDEAGNIVKIAYPLDLFEPGNIPQILSSIAGNIFGMKAVKNLRLLDIRFPKELVKSFKGPKFGIEGVRELLGVYDRPLVGTIVKPKVGLSAEEHAEVAYEAWVGGLDLVKDDENLTSQPFNPFEERVKKTLEARDKAEEETGEKKMYLVNITAPTEEMIRRAELVKDLGGKYVMIDIITAGFSAVQSLREEDLGLAIHAHRAMHAAFTRNPKHGISMLVLAKLARLVGVDQLHIGTVVGKMEGDKEEVLAIRDALRLDRVPADEANHFLEQDWGNIKPVFPVASGGLHPGLIPDLIDIFGKDVIIQFGGGVHGHPDGTRAGAKAMRQAIEAAMEGISLEEYAKEHKELEKALEKWG",
         null,
         "0",
         "400-SUMO",
         "MSTDYIDLNYTPKENDLICCFHIEPADGVDLEEAAGRVAAESSIGTWTDVSTMKPEIWEKLKARVYEIDEAGNIVKIAYPLDLFEPGNIPQILSSIAGNIFGMKAVKNLRLLDIRFPKELVKSFKGPKFGIEGVRELLGVYDRPLVGTIVKPKVGLSAEEHAEVAYEAWVGGLDLVKDDENLTSQPFNPFEERVKKTLEARDKAEEETGEKKMYLVNITAPTEEMIRRAELVKDLGGKYVMIDIITAGFSAVQSLREEDLGLAIHAHRAMHAAFTRNPKHGISMLVLAKLARLVGVDQLHIGTVVGKMEGDKEEVLAIRDALRLDRVPADEANHFLEQDWGNIKPVFPVASGGLHPGLIPDLIDIFGKDVIIQFGGGVHGHPDGTRAGAKAMRQAIEAAMEGISLEEYAKEHKELEKALEKWG"
        ],
        [
         "2199",
         "332",
         "SUMO",
         "MADKDVIATYHIEEGVTLEKAAQEIAAEQSTGTWTDVSTEQEVVEKLGARVVSIEPSGGGNTVTIAYPAEIFEPGNIPQILSVVAGNLFGLGALKALRLLDVDFPPELVKSFKGPKFGIEGVRKLLGVYDRPLVGTIIKPKVGLSPKETAEVAYQAAIGGVDLIKDDETLTDQPFCPLEERLKAVMEKLDKAEEETGKKVLYAVNITAGADEIVERAERAVDLGANMVMIDVITAGFSAVQALREENINLPIHVHRTMHGALTRNPEHGISMRVLAKLVRMVGGDQLHTGTVSGKMEHDVSEIRASRDALRQPWYNLKPVFPVASGGLHPGKVPANLDCFGTDIILQAGGGIHGHPDGTRAGAKAMRQAVEAWMEGVSLEEYAKDHPELARALEKWGPSR",
         null,
         "0",
         "332-SUMO",
         "MADKDVIATYHIEEGVTLEKAAQEIAAEQSTGTWTDVSTEQEVVEKLGARVVSIEPSGGGNTVTIAYPAEIFEPGNIPQILSVVAGNLFGLGALKALRLLDVDFPPELVKSFKGPKFGIEGVRKLLGVYDRPLVGTIIKPKVGLSPKETAEVAYQAAIGGVDLIKDDETLTDQPFCPLEERLKAVMEKLDKAEEETGKKVLYAVNITAGADEIVERAERAVDLGANMVMIDVITAGFSAVQALREENINLPIHVHRTMHGALTRNPEHGISMRVLAKLVRMVGGDQLHTGTVSGKMEHDVSEIRASRDALRQPWYNLKPVFPVASGGLHPGKVPANLDCFGTDIILQAGGGIHGHPDGTRAGAKAMRQAVEAWMEGVSLEEYAKDHPELARALEKWGPSR"
        ],
        [
         "2208",
         "483",
         "SUMO",
         "MSPSTASTSEEKKDRWASGVTPYAEMGYYDADYEPKDTDILCAFRITPQPGVDPIEAAAAVAGESSTATWTVVWTDRLTDHKHYQAKAYRVEPVPGTEGQYIAKIAYDIDLFEEGSIANLTSSIIGNVFGFKALKALRLEDMRIPPHYVKTFQGPAHGIVMEREYLDKFGRPLLGATVKPKLGLSAKNYGRVVYEALRGGLDFTKDDENINSQPFMRWRDRFLYCMEAVNKASAATGEVKGHYMNVTAATMEEMYERAEFAKELGSVIIMIDLTVGYTAIQSMAKWARANGVILHLHRAGHGTYTRQKTHGVSFRVIAKWMRLAGVDHIHAGTVVGKLEGDPNMTKGYYDTLRESHIPENPAHGIYFDQDWASMPGVMPVASGGIHAGQMHQLLHYLGEDVVLQFGGGTIGHPMGIAAGATANRVAVEAMIQARNEGRDYFQEGPDILEKAAKHCPELNAALQVWKDITFDFESTDTPDVVATPSVG",
         null,
         "0",
         "483-SUMO",
         "MSPSTASTSEEKKDRWASGVTPYAEMGYYDADYEPKDTDILCAFRITPQPGVDPIEAAAAVAGESSTATWTVVWTDRLTDHKHYQAKAYRVEPVPGTEGQYIAKIAYDIDLFEEGSIANLTSSIIGNVFGFKALKALRLEDMRIPPHYVKTFQGPAHGIVMEREYLDKFGRPLLGATVKPKLGLSAKNYGRVVYEALRGGLDFTKDDENINSQPFMRWRDRFLYCMEAVNKASAATGEVKGHYMNVTAATMEEMYERAEFAKELGSVIIMIDLTVGYTAIQSMAKWARANGVILHLHRAGHGTYTRQKTHGVSFRVIAKWMRLAGVDHIHAGTVVGKLEGDPNMTKGYYDTLRESHIPENPAHGIYFDQDWASMPGVMPVASGGIHAGQMHQLLHYLGEDVVLQFGGGTIGHPMGIAAGATANRVAVEAMIQARNEGRDYFQEGPDILEKAAKHCPELNAALQVWKDITFDFESTDTPDVVATPSVG"
        ],
        [
         "2213",
         "634",
         "SUMO",
         "MAGDRLVATYHLAGPGEEAEKKAKGIALEQTVEMPLELVPEAAIRDRVVGRVEDIEPIDGGRYRVTIAYPVATAGGELPQLLNVIFGNISLQPGIRLVDIHLPPSFLKSFPGPRFGIEGLRKLLGVHDRPLLCTALKPMGLSPEELAEIAYQCALGGVDIIKDDHGLADQPYSPFEERVRACARAVEKANRETGRKTLYLPNITAPLDELRERARFAREAGAKAVLISPMLVGLDTMRALAERLGLPIMAHPAFSGAFVASPEHGISHSLLLGKLMRLAGADAVIFPNFGGRFAFSREECRAIAEAARSPWGHLKPVFPVPGGGMSLDRVPDMLRTYGPDVILLIGGGLFAHPDGLEAGARAFREAVEAMV",
         null,
         "0",
         "634-SUMO",
         "MAGDRLVATYHLAGPGEEAEKKAKGIALEQTVEMPLELVPEAAIRDRVVGRVEDIEPIDGGRYRVTIAYPVATAGGELPQLLNVIFGNISLQPGIRLVDIHLPPSFLKSFPGPRFGIEGLRKLLGVHDRPLLCTALKPMGLSPEELAEIAYQCALGGVDIIKDDHGLADQPYSPFEERVRACARAVEKANRETGRKTLYLPNITAPLDELRERARFAREAGAKAVLISPMLVGLDTMRALAERLGLPIMAHPAFSGAFVASPEHGISHSLLLGKLMRLAGADAVIFPNFGGRFAFSREECRAIAEAARSPWGHLKPVFPVPGGGMSLDRVPDMLRTYGPDVILLIGGGLFAHPDGLEAGARAFREAVEAMV"
        ],
        [
         "2214",
         "651",
         "SUMO",
         "MADRITATYLIEAPADVEKAAETLAGEQSTGTFTRVPGETDELKERFAARVESIEALPEAEAPSLPGAGGGGRYRRARVTISWPLDNFGPNLPMLLSTLLGNLFGMKELSGIRLEDIQLPASFVAAYPGPAFGIEGTRRLTGVHDRPLIGTIVKPSIGLSPEETAELVQQLAEGGIDFIKDDELLADPPYCPFDERVKAVMRVLDRAADRTGKKTMYAVNITDEVDEMLRRHDLVVDAGGTCVMVNLNSVGLSALAALRRHSSLPIHAHRAGWGMLTRHPALGMSFKAYQKLWRLAGVDHLHVNGLGGKFWEPDDSVVQSARACLTPLYDHKPVMPVFSGGQTVGQVPPTYQRLGTADLIFAAGGGILGHPDGPAAGVRALRQAWEAAVAGIPLEEYAKDHPELAKAIEKFGKARQA",
         null,
         "0",
         "651-SUMO",
         "MADRITATYLIEAPADVEKAAETLAGEQSTGTFTRVPGETDELKERFAARVESIEALPEAEAPSLPGAGGGGRYRRARVTISWPLDNFGPNLPMLLSTLLGNLFGMKELSGIRLEDIQLPASFVAAYPGPAFGIEGTRRLTGVHDRPLIGTIVKPSIGLSPEETAELVQQLAEGGIDFIKDDELLADPPYCPFDERVKAVMRVLDRAADRTGKKTMYAVNITDEVDEMLRRHDLVVDAGGTCVMVNLNSVGLSALAALRRHSSLPIHAHRAGWGMLTRHPALGMSFKAYQKLWRLAGVDHLHVNGLGGKFWEPDDSVVQSARACLTPLYDHKPVMPVFSGGQTVGQVPPTYQRLGTADLIFAAGGGILGHPDGPAAGVRALRQAWEAAVAGIPLEEYAKDHPELAKAIEKFGKARQA"
        ],
        [
         "2216",
         "E10",
         "SUMO",
         "MNAEDVKGFFASRESLDMEQYLVLDYYLESVGDIETALAHFCSEQSTAQWKRVGVDEDFRLVHAAKVIDYEVIEELEQLSYPVKHSETGKIHACRVTIAHPHCNFGPKIPNLLTAVCGEGTYFTPGVPVVKLMDIHFPDTYLADFEGPKFGIEGLRDILNAHGRPIFFGVVKPNIGLSPGEFAEIAYQSWLGGLDIAKDDEMLADVTWSSIEERAAHLGKARRKAEAETGEPKIYLANITDEVDSLMEKHDVAVRNGANALLINALPVGLSAVRMLSNYTQVPLIGHFPFIASFSRMEKYGIHSKVMTKLQRLAGLDAVIMPGFGDRVMTPEEEVLENVIECTKPMGRIKPCLPVPGGSDSALTLQTVYEKVGNVDFGFVPGRGVFGHPMGPKAGAKSIRQAWEAIEQGISIETWAETHPELQAMVDQSLLKKQD",
         null,
         "0",
         "E10-SUMO",
         "MNAEDVKGFFASRESLDMEQYLVLDYYLESVGDIETALAHFCSEQSTAQWKRVGVDEDFRLVHAAKVIDYEVIEELEQLSYPVKHSETGKIHACRVTIAHPHCNFGPKIPNLLTAVCGEGTYFTPGVPVVKLMDIHFPDTYLADFEGPKFGIEGLRDILNAHGRPIFFGVVKPNIGLSPGEFAEIAYQSWLGGLDIAKDDEMLADVTWSSIEERAAHLGKARRKAEAETGEPKIYLANITDEVDSLMEKHDVAVRNGANALLINALPVGLSAVRMLSNYTQVPLIGHFPFIASFSRMEKYGIHSKVMTKLQRLAGLDAVIMPGFGDRVMTPEEEVLENVIECTKPMGRIKPCLPVPGGSDSALTLQTVYEKVGNVDFGFVPGRGVFGHPMGPKAGAKSIRQAWEAIEQGISIETWAETHPELQAMVDQSLLKKQD"
        ],
        [
         "2217",
         "E3",
         "SUMO",
         "MPKTQSAAGYKAGVKDYKLTYYTPDYTPKDTDLLAAFRFSPQPGVPADEAGAAIAAESSTGTWTTVWTDLLTDMDRYKGKCYHIEPVQGEENSYFAFIAYPLDLFEEGSVTNILTSIVGNVFGFKAIRSLRLEDIRFPVALVKTFQGPPHGIQVERDLLNKYGRPMLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENINSQPFQRWRDRFLFVADAIHKSQAETGEIKGHYLNVTAPTCEEMMKRAEFAKELGMPIIMHDFLTAGFTANTTLAKWCRDNGVLLHIHRAMHAVIDRQRNHGIHFRVLAKCLRLSGGDHLHSGTVVGKLEGDKASTLGFVDLMREDHIEADRSRGVFFTQDWASMPGVLPVASGGIHVWHMPALVEIFGDDSVLQFGGGTLGHPWGNAPGATANRVALEACVQARNEGRDLYREGGDILREAGKWSPELAAALDLWKEIKFEFETMDKL",
         null,
         "0",
         "E3-SUMO",
         "MPKTQSAAGYKAGVKDYKLTYYTPDYTPKDTDLLAAFRFSPQPGVPADEAGAAIAAESSTGTWTTVWTDLLTDMDRYKGKCYHIEPVQGEENSYFAFIAYPLDLFEEGSVTNILTSIVGNVFGFKAIRSLRLEDIRFPVALVKTFQGPPHGIQVERDLLNKYGRPMLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENINSQPFQRWRDRFLFVADAIHKSQAETGEIKGHYLNVTAPTCEEMMKRAEFAKELGMPIIMHDFLTAGFTANTTLAKWCRDNGVLLHIHRAMHAVIDRQRNHGIHFRVLAKCLRLSGGDHLHSGTVVGKLEGDKASTLGFVDLMREDHIEADRSRGVFFTQDWASMPGVLPVASGGIHVWHMPALVEIFGDDSVLQFGGGTLGHPWGNAPGATANRVALEACVQARNEGRDLYREGGDILREAGKWSPELAAALDLWKEIKFEFETMDKL"
        ],
        [
         "2225",
         "446",
         "SUMO",
         "MADSTTTTTRDAKERYKAGVLPYAQMGYWEPDYEPKDTDILALFRITPQDGVDPEEAAAAVAGESSTATWTVVWTDRLTACEHYRAKAYRVEPVPGTPGQYFAYIAYDLDLFEEGSIANLTASIIGNVFGFKPLKALRLEDMRIPVAYVKTFQGPPTGIVVERERLDKFGRPLLGATVKPKLGLSGRNYGRVVYEALKGGLDFTKDDENINSQPFMHWRDRFLYCMEAVNRAQAATGEVKGHYLNVTAATMEEMYERAEFAKELGSVIVMIDLVIGYTAIQSMAKWARRNDMILHLHRAGHSTYTRQKNHGVSFRVIAKWMRLAGVDHIHAGTVVGKLEGDPNTVRGYYDVCRESHTPQNLENGLFFDQDWASLRKVMPVASGGIHAGQMHQLLHYLGEDVVLQFGGGTIGHPMGIAAGATANRVALEAMILARNEGRDFLNEGPEILRDAAKWCAPLRAALDTWGDVTFNYTSTDTPDFVPTPTVA",
         null,
         "0",
         "446-SUMO",
         "MADSTTTTTRDAKERYKAGVLPYAQMGYWEPDYEPKDTDILALFRITPQDGVDPEEAAAAVAGESSTATWTVVWTDRLTACEHYRAKAYRVEPVPGTPGQYFAYIAYDLDLFEEGSIANLTASIIGNVFGFKPLKALRLEDMRIPVAYVKTFQGPPTGIVVERERLDKFGRPLLGATVKPKLGLSGRNYGRVVYEALKGGLDFTKDDENINSQPFMHWRDRFLYCMEAVNRAQAATGEVKGHYLNVTAATMEEMYERAEFAKELGSVIVMIDLVIGYTAIQSMAKWARRNDMILHLHRAGHSTYTRQKNHGVSFRVIAKWMRLAGVDHIHAGTVVGKLEGDPNTVRGYYDVCRESHTPQNLENGLFFDQDWASLRKVMPVASGGIHAGQMHQLLHYLGEDVVLQFGGGTIGHPMGIAAGATANRVALEAMILARNEGRDFLNEGPEILRDAAKWCAPLRAALDTWGDVTFNYTSTDTPDFVPTPTVA"
        ],
        [
         "2231",
         "574",
         "SUMO",
         "MTAKTYQAGVKDYRETYWDPDYTPKDTDILACFKITPQPGVPREEAAAAVAAESSTGTWTTVWTDLLTDLDYYKGRAYRIEDVPGDDECFYAFVAYPIDLFEEGSVVNVLTSLVGNVFGFKAIRALRLEDVRFPLAYVKTCGGPPNGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFEFVAEAIHKAEAETGERKGHYLNVTAPTVEEMYKRAEFAKELGMPIIMHDYLTGGFTANTSLANWCRDNGMLLHIHRAMHAVIDRNPHHGIHFRVLAKCLRLSGGDHLHSGTVVGKLEGDREATLGWIDLMRESFIPEDRSRGIFFDQDWGSMPGVFPVASGGIHVWHMPALVSIFGDDSVLQFGGGTLGHPWGNAAGAAANRVALEACVQARNEGRDLEKEGKDILTEAAKHSPELAVAMETWKEIKFEFDTVDKLDVASG",
         null,
         "1",
         "574-SUMO",
         "MTAKTYQAGVKDYRETYWDPDYTPKDTDILACFKITPQPGVPREEAAAAVAAESSTGTWTTVWTDLLTDLDYYKGRAYRIEDVPGDDECFYAFVAYPIDLFEEGSVVNVLTSLVGNVFGFKAIRALRLEDVRFPLAYVKTCGGPPNGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFEFVAEAIHKAEAETGERKGHYLNVTAPTVEEMYKRAEFAKELGMPIIMHDYLTGGFTANTSLANWCRDNGMLLHIHRAMHAVIDRNPHHGIHFRVLAKCLRLSGGDHLHSGTVVGKLEGDREATLGWIDLMRESFIPEDRSRGIFFDQDWGSMPGVFPVASGGIHVWHMPALVSIFGDDSVLQFGGGTLGHPWGNAAGAAANRVALEACVQARNEGRDLEKEGKDILTEAAKHSPELAVAMETWKEIKFEFDTVDKLDVASG"
        ],
        [
         "2255",
         "E2",
         "SUMO",
         "MSPQTETKASVEFKAGVKDYKLTYYTPEYETLDTDILAAFRVSPQPGVPPEEAGAAVAAESSTGTWTTVWTDGLTNLDRYKGRCYHIEPVAGEENQYICYVAYPLDLFEEGSVTNMFTSIVGNVFGFKALRALRLEDLRIPVAYVKTFQGPPHGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFLFCAEALYKAQAETGEIKGHYLNATAGTCEDMMKRAVFARELGVPIVMHDYLTGGFTANTTLSHYCRDNGLLLHIHRAMHAVIDRQKNHGMHFRVLAKALRLSGGDHIHSGTVVGKLEGERDITLGFVDLLRDDYTEKDRSRGIYFTQSWVSTPGVLPVASGGIHVWHMPALTEIFGDDSVLQFGGGTLGHPWGNAPGAVANRVALEACVQARNEGRDLAREGNTIIREATKWSPELAAACEVWKEIKFEFPAMDTV",
         null,
         "0",
         "E2-SUMO",
         "MSPQTETKASVEFKAGVKDYKLTYYTPEYETLDTDILAAFRVSPQPGVPPEEAGAAVAAESSTGTWTTVWTDGLTNLDRYKGRCYHIEPVAGEENQYICYVAYPLDLFEEGSVTNMFTSIVGNVFGFKALRALRLEDLRIPVAYVKTFQGPPHGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFLFCAEALYKAQAETGEIKGHYLNATAGTCEDMMKRAVFARELGVPIVMHDYLTGGFTANTTLSHYCRDNGLLLHIHRAMHAVIDRQKNHGMHFRVLAKALRLSGGDHIHSGTVVGKLEGERDITLGFVDLLRDDYTEKDRSRGIYFTQSWVSTPGVLPVASGGIHVWHMPALTEIFGDDSVLQFGGGTLGHPWGNAPGAVANRVALEACVQARNEGRDLAREGNTIIREATKWSPELAAACEVWKEIKFEFPAMDTV"
        ],
        [
         "2257",
         "369",
         "SUMO",
         "MGITYEDFLDLDYEPTDEDLVCTFRIDPATGMSTEAAASRVASESSNGTWAALQTGADFTDMGATTFSIDGDTIRVAYPAGLFEPGNMPQVLSCIAGNIMGMKAVDTIRLMDCEWPESIVSSFPGPLFGSSVREEIFGVDDRPITATVPKPKVGLSTAAHAQVGYDAWVGGVDLLKDDENLTDQAFNPFADRLTESLALRDDAEDETGEKKSYLINVTADTQTMLDRVDEVAEQGGEYVMVDIITAGWAGLQTVRERTEKHGLAIHAHRAMHAAFDRLPTHGVSMRVLAQISRLCGVDQLHTGTAGLGKLANEDTVGINEWLRSDLYGTNDVLPVASGGLHPGLLPDLLDATGTNVCVQLGGGIHGHPDGTRAGAVALRSAIDAYVEGKSIQEAADETPELAVALDKWGTETPR",
         null,
         "0",
         "369-SUMO",
         "MGITYEDFLDLDYEPTDEDLVCTFRIDPATGMSTEAAASRVASESSNGTWAALQTGADFTDMGATTFSIDGDTIRVAYPAGLFEPGNMPQVLSCIAGNIMGMKAVDTIRLMDCEWPESIVSSFPGPLFGSSVREEIFGVDDRPITATVPKPKVGLSTAAHAQVGYDAWVGGVDLLKDDENLTDQAFNPFADRLTESLALRDDAEDETGEKKSYLINVTADTQTMLDRVDEVAEQGGEYVMVDIITAGWAGLQTVRERTEKHGLAIHAHRAMHAAFDRLPTHGVSMRVLAQISRLCGVDQLHTGTAGLGKLANEDTVGINEWLRSDLYGTNDVLPVASGGLHPGLLPDLLDATGTNVCVQLGGGIHGHPDGTRAGAVALRSAIDAYVEGKSIQEAADETPELAVALDKWGTETPR"
        ],
        [
         "2264",
         "412",
         "SUMO",
         "MTTITTAPTAEVSKKYKAGVRPYAADYYVPDYAPLDTDLLCAFRIQPKPGVDMIEAAAAVAAESSTGTWTEVWSNQLTDIDYYKAKVYRIEGDIAYIAYPMDLFEENSIVNIMSSIVGNVFGFKAVSALRLEDMRIPVALVKTFPGPNIGIYDERARLNKWDRPLLGGTVKPKLGLSAKDYATIIYECLVGGLDTTKDDENMNSQPFNRWRDRFLYGMDAVKKAEAETGEAKGHFFNVTANSTEESLRRLEYIAAQGSRYIMYDFLTAGFAASADVFKRAGELGVIVHCHRAMHAVFTRQKNHGIHMRVVAKWLRLTGGDHLHTGTVVGKLEGSRNETLGIIDLLRERVIPANPERGLYFEQDFAGLKTVWPVASGGIHVLHIPDLYKIYGNDAFWLFGGGTHGHPRGSRAGARANRVATEAIASGKTLEEAARTCPELREAMELWGNVKFEVSE",
         null,
         "1",
         "412-SUMO",
         "MTTITTAPTAEVSKKYKAGVRPYAADYYVPDYAPLDTDLLCAFRIQPKPGVDMIEAAAAVAAESSTGTWTEVWSNQLTDIDYYKAKVYRIEGDIAYIAYPMDLFEENSIVNIMSSIVGNVFGFKAVSALRLEDMRIPVALVKTFPGPNIGIYDERARLNKWDRPLLGGTVKPKLGLSAKDYATIIYECLVGGLDTTKDDENMNSQPFNRWRDRFLYGMDAVKKAEAETGEAKGHFFNVTANSTEESLRRLEYIAAQGSRYIMYDFLTAGFAASADVFKRAGELGVIVHCHRAMHAVFTRQKNHGIHMRVVAKWLRLTGGDHLHTGTVVGKLEGSRNETLGIIDLLRERVIPANPERGLYFEQDFAGLKTVWPVASGGIHVLHIPDLYKIYGNDAFWLFGGGTHGHPRGSRAGARANRVATEAIASGKTLEEAARTCPELREAMELWGNVKFEVSE"
        ],
        [
         "2293",
         "520",
         "SUMO",
         "MAPQTETKTGAGFKAGVKDYRLTYYTPDYQVKDTDILAAFRMTPQPGVPPEEAGAAVAAESSTGTWTTVWTDGLTSLDRYKGRCYDIEPVPGEDNQYIAYVAYPLDLFEEGSVTNLFTSIVGNVFGFKALRALRLEDLRIPVAYVKTFQGPPHGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFLFVAEAIYKAQAETGEIKGHYLNATAGTCEEMMKRAEFAKELGVPIVMHDYLTGGFTANTSLAHYCRDNGLLLHIHRAMHAVIDRQRNHGIHFRVLAKALRLSGGDHLHSGTVVGKLEGEREVTLGFVDLMRDDYIEKDRSRGIYFTQDWASLPGVMPVASGGIHVWHMPALVEIFGDDSCLQFGGGTLGHPWGNAPGAAANRVALEACVQARNEGRDLAREGGDVIRAAAKWSPELAAACEVWKEIKFEFETIDTL",
         null,
         "0",
         "520-SUMO",
         "MAPQTETKTGAGFKAGVKDYRLTYYTPDYQVKDTDILAAFRMTPQPGVPPEEAGAAVAAESSTGTWTTVWTDGLTSLDRYKGRCYDIEPVPGEDNQYIAYVAYPLDLFEEGSVTNLFTSIVGNVFGFKALRALRLEDLRIPVAYVKTFQGPPHGIQVERDKLNKYGRPLLGCTIKPKLGLSAKNYGRAVYECLRGGLDFTKDDENVNSQPFMRWRDRFLFVAEAIYKAQAETGEIKGHYLNATAGTCEEMMKRAEFAKELGVPIVMHDYLTGGFTANTSLAHYCRDNGLLLHIHRAMHAVIDRQRNHGIHFRVLAKALRLSGGDHLHSGTVVGKLEGEREVTLGFVDLMRDDYIEKDRSRGIYFTQDWASLPGVMPVASGGIHVWHMPALVEIFGDDSCLQFGGGTLGHPWGNAPGAAANRVALEACVQARNEGRDLAREGGDVIRAAAKWSPELAAACEVWKEIKFEFETIDTL"
        ],
        [
         "2324",
         "339",
         "SUMO",
         "MQKEYINLKLKDPRNGEYLLAVFHLVPAGGLNILDAASEVAAESSTGSNVKVSTATEFSKSLNALVYKIDEEKNLVWIAYPWRIFDRGGNVQNILTYIAGNIFGMSEIKALKLLDVWFPPEMLKQYDGPSYTLDDMRKYLGVYDRPILGTIIKPKIGLTSEEYAEVCYDFWVGGGDFVKNDEPQANQDFCPYEKMVDAIREAMDKAEKETGKKKVHSFNVSAADFDTMIKRCEYIINKMKPGSYAFLIDGITAGWMAVQTLRRRYPDVFIHFHRAGHGAFTRPENPIGFSVLVLTKFARLAGASGIHTGTAGVGKMAGDPEEDVTAAHMALKLKAKGPFFEQTWSKIPEKDKDVINMVEEEEAHHVVLEDDSWRGMKKTCPIVSGGLNPVLLKPFIDVMGNVDFITTMGGGVHSHPGGTKAGAKALVQACEAWKKGIDIEEYAKDHKELAQAIEFYSKKKEKAHKY",
         null,
         "1",
         "339-SUMO",
         "MQKEYINLKLKDPRNGEYLLAVFHLVPAGGLNILDAASEVAAESSTGSNVKVSTATEFSKSLNALVYKIDEEKNLVWIAYPWRIFDRGGNVQNILTYIAGNIFGMSEIKALKLLDVWFPPEMLKQYDGPSYTLDDMRKYLGVYDRPILGTIIKPKIGLTSEEYAEVCYDFWVGGGDFVKNDEPQANQDFCPYEKMVDAIREAMDKAEKETGKKKVHSFNVSAADFDTMIKRCEYIINKMKPGSYAFLIDGITAGWMAVQTLRRRYPDVFIHFHRAGHGAFTRPENPIGFSVLVLTKFARLAGASGIHTGTAGVGKMAGDPEEDVTAAHMALKLKAKGPFFEQTWSKIPEKDKDVINMVEEEEAHHVVLEDDSWRGMKKTCPIVSGGLNPVLLKPFIDVMGNVDFITTMGGGVHSHPGGTKAGAKALVQACEAWKKGIDIEEYAKDHKELAQAIEFYSKKKEKAHKY"
        ],
        [
         "2332",
         "E8",
         "SUMO",
         "MIQEELSKTLNPKQVQYMRMDLPDPRNGEYLLAVFHLIPSGELNIMQAAAEVAAESSTGTNFAVKTETPFSRVMNALVYKVDIEKNLVWIAYPWRLFDRNGNVQNIMTYIAGNALGMKEIKALKLLDIWFPPSMLEQYDGPSYTLDDMRTYLNVHDRPILGTIIKPKMGLTSSEYAEVCYDFWVGGGDFVKNDEPQADQDFCPYDKMVKYVKMAMDKAVKETGKKKVHSFNVSSADFDTMIERCEMIREAGFEPGSYAFLIDGITAGWMAVQTLRRRYPDVFLHFHRAGHGGFTRPENPIGFSVLVLSKFARLAGASGIHTGTAGVGKMAGSPEEDVTAARNILKVEGKGHFFTQNWGRIPPQDDDAIKMVEMDDAHHVVLEDDSWRGLKKCCPIISGGLNPTLLEPFIDVMGGIDFITTMGAGCHAHPRGTRAGAMALVQACEAYKNKIDIADYAKDHRELAEAIEFFSKKKKK",
         null,
         "1",
         "E8-SUMO",
         "MIQEELSKTLNPKQVQYMRMDLPDPRNGEYLLAVFHLIPSGELNIMQAAAEVAAESSTGTNFAVKTETPFSRVMNALVYKVDIEKNLVWIAYPWRLFDRNGNVQNIMTYIAGNALGMKEIKALKLLDIWFPPSMLEQYDGPSYTLDDMRTYLNVHDRPILGTIIKPKMGLTSSEYAEVCYDFWVGGGDFVKNDEPQADQDFCPYDKMVKYVKMAMDKAVKETGKKKVHSFNVSSADFDTMIERCEMIREAGFEPGSYAFLIDGITAGWMAVQTLRRRYPDVFLHFHRAGHGGFTRPENPIGFSVLVLSKFARLAGASGIHTGTAGVGKMAGSPEEDVTAARNILKVEGKGHFFTQNWGRIPPQDDDAIKMVEMDDAHHVVLEDDSWRGLKKCCPIISGGLNPTLLEPFIDVMGGIDFITTMGAGCHAHPRGTRAGAMALVQACEAYKNKIDIADYAKDHRELAEAIEFFSKKKKK"
        ],
        [
         "2340",
         "403",
         "SUMO",
         "MSKRYTDYIDLNYTPKENDLLCCFHVEPAEGVDLEEAAGAVAAESSIGTWTDVSTMKPEIWEKLRARVYEIEGNIVKIAYPLDLFEPGNIPQILSSIAGNIFGMKAVKNLRLLDIRFPPELVKSFKGPAFGIEGVRELLGVYDRPLVGTIVKPKLGLSAKEHAEVVYEALVGGLDLVKDDENLTSQPFNPFEERVKRTLEAVDKAEEETGEKKVYLVNVTAPTEEMIRRAELVKDLGGKYVMVDIITAGFSAVQSLREADLGLVIHAHRAMHAAFTRNKKHGISMLVLAKLARLAGVDQLHIGTVVGKMEGDKEEVLAIRDALRNDRVPADEADHFLDQDWGNIKPVFPVASGGLHPGHIPDLIDIFGKDVILQFGGGVHGHPEGTRAGAKAMRAAVEAAMEGISLEEAAKDHKELEEALEKWG",
         null,
         "1",
         "403-SUMO",
         "MSKRYTDYIDLNYTPKENDLLCCFHVEPAEGVDLEEAAGAVAAESSIGTWTDVSTMKPEIWEKLRARVYEIEGNIVKIAYPLDLFEPGNIPQILSSIAGNIFGMKAVKNLRLLDIRFPPELVKSFKGPAFGIEGVRELLGVYDRPLVGTIVKPKLGLSAKEHAEVVYEALVGGLDLVKDDENLTSQPFNPFEERVKRTLEAVDKAEEETGEKKVYLVNVTAPTEEMIRRAELVKDLGGKYVMVDIITAGFSAVQSLREADLGLVIHAHRAMHAAFTRNKKHGISMLVLAKLARLAGVDQLHIGTVVGKMEGDKEEVLAIRDALRNDRVPADEADHFLDQDWGNIKPVFPVASGGLHPGHIPDLIDIFGKDVILQFGGGVHGHPEGTRAGAKAMRAAVEAAMEGISLEEAAKDHKELEEALEKWG"
        ],
        [
         "2360",
         "E4",
         "SUMO",
         "MDTKTTEIKGKERYKAGVLKYAQMGYWDGDYVPKDTDVLALFRITPQEGVDPVEAAAAVAGESSTATWTVVWTDRLTACDSYRAKAYRVEPVPGTPGQYFCYVAYDLILFEEGSIANLTASIIGNVFSFKPLKAARLEDMRFPVAYVKTYKGPPTGIVGERERLDKFGKPLLGATTKPKLGLSGKNYGRVVYEGLKGGLDFMKDDENINSQPFMHWRDRFLYVMEAVNLASAQTGEVKGHYLNITAGTMEEMYRRAEFAKSLGSVIVMVDLIIGYTAIQSISEWCRQNDMILHMHRAGHGTYTRQKNHGISFRVIAKWLRLAGVDHLHCGTAVGKLEGDPLTVQGYYNVCREPFNTVDLPRGIFFEQDWADLRKVMPVASGGIHAGQMHQLLSLFGDDVVLQFGGGTIGHPMGIQAGATANRVALEAMVLARNEGRNIDVEGPEILRAAAKWCKPLEAALDTWGNITFNYTSTDTSDFVPTASVAM",
         null,
         "0",
         "E4-SUMO",
         "MDTKTTEIKGKERYKAGVLKYAQMGYWDGDYVPKDTDVLALFRITPQEGVDPVEAAAAVAGESSTATWTVVWTDRLTACDSYRAKAYRVEPVPGTPGQYFCYVAYDLILFEEGSIANLTASIIGNVFSFKPLKAARLEDMRFPVAYVKTYKGPPTGIVGERERLDKFGKPLLGATTKPKLGLSGKNYGRVVYEGLKGGLDFMKDDENINSQPFMHWRDRFLYVMEAVNLASAQTGEVKGHYLNITAGTMEEMYRRAEFAKSLGSVIVMVDLIIGYTAIQSISEWCRQNDMILHMHRAGHGTYTRQKNHGISFRVIAKWLRLAGVDHLHCGTAVGKLEGDPLTVQGYYNVCREPFNTVDLPRGIFFEQDWADLRKVMPVASGGIHAGQMHQLLSLFGDDVVLQFGGGTIGHPMGIQAGATANRVALEAMVLARNEGRNIDVEGPEILRAAAKWCKPLEAALDTWGNITFNYTSTDTSDFVPTASVAM"
        ],
        [
         "2363",
         "E6",
         "SUMO",
         "MAIHNPLAGPKTVKARPTAELSDAYKAGVRAYAVDYYVPDYIPQDTDLLCAFRIQPRGVDMIEAAAAVAAESSTGTWTEVWSNQLTDIDFYKAKVYAITGDIAYIAYPLDLFEENSVVNIMSSIVGNVFGFKAVGALRLEDMRIPLALVKTFPGPRVGIYDERVWSNKWDRPLIGGTVKPKLGLSPKAYSTIIYECLSGGLDTSKDDENMNSQPFSRWRDRFMYAQEAVDRAAAETNEFKGHWHNVTAGSTEESLRRLEYAYELGSRMVMFDFLTAGFAASADIFKRAGELDMIVHCHRAMHAVFTRQANHGIAMRVVAKWLRLTGGDHLHTGTVVGKLEGSWNDTLGIIDILRERYVKANLEHGLYFDQDFGGLKASWPVASGGIHVHHVPDLLKIYGNDAFFLFGGGTHGHPDGSRAGAIANRAAVEAVSAGQTLQQAARSCPELRKSLELWADVKFEVVQ",
         null,
         "1",
         "E6-SUMO",
         "MAIHNPLAGPKTVKARPTAELSDAYKAGVRAYAVDYYVPDYIPQDTDLLCAFRIQPRGVDMIEAAAAVAAESSTGTWTEVWSNQLTDIDFYKAKVYAITGDIAYIAYPLDLFEENSVVNIMSSIVGNVFGFKAVGALRLEDMRIPLALVKTFPGPRVGIYDERVWSNKWDRPLIGGTVKPKLGLSPKAYSTIIYECLSGGLDTSKDDENMNSQPFSRWRDRFMYAQEAVDRAAAETNEFKGHWHNVTAGSTEESLRRLEYAYELGSRMVMFDFLTAGFAASADIFKRAGELDMIVHCHRAMHAVFTRQANHGIAMRVVAKWLRLTGGDHLHTGTVVGKLEGSWNDTLGIIDILRERYVKANLEHGLYFDQDFGGLKASWPVASGGIHVHHVPDLLKIYGNDAFFLFGGGTHGHPDGSRAGAIANRAAVEAVSAGQTLQQAARSCPELRKSLELWADVKFEVVQ"
        ],
        [
         "2378",
         "352",
         "SUMO",
         "MDQSNRYADLSLKEEDLIKGGNHLLVAYRLKPAAGYGFLEAAAHVAAESSTGTNVEVSTTDDFTKGVDALVYEIDEAKGLMKIAYPVDLFDRNLIDGRANIAHMLTLIIGNNQGMGDIEGLKMLDFYVPPKMLRRFDGPAVNISDMWKILGRPVEDGGYIAGTIIKPKLGLRPEPFAEACYQFWLGGDFIKNDEPQANQPFCPMEKVIPLVAEAMDRAQDETGQAKLFSANITADDHEEMIKRGEYVLETFGPNASHVAFLVDGFVAGPAAVTTARRNFPNTFLHFHRAGHGAVTSPQSPMGYTALVLMKLARLMGASGIHTGTMGYGKMEGDADEKVIAYMLERDECQGPFFHQEWYGMKPTTPIISGGMNALRLPGFFENLGHGNVINTAGGGSYGHIDSPAAGAVSLRQAYECWKSGADPIEYAKEHKEFARAFESFPKDADKIFPGWREKLGVHK",
         null,
         "0",
         "352-SUMO",
         "MDQSNRYADLSLKEEDLIKGGNHLLVAYRLKPAAGYGFLEAAAHVAAESSTGTNVEVSTTDDFTKGVDALVYEIDEAKGLMKIAYPVDLFDRNLIDGRANIAHMLTLIIGNNQGMGDIEGLKMLDFYVPPKMLRRFDGPAVNISDMWKILGRPVEDGGYIAGTIIKPKLGLRPEPFAEACYQFWLGGDFIKNDEPQANQPFCPMEKVIPLVAEAMDRAQDETGQAKLFSANITADDHEEMIKRGEYVLETFGPNASHVAFLVDGFVAGPAAVTTARRNFPNTFLHFHRAGHGAVTSPQSPMGYTALVLMKLARLMGASGIHTGTMGYGKMEGDADEKVIAYMLERDECQGPFFHQEWYGMKPTTPIISGGMNALRLPGFFENLGHGNVINTAGGGSYGHIDSPAAGAVSLRQAYECWKSGADPIEYAKEHKEFARAFESFPKDADKIFPGWREKLGVHK"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 79
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSU_id</th>\n",
       "      <th>SSU_id</th>\n",
       "      <th>lsu_seq</th>\n",
       "      <th>ssu_seq</th>\n",
       "      <th>activity_binary</th>\n",
       "      <th>LSU_SSU_id</th>\n",
       "      <th>LSU_SSU_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>337</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MAQQKEYVDLNLKDEDLVKNGNHLLAVFHLKPAGGLDLLEAASEVA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>337-SUMO</td>\n",
       "      <td>MAQQKEYVDLNLKDEDLVKNGNHLLAVFHLKPAGGLDLLEAASEVA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>435</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MQTNSQTKAQFQAGVREYRETYYDPGYTPKDTDILAAFRVTPQPGV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>435-SUMO</td>\n",
       "      <td>MQTNSQTKAQFQAGVREYRETYYDPGYTPKDTDILAAFRVTPQPGV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>495</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MQTNSQTKALFDAGVREYRETYYDPGYVPKDTDVLAAFRVTPQPGV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>495-SUMO</td>\n",
       "      <td>MQTNSQTKALFDAGVREYRETYYDPGYVPKDTDVLAAFRVTPQPGV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>348</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MQKEYLNLGDQSVNNGQYLLAVFHIVPAGGLNLADAATEIAAESST...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>348-SUMO</td>\n",
       "      <td>MQKEYLNLGDQSVNNGQYLLAVFHIVPAGGLNLADAATEIAAESST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>366</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MSERYTDFVDLNYTPGENDLICTFRIEPADGISLEEAAGRVASESS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>366-SUMO</td>\n",
       "      <td>MSERYTDFVDLNYTPGENDLICTFRIEPADGISLEEAAGRVASESS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>597</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MMAKTYQAGVKDYRETYWEPDYTPKDTDILACFKITPQPGVPREEA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>597-SUMO</td>\n",
       "      <td>MMAKTYQAGVKDYRETYWEPDYTPKDTDILACFKITPQPGVPREEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>331</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MAENDLIATYHIEDGVDLEKAAQEIAAEQSTGTWTDVSTEQELVEK...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>331-SUMO</td>\n",
       "      <td>MAENDLIATYHIEDGVDLEKAAQEIAAEQSTGTWTDVSTEQELVEK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>404</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MSMRYTDFVDLNYTPKENDVLACFYVEPAEGVDIEEAAGAVASESS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>404-SUMO</td>\n",
       "      <td>MSMRYTDFVDLNYTPKENDVLACFYVEPAEGVDIEEAAGAVASESS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>440</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MSGSTTSEEEKERWSAGVIPYAKMGYWEPDYEPKDTDILAAFRITP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>440-SUMO</td>\n",
       "      <td>MSGSTTSEEEKERWSAGVIPYAKMGYWEPDYEPKDTDILAAFRITP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>453</td>\n",
       "      <td>SUMO</td>\n",
       "      <td>MNDMTTTQITDAKERYKAGVLKYRQMGYWQPDYTPKDTDIIALFRI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>453-SUMO</td>\n",
       "      <td>MNDMTTTQITDAKERYKAGVLKYRQMGYWQPDYTPKDTDIIALFRI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LSU_id SSU_id                                            lsu_seq ssu_seq  \\\n",
       "246     337   SUMO  MAQQKEYVDLNLKDEDLVKNGNHLLAVFHLKPAGGLDLLEAASEVA...     NaN   \n",
       "594     435   SUMO  MQTNSQTKAQFQAGVREYRETYYDPGYTPKDTDILAAFRVTPQPGV...     NaN   \n",
       "660     495   SUMO  MQTNSQTKALFDAGVREYRETYYDPGYVPKDTDVLAAFRVTPQPGV...     NaN   \n",
       "787     348   SUMO  MQKEYLNLGDQSVNNGQYLLAVFHIVPAGGLNLADAATEIAAESST...     NaN   \n",
       "861     366   SUMO  MSERYTDFVDLNYTPGENDLICTFRIEPADGISLEEAAGRVASESS...     NaN   \n",
       "...     ...    ...                                                ...     ...   \n",
       "2567    597   SUMO  MMAKTYQAGVKDYRETYWEPDYTPKDTDILACFKITPQPGVPREEA...     NaN   \n",
       "2633    331   SUMO  MAENDLIATYHIEDGVDLEKAAQEIAAEQSTGTWTDVSTEQELVEK...     NaN   \n",
       "2645    404   SUMO  MSMRYTDFVDLNYTPKENDVLACFYVEPAEGVDIEEAAGAVASESS...     NaN   \n",
       "2652    440   SUMO  MSGSTTSEEEKERWSAGVIPYAKMGYWEPDYEPKDTDILAAFRITP...     NaN   \n",
       "2666    453   SUMO  MNDMTTTQITDAKERYKAGVLKYRQMGYWQPDYTPKDTDIIALFRI...     NaN   \n",
       "\n",
       "      activity_binary LSU_SSU_id  \\\n",
       "246                 0   337-SUMO   \n",
       "594                 1   435-SUMO   \n",
       "660                 1   495-SUMO   \n",
       "787                 1   348-SUMO   \n",
       "861                 1   366-SUMO   \n",
       "...               ...        ...   \n",
       "2567                1   597-SUMO   \n",
       "2633                0   331-SUMO   \n",
       "2645                0   404-SUMO   \n",
       "2652                0   440-SUMO   \n",
       "2666                0   453-SUMO   \n",
       "\n",
       "                                            LSU_SSU_seq  \n",
       "246   MAQQKEYVDLNLKDEDLVKNGNHLLAVFHLKPAGGLDLLEAASEVA...  \n",
       "594   MQTNSQTKAQFQAGVREYRETYYDPGYTPKDTDILAAFRVTPQPGV...  \n",
       "660   MQTNSQTKALFDAGVREYRETYYDPGYVPKDTDVLAAFRVTPQPGV...  \n",
       "787   MQKEYLNLGDQSVNNGQYLLAVFHIVPAGGLNLADAATEIAAESST...  \n",
       "861   MSERYTDFVDLNYTPGENDLICTFRIEPADGISLEEAAGRVASESS...  \n",
       "...                                                 ...  \n",
       "2567  MMAKTYQAGVKDYRETYWEPDYTPKDTDILACFKITPQPGVPREEA...  \n",
       "2633  MAENDLIATYHIEDGVDLEKAAQEIAAEQSTGTWTDVSTEQELVEK...  \n",
       "2645  MSMRYTDFVDLNYTPKENDVLACFYVEPAEGVDIEEAAGAVASESS...  \n",
       "2652  MSGSTTSEEEKERWSAGVIPYAKMGYWEPDYEPKDTDILAAFRITP...  \n",
       "2666  MNDMTTTQITDAKERYKAGVLKYRQMGYWQPDYTPKDTDIIALFRI...  \n",
       "\n",
       "[79 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset_large_subet[combined_dataset_large_subet.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, sequences, binary_activity, tokenizer, max_length=1024):\n",
    "        self.sequences = sequences\n",
    "        self.binary_activity = binary_activity\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx][:self.max_length]\n",
    "        binding_site = self.binary_activity[idx]\n",
    "        encoding = self.tokenizer(sequence, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        encoding['labels'] = binding_site # + [-100] * (self.max_length - len(binding_site))  # Ignore extra padding tokens\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 20, 5, 9, 13, 10, 4, 7, 5, 11, 19, 21, 12, 9, 13, 6, 5, 13, 4, 9, 15, 5, 5, 16, 16, 12, 5, 5, 9, 16, 8, 11, 6, 11, 22, 11, 9, 7, 14, 11, 9, 11, 9, 9, 4, 10, 9, 10, 21, 5, 5, 10, 7, 7, 13, 12, 9, 9, 4, 6, 6, 6, 6, 17, 10, 7, 11, 12, 5, 19, 14, 4, 9, 17, 18, 6, 14, 17, 12, 14, 16, 4, 4, 8, 11, 12, 20, 6, 17, 4, 18, 6, 20, 8, 5, 4, 15, 6, 7, 10, 4, 4, 13, 12, 21, 18, 14, 14, 8, 18, 4, 15, 8, 18, 14, 6, 14, 15, 18, 6, 12, 9, 6, 7, 10, 15, 4, 4, 6, 7, 19, 13, 10, 14, 4, 12, 6, 11, 12, 12, 15, 14, 15, 12, 6, 4, 8, 14, 9, 9, 4, 5, 9, 7, 5, 19, 16, 5, 5, 4, 6, 6, 12, 13, 4, 12, 15, 13, 13, 9, 12, 4, 5, 13, 16, 14, 18, 23, 14, 18, 9, 9, 10, 7, 15, 5, 7, 20, 9, 5, 4, 13, 15, 5, 9, 9, 9, 11, 6, 15, 15, 11, 4, 19, 5, 7, 17, 12, 11, 5, 14, 5, 13, 9, 20, 7, 9, 10, 5, 9, 4, 5, 7, 13, 4, 6, 5, 17, 5, 7, 20, 12, 17, 7, 4, 11, 7, 6, 4, 8, 5, 4, 16, 5, 4, 10, 9, 13, 12, 17, 4, 14, 12, 21, 5, 21, 10, 5, 20, 21, 6, 5, 18, 11, 10, 17, 14, 9, 21, 6, 12, 8, 18, 10, 7, 4, 5, 15, 4, 20, 10, 4, 5, 6, 5, 13, 16, 4, 21, 7, 6, 11, 18, 6, 6, 15, 20, 5, 21, 14, 15, 9, 9, 7, 4, 5, 11, 5, 13, 5, 4, 10, 16, 14, 22, 19, 17, 4, 15, 14, 7, 18, 14, 7, 5, 8, 6, 6, 4, 21, 14, 6, 20, 7, 14, 5, 4, 4, 9, 10, 18, 6, 11, 13, 12, 12, 4, 5, 5, 6, 6, 6, 12, 21, 6, 21, 14, 13, 6, 14, 10, 5, 6, 5, 15, 5, 18, 10, 16, 5, 12, 9, 5, 5, 20, 9, 6, 7, 14, 4, 9, 9, 19, 5, 15, 13, 21, 14, 9, 4, 5, 10, 5, 4, 9, 15, 22, 6, 14, 11, 10, 20, 16, 5, 19, 16, 16, 8, 16, 15, 11, 6, 11, 18, 8, 19, 4, 14, 14, 20, 11, 5, 9, 16, 7, 11, 5, 16, 12, 16, 19, 23, 4, 9, 15, 6, 22, 5, 12, 23, 12, 9, 21, 11, 9, 14, 9, 17, 14, 10, 17, 17, 19, 22, 13, 20, 22, 6, 5, 14, 20, 18, 6, 9, 6, 13, 11, 16, 5, 12, 4, 5, 9, 12, 9, 5, 23, 21, 9, 5, 21, 14, 17, 21, 21, 7, 10, 4, 11, 5, 19, 13, 17, 19, 5, 16, 17, 8, 10, 20, 8, 18, 7, 7, 21, 10, 14, 5, 10, 10, 2, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], 'labels': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_train_test(Xs, ys, headers, random_seed, fraction=0.8):\n",
    "    lsu_list = [x.split(\"-\")[0] for x in headers]\n",
    "    lsu_list_uniq = pd.Series(lsu_list).unique().copy()\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(lsu_list_uniq)\n",
    "    train_size = int(len(lsu_list_uniq) * fraction)\n",
    "    train_set = lsu_list_uniq[:train_size]\n",
    "    test_set = lsu_list_uniq[train_size:]\n",
    "    train_indices = [i for i, x in enumerate(lsu_list) if x in train_set]\n",
    "    test_indices = [i for i, x in enumerate(lsu_list) if x in test_set]\n",
    "\n",
    "    Xs_train = [Xs[i] for i in train_indices]\n",
    "    Xs_test = [Xs[i] for i in test_indices]\n",
    "    ys_train = [ys[i] for i in train_indices]\n",
    "    ys_test = [ys[i] for i in test_indices]\n",
    "    return train_indices, test_indices, train_set, test_set, Xs_train, Xs_test, ys_train, ys_test\n",
    "\n",
    "train_indices, test_indices, train_ids, test_ids, Xs_train, Xs_test, ys_train, ys_test = generate_train_test(sequences, binary_activity, lsu_ssu_ids, 42)\n",
    "\n",
    "train_dataset = ProteinDataset(Xs_train, ys_train, tokenizer)\n",
    "val_dataset = ProteinDataset(Xs_test, ys_test, tokenizer)\n",
    "train_dataset, val_dataset = accelerator.prepare(train_dataset, val_dataset)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ProteinDataset at 0x7feafd430e10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2276, 402)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequences), len(val_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the finetuned model to the mutant dataset (test set) to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/kaustubh/RuBisCO_ML/ESM_LoRA/training_runs/esm2_t33_650M-finetuned-lora_2025-05-09_03-56-15\"\n",
    "base_model_path = \"facebook/esm2_t33_650M_UR50D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomModel(EsmPreTrainedModel):\n",
    "#     def __init__(self):\n",
    "#         super().__init__(EsmConfig.from_pretrained(\"facebook/esm2_t33_650M_UR50D\"))\n",
    "#         self.backbone = EsmModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "#         self.outputs = torch.nn.Linear(1280, 1)\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         input_ids,\n",
    "#         attention_mask=None,\n",
    "#         token_type_ids=None,\n",
    "#         position_ids=None,\n",
    "#         labels=None,\n",
    "#         inputs_embeds=None,\n",
    "#         output_attentions=False,\n",
    "#         output_hidden_states=False,\n",
    "#         return_dict=True\n",
    "#     ):\n",
    "#         outputs = self.backbone(\n",
    "#             input_ids,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "#             output_attentions=output_attentions,\n",
    "#             output_hidden_states=output_hidden_states,\n",
    "#             return_dict=return_dict\n",
    "#         )\n",
    "\n",
    "#         sequence_output = outputs.last_hidden_state # (B, L, 1280)\n",
    "#         bos_emb = sequence_output[:,0] # (B, L, 1280) -> (B, 1280)\n",
    "#         # outputs = [self.outputs[i](sequence_output) for i in range(5)]\n",
    "#         pred = self.outputs(bos_emb).squeeze(1) # (B,)\n",
    "\n",
    "#         # if labels, then we are training\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             assert pred.shape == labels.shape, f\"{pred}, {labels}\"\n",
    "#             loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "#             loss = loss_fn(pred, labels.float())\n",
    "#             # loss = sum(losses)/len(losses)\n",
    "\n",
    "#         return {\n",
    "#             \"loss\": loss,\n",
    "#             \"last_hidden_state\": sequence_output,\n",
    "#             \"logits\": pred\n",
    "#         }\n",
    "\n",
    "#     def get_embedding(\n",
    "#         self,\n",
    "#         input_ids,\n",
    "#         attention_mask=None,\n",
    "#         token_type_ids=None,\n",
    "#         position_ids=None,\n",
    "#         labels=None,\n",
    "#         inputs_embeds=None,\n",
    "#         output_attentions=False,\n",
    "#         output_hidden_states=False,\n",
    "#         return_dict=True\n",
    "#     ):\n",
    "#         outputs = self.backbone(\n",
    "#             input_ids,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "#             output_attentions=output_attentions,\n",
    "#             output_hidden_states=output_hidden_states,\n",
    "#             return_dict=return_dict\n",
    "#         )\n",
    "\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(EsmPreTrainedModel):\n",
    "    def __init__(self, model=None):\n",
    "        print(torch.cuda.memory_stats())\n",
    "        super().__init__(EsmConfig.from_pretrained(\"facebook/esm2_t33_650M_UR50D\"))\n",
    "        self.backbone = EsmModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "        self.outputs = torch.nn.Linear(1280, 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        labels=None,\n",
    "        inputs_embeds=None,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        return_dict=True\n",
    "    ):\n",
    "        outputs = self.backbone(\n",
    "            input_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs.last_hidden_state # (B, L, 1280)\n",
    "\n",
    "        ## Following for getting the BOS token embedding\n",
    "        # bos_emb = sequence_output[:,0] # (B, L, 1280) -> (B, 1280)\n",
    "        # # outputs = [self.outputs[i](sequence_output) for i in range(5)]\n",
    "        # outputs = self.outputs(bos_emb).squeeze(1) # (B,)\n",
    "\n",
    "        ## Following for getting the mean of the sequence embeddings\n",
    "        mask_sum = attention_mask.sum(dim=1, keepdim=True).float()\n",
    "        mean_emb = (sequence_output * attention_mask.unsqueeze(-1)).sum(dim=1) / mask_sum\n",
    "        outputs = self.outputs(mean_emb).squeeze(1) # (B,)\n",
    "\n",
    "        # if labels, then we are training\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            assert outputs.shape == labels.shape, f\"{outputs}, {labels}\"\n",
    "            loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            # loss = sum(losses)/len(losses)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"last_hidden_state\": sequence_output,\n",
    "            \"logits\": outputs\n",
    "        }\n",
    "\n",
    "    def get_embedding(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        labels=None,\n",
    "        inputs_embeds=None,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        return_dict=True\n",
    "    ):\n",
    "        outputs = self.backbone(\n",
    "            input_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict\n",
    "        )\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'active.all.allocated': 97139033, 'active.all.current': 2, 'active.all.freed': 97139031, 'active.all.peak': 12085, 'active.large_pool.allocated': 59848562, 'active.large_pool.current': 2, 'active.large_pool.freed': 59848560, 'active.large_pool.peak': 2903, 'active.small_pool.allocated': 37290471, 'active.small_pool.current': 0, 'active.small_pool.freed': 37290471, 'active.small_pool.peak': 9282, 'active_bytes.all.allocated': 1522626385710592, 'active_bytes.all.current': 17039360, 'active_bytes.all.freed': 1522626368671232, 'active_bytes.all.peak': 45553500160, 'active_bytes.large_pool.allocated': 1517876792433664, 'active_bytes.large_pool.current': 17039360, 'active_bytes.large_pool.freed': 1517876775394304, 'active_bytes.large_pool.peak': 45225992192, 'active_bytes.small_pool.allocated': 4749593276928, 'active_bytes.small_pool.current': 0, 'active_bytes.small_pool.freed': 4749593276928, 'active_bytes.small_pool.peak': 328572928, 'allocated_bytes.all.allocated': 1522626385710592, 'allocated_bytes.all.current': 17039360, 'allocated_bytes.all.freed': 1522626368671232, 'allocated_bytes.all.peak': 45553500160, 'allocated_bytes.large_pool.allocated': 1517876792433664, 'allocated_bytes.large_pool.current': 17039360, 'allocated_bytes.large_pool.freed': 1517876775394304, 'allocated_bytes.large_pool.peak': 45225992192, 'allocated_bytes.small_pool.allocated': 4749593276928, 'allocated_bytes.small_pool.current': 0, 'allocated_bytes.small_pool.freed': 4749593276928, 'allocated_bytes.small_pool.peak': 328572928, 'allocation.all.allocated': 97139033, 'allocation.all.current': 2, 'allocation.all.freed': 97139031, 'allocation.all.peak': 12085, 'allocation.large_pool.allocated': 59848562, 'allocation.large_pool.current': 2, 'allocation.large_pool.freed': 59848560, 'allocation.large_pool.peak': 2903, 'allocation.small_pool.allocated': 37290471, 'allocation.small_pool.current': 0, 'allocation.small_pool.freed': 37290471, 'allocation.small_pool.peak': 9282, 'inactive_split.all.allocated': 43145703, 'inactive_split.all.current': 3, 'inactive_split.all.freed': 43145700, 'inactive_split.all.peak': 1007, 'inactive_split.large_pool.allocated': 31798122, 'inactive_split.large_pool.current': 3, 'inactive_split.large_pool.freed': 31798119, 'inactive_split.large_pool.peak': 649, 'inactive_split.small_pool.allocated': 11347581, 'inactive_split.small_pool.current': 0, 'inactive_split.small_pool.freed': 11347581, 'inactive_split.small_pool.peak': 359, 'inactive_split_bytes.all.allocated': 852780244335104, 'inactive_split_bytes.all.current': 27000832, 'inactive_split_bytes.all.freed': 852780217334272, 'inactive_split_bytes.all.peak': 2713252864, 'inactive_split_bytes.large_pool.allocated': 847474279012352, 'inactive_split_bytes.large_pool.current': 27000832, 'inactive_split_bytes.large_pool.freed': 847474252011520, 'inactive_split_bytes.large_pool.peak': 2701736960, 'inactive_split_bytes.small_pool.allocated': 5305965322752, 'inactive_split_bytes.small_pool.current': 0, 'inactive_split_bytes.small_pool.freed': 5305965322752, 'inactive_split_bytes.small_pool.peak': 46248448, 'max_split_size': -1, 'num_alloc_retries': 1, 'num_device_alloc': 3518, 'num_device_free': 1900, 'num_ooms': 0, 'num_sync_all_streams': 24, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 1522306055927972, 'requested_bytes.all.current': 17039360, 'requested_bytes.all.freed': 1522306038888612, 'requested_bytes.all.peak': 44722844508, 'requested_bytes.large_pool.allocated': 1517561612074320, 'requested_bytes.large_pool.current': 17039360, 'requested_bytes.large_pool.freed': 1517561595034960, 'requested_bytes.large_pool.peak': 44395520000, 'requested_bytes.small_pool.allocated': 4744443853652, 'requested_bytes.small_pool.current': 0, 'requested_bytes.small_pool.freed': 4744443853652, 'requested_bytes.small_pool.peak': 328391500, 'reserved_bytes.all.allocated': 206517043200, 'reserved_bytes.all.current': 46514831360, 'reserved_bytes.all.freed': 160002211840, 'reserved_bytes.all.peak': 46523219968, 'reserved_bytes.large_pool.allocated': 205831274496, 'reserved_bytes.large_pool.current': 46183481344, 'reserved_bytes.large_pool.freed': 159647793152, 'reserved_bytes.large_pool.peak': 46191869952, 'reserved_bytes.small_pool.allocated': 685768704, 'reserved_bytes.small_pool.current': 331350016, 'reserved_bytes.small_pool.freed': 354418688, 'reserved_bytes.small_pool.peak': 331350016, 'segment.all.allocated': 3518, 'segment.all.current': 1618, 'segment.all.freed': 1900, 'segment.all.peak': 1644, 'segment.large_pool.allocated': 3191, 'segment.large_pool.current': 1460, 'segment.large_pool.freed': 1731, 'segment.large_pool.peak': 1486, 'segment.small_pool.allocated': 327, 'segment.small_pool.current': 158, 'segment.small_pool.freed': 169, 'segment.small_pool.peak': 158})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForTokenClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): CustomModel(\n",
       "      (backbone): EsmModel(\n",
       "        (embeddings): EsmEmbeddings(\n",
       "          (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "        )\n",
       "        (encoder): EsmEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-32): 33 x EsmLayer(\n",
       "              (attention): EsmAttention(\n",
       "                (self): EsmSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (rotary_embeddings): RotaryEmbedding()\n",
       "                )\n",
       "                (output): EsmSelfOutput(\n",
       "                  (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (intermediate): EsmIntermediate(\n",
       "                (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (output): EsmOutput(\n",
       "                (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pooler): EsmPooler(\n",
       "          (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "        (contact_head): EsmContactPredictionHead(\n",
       "          (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (outputs): Linear(in_features=1280, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = CustomModel()\n",
    "loaded_model = PeftModel.from_pretrained(base_model, model_path).to(torch.device(\"cuda:0\"))\n",
    "loaded_model.eval()\n",
    "# Load base_model_path to base_model\n",
    "# base_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "formIII_mutants = combined_dataset.query('LSU_id.str.startswith(\"Anc3\")')\n",
    "formIII_seqs = formIII_mutants['LSU_SSU_seq'].to_list()\n",
    "formIII_labels = formIII_mutants['activity_binary'].to_list()\n",
    "formIII_ids = formIII_mutants['LSU_SSU_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m [formIII_labels[i]]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Sigmoid activation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/peft_model.py:2314\u001b[0m, in \u001b[0;36mPeftModelForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   2312\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   2313\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 2314\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2315\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2317\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2319\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2325\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, labels, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     11\u001b[0m     input_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m ):\n\u001b[0;32m---> 21\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state \u001b[38;5;66;03m# (B, L, 1280)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m## Following for getting the BOS token embedding\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# bos_emb = sequence_output[:,0] # (B, L, 1280) -> (B, 1280)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# # outputs = [self.outputs[i](sequence_output) for i in range(5)]\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# outputs = self.outputs(bos_emb).squeeze(1) # (B,)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m## Following for getting the mean of the sequence embeddings\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/transformers/models/esm/modeling_esm.py:900\u001b[0m, in \u001b[0;36mEsmModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    898\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 900\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    908\u001b[0m     embedding_output,\n\u001b[1;32m    909\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    917\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    918\u001b[0m )\n\u001b[1;32m    919\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/transformers/models/esm/modeling_esm.py:196\u001b[0m, in \u001b[0;36mEsmEmbeddings.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    193\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_position_ids_from_inputs_embeds(inputs_embeds)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Note that if we want to support ESM-1 (not 1b!) in future then we need to support an\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# embedding_scale factor here.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/lora_esm/lib/python3.13/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "output_pred_formIII = []\n",
    "output_emb_formIII = []\n",
    "\n",
    "for i in range(len(formIII_seqs)):\n",
    "    inputs = loaded_tokenizer(formIII_seqs[i], truncation=True, padding='max_length', max_length=1024, return_tensors=\"pt\")\n",
    "    labels = [formIII_labels[i]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"].squeeze(0)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        # Sigmoid activation\n",
    "        outputs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        output_pred_formIII.append(outputs)\n",
    "        # print(outputs, labels)\n",
    "        outputs_emb = loaded_model(**inputs)[\"last_hidden_state\"].squeeze(0)[0]\n",
    "        outputs_emb = outputs_emb.cpu().numpy()\n",
    "\n",
    "        output_emb_formIII.append(outputs_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anc367_mutant_7-none 0.39452004 0\n",
      "Anc367_mutant_10-none 0.39413607 0\n",
      "Anc367_mutant_15-none 0.5660141 1\n",
      "Anc367_mutant_17-none 0.39281946 0\n",
      "Anc367_mutant_20-none 0.39457932 1\n",
      "Anc367_mutant_26-none 0.43341178 1\n",
      "Anc367_mutant_29-none 0.3943195 0\n",
      "Anc367_mutant_38-none 0.3946639 1\n",
      "Anc367_mutant_39-none 0.39664474 0\n",
      "Anc367_mutant_42-none 0.39815158 0\n",
      "Anc366-none 0.5675697 1\n",
      "Anc367-none 0.39563125 0\n",
      "Anc393_mutant_4-none 0.5494187 1\n",
      "Anc393_mutant_11-none 0.55009073 1\n",
      "Anc393_mutant_12-none 0.54990363 1\n",
      "Anc393_mutant_13-none 0.547416 0\n",
      "Anc393_mutant_14-none 0.551925 1\n",
      "Anc393_mutant_15-none 0.54683113 1\n",
      "Anc393_mutant_16-none 0.5454568 1\n",
      "Anc393_mutant_18-none 0.55009997 1\n",
      "Anc393_mutant_19-none 0.5475726 1\n",
      "Anc393_mutant_21-none 0.5477891 0\n",
      "Anc393_mutant_22-none 0.54851604 1\n",
      "Anc393_mutant_25-none 0.55237514 0\n",
      "Anc393_mutant_27-none 0.55394256 1\n",
      "Anc393_mutant_28-none 0.55300885 1\n",
      "Anc393_mutant_29-none 0.5450992 1\n",
      "Anc393_mutant_30-none 0.5522993 1\n",
      "Anc393_mutant_31-none 0.54972893 0\n",
      "Anc393_mutant_32-none 0.5499214 1\n",
      "Anc393_mutant_33-none 0.5506281 1\n",
      "Anc393_mutant_35-none 0.5458271 1\n",
      "Anc393_mutant_36-none 0.550998 0\n",
      "Anc393_mutant_38-none 0.5447293 1\n",
      "Anc393_mutant_41-none 0.5422887 1\n",
      "Anc393_mutant_42-none 0.55179524 1\n",
      "Anc393_mutant_43-none 0.55121505 1\n",
      "Anc393_mutant_46-none 0.55420226 1\n",
      "Anc393_mutant_47-none 0.54722315 1\n",
      "Anc393_mutant_49-none 0.5504571 1\n",
      "Anc365-none 0.5648255 1\n",
      "Anc393-none 0.5330075 0\n",
      "Anc367_mutant_0-none 0.40332586 0\n",
      "Anc367_mutant_1-none 0.5723642 1\n",
      "Anc367_mutant_2-none 0.39505202 0\n",
      "Anc367_mutant_3-none 0.39458796 0\n",
      "Anc367_mutant_4-none 0.39434353 0\n",
      "Anc367_mutant_5-none 0.54101586 1\n",
      "Anc367_mutant_6-none 0.39392382 0\n",
      "Anc367_mutant_8-none 0.39437854 0\n",
      "Anc367_mutant_9-none 0.39523163 1\n",
      "Anc367_mutant_11-none 0.39459655 1\n",
      "Anc367_mutant_12-none 0.39350465 0\n",
      "Anc367_mutant_13-none 0.39368075 1\n",
      "Anc367_mutant_14-none 0.39552772 0\n",
      "Anc367_mutant_16-none 0.39445212 1\n",
      "Anc367_mutant_18-none 0.39363936 1\n",
      "Anc367_mutant_19-none 0.5047309 0\n",
      "Anc367_mutant_21-none 0.3972884 0\n",
      "Anc367_mutant_22-none 0.3936747 0\n",
      "Anc367_mutant_23-none 0.39836788 0\n",
      "Anc367_mutant_24-none 0.3929273 0\n",
      "Anc367_mutant_25-none 0.5171405 1\n",
      "Anc367_mutant_27-none 0.42305666 1\n",
      "Anc367_mutant_28-none 0.39599586 0\n",
      "Anc367_mutant_30-none 0.3948435 1\n",
      "Anc367_mutant_31-none 0.39417106 0\n",
      "Anc367_mutant_32-none 0.39280534 0\n",
      "Anc367_mutant_33-none 0.39585793 0\n",
      "Anc367_mutant_34-none 0.5006044 1\n",
      "Anc367_mutant_35-none 0.39229006 0\n",
      "Anc367_mutant_36-none 0.39517808 0\n",
      "Anc367_mutant_37-none 0.39508668 0\n",
      "Anc367_mutant_40-none 0.500123 1\n",
      "Anc367_mutant_41-none 0.39392725 0\n",
      "Anc367_mutant_43-none 0.39448202 0\n",
      "Anc367_mutant_44-none 0.39500126 0\n",
      "Anc367_mutant_45-none 0.39652467 0\n",
      "Anc367_mutant_46-none 0.39938065 1\n",
      "Anc367_mutant_47-none 0.3930629 0\n",
      "Anc367_mutant_48-none 0.39398363 1\n",
      "Anc367_mutant_49-none 0.39440832 0\n",
      "Anc393_mutant_0-none 0.5509912 0\n",
      "Anc393_mutant_1-none 0.5454468 0\n",
      "Anc393_mutant_2-none 0.5531871 1\n",
      "Anc393_mutant_3-none 0.55219144 0\n",
      "Anc393_mutant_5-none 0.5522976 1\n",
      "Anc393_mutant_6-none 0.548946 0\n",
      "Anc393_mutant_7-none 0.54593784 1\n",
      "Anc393_mutant_8-none 0.5449565 0\n",
      "Anc393_mutant_9-none 0.54834914 0\n",
      "Anc393_mutant_10-none 0.55379885 0\n",
      "Anc393_mutant_17-none 0.5545241 1\n",
      "Anc393_mutant_20-none 0.5512623 1\n",
      "Anc393_mutant_23-none 0.5495259 1\n",
      "Anc393_mutant_24-none 0.5442112 0\n",
      "Anc393_mutant_26-none 0.54710597 1\n",
      "Anc393_mutant_34-none 0.549105 0\n",
      "Anc393_mutant_37-none 0.5532475 1\n",
      "Anc393_mutant_39-none 0.55024165 1\n",
      "Anc393_mutant_40-none 0.54661417 1\n",
      "Anc393_mutant_44-none 0.55030185 1\n",
      "Anc393_mutant_45-none 0.5441049 1\n",
      "Anc393_mutant_48-none 0.5521941 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_pred_formIII)):\n",
    "    print(formIII_ids[i], output_pred_formIII[i], formIII_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAKTCAYAAADxOSLbAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYRRJREFUeJzt3Xl8VPW9//H3OTPJZE9YshAIu7IoCKIguKGgoLhbr8UVq/TWurRiq9KfG1pF61K7WL3dpNa9teKOIqJWQVEUFQRkDxASlpBM1pnMnPP7Y0ggZGaynCSThNfz8ZiHzjnfc85nGNLm7XczbNu2BQAAAABoETPWBQAAAABAZ0aoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA64Y11ALFiWpYKCAqWmpsowjFiXAwAAACBGbNtWWVmZcnNzZZot63M6JENVQUGB8vLyYl0GAAAAgA5i69at6tOnT4uuPSRDVWpqqqTQH1xaWlqMqwEAAAAQK16vV3l5eXUZoSUOyVBVO+QvLS2NUAUAAADA0bQgFqoAAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIAD7lgXgK6lpsSr7c+/rrKV3ytQulcZxx6hnqedpNThw2JdGgAAANAmCFVoNdv+OV/f/vQOWdX+umMFL74jV/Jj6nHKCA3/zf1KPmxwDCsEAAAAWh/D/w5htm0rWFkly+9vvHEjdi74UF9ffVu9QFUrWGFpzwcrteLyq1SVv9XxswAAAICOhFB1CLIDARU8+7yWn3WOlo4/XkuOPU7fzvxf7V36aYvvue7eP0pG5PPB8qD8e8uV/+e/tvgZAAAAQEdEqDrE2IGAVs/6hTY+9LCqtxfUHS/9YrlW/eSn2vHSv5t9z+odO1Wy7BvJsqO2C5TWaOebb8uqqWn2MwAAAICOilB1iCl8Zb6KP/xIsu3Qq5ZlSZI23D9X1QUFEa4OL1he2aR2tmXLrqlRsLy8WfcHAAAAOjJC1SFmx/MvSEbkcXq2ZWn1zbObdc+E3tkyExMabefymDLi4+VKSWnW/QEAAICOjFB1CLFtW5UbN9XvoQqj7OuvVblpS5Pv60pKVN6VF0iuKH+dDMmdEa/sc8+WGRfX5HsDAAAAHR2h6hBiGIaMJgUaQzv+Nb9Z9z78rhuU1L9PxF6whN4JiktPU98fX92s+wIAAAAdHaHqENP9pBNlR+mpMgxDVsBW9bbmzauK79ldx3/ykvpde6mM+P3BzZVoKjHPo54nH6vRz85TQq9eLa4dAAAA6IjY/PcQ02fGldq9cJFs25ZxUK+SbduSJdmWobju3Zp97/ge3XTk7+7QsAdvUdWWbarYsEGueLeSBg1U0oD+rfQJAAAAgI4l5j1V/fv3Dw1LO+h13XXXhW0/b968Bm0TEhpfJAEhqSOOVOqoMZJCIar2JUmypJqKoOxAUNnnntniZ7gSPEoZMkjZZ56unpNPJVABAACgS4t5T9Xnn3+uYDBY937lypU67bTTdNFFF0W8Ji0tTWvXrq17f3CPC6I7fM7t+nza/8gO+mTsi9VWjSU7YEumqZ6TTlLaqBGxLRIAAADoJGIeqjIzM+u9f+CBBzRo0CCdfPLJEa8xDEM5OTltXVqXlTSgn0a/+JRW3XCLqjbnS6Yp2ZIMQ9nnTdPQ++8gqAIAAABNFPNQdSC/369nnnlGs2bNivpLfXl5ufr16yfLsnT00Ufr/vvv1xFHHBGxvc/nk8/nq3vv9Xpbte7OKG3EcB23+HWVLP1c5Wu+l+nxqMcpJyohl7AKAAAANEeHClXz589XSUmJZsyYEbHNkCFD9Pe//10jR45UaWmpHn74YU2YMEGrVq1Snz59wl4zd+5czZkzp42q7rwMw1C3CWPVbcLYWJcCAAAAdFqGHW197XY2ZcoUxcfH6/XXX2/yNTU1NRo2bJimT5+ue++9N2ybcD1VeXl5Ki0tVVpamuO6AQAAAHROXq9X6enpjrJBh+mp2rJli9577z395z//adZ1cXFxGj16tNavXx+xjcfjkcfjcVoiAAAAADQQ8yXVaz311FPKysrStGnTmnVdMBjUt99+q15sKgsAAAAgBjpEqLIsS0899ZSuvPJKud31O8+uuOIKzZ49u+79Pffco3fffVcbN27Ul19+qcsuu0xbtmzRNddc095lAwAAAEDHGP733nvvKT8/Xz/60Y8anMvPz5dp7s9+e/fu1cyZM1VYWKhu3bppzJgxWrJkiYYPH96eJQMAAACApA62UEV7aY3JaAAAAAA6v9bIBh1i+B8AAAAAdFaEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADjQIZZUR+PsYFD+gm2yAzWKz+0j05MQ65IAAAAAiFDV4dm2rb1vv6o9r7yoQPFuSZKRkKBuk6cpc/qVMhMSY1whAAAAcGgjVHVwRU89ob1vvlLvmF1dreK3XlHl99+p35yHZcbHx6g6AAAAAMyp6sCqNnzfIFDVsSxVr1ujkoVvtm9RAAAAAOohVHVgJe+9LZmuqG32vvN6O1UDAAAAIBxCVQfmL9gmWcHIDWxbNUWF7VcQAAAAgAYIVR2YKyVVMqN/RWZSUjtVAwAAACAcQlUHlnbCRMmyIjcwTaWfNLnd6gEAAADQEKGqA0sZdaxc6RnhT5qmzIREdZ92frvWBAAAAKA+QlUHZQeD2v67uQqWlYY9b7jd6nvXg4rLym7nygAAAAAciFDVQZV/sVQVyz+VIckwDYX+Zf/LrvGrpmhHbIsEAAAAQKjqqEree6veIhWGYcgwjNAbO/QqePxh7fznX+TfyQqAAAAAQKwQqjoof2FBg0UqbNsOBara9z6f9rz2b2288WqVf728nSsEAAAAIBGqOixXappCY/1CDg5UdSxLdqBG2x64S4HSve1WHwAAAIAQQlUHFVoq/cBuqSiNbVt2jV8li95p67IAAAAAHIRQ1UGlnTxZcdm9JNPVtAtsW5Wrvm7bogAAAAA04I51AQip3rJJpYveln/HNrmSU5V6/MnKu/NBFfxurqq/Xx3r8gAAAABEQKiKMdu2tevZv6n41ZdCvVJWUDJNeT9ZLM/Aw5T3/+5Xza4iFfzuAfkLtkl2hHGAhqGkI0a2b/EAAAAAGP4XayUL3wwFKikUqKS6Vf98mzeo4NFfK3HQ4cq5+vr6gcoI7V9V93K7lTFpajtXDwAAAIBQFUO2ZWnPKy9EbmBZqlz1tao3rlPyUUcr6/JrJEmGy5TpMuuClUxDhh3Unv88F1olEAAAAEC7IVTFkH/HdgV274zeyDRV/tXnkqQe512spGFHqHYP4NrNgGsXXi9Z8Jr2vvVKG1ULAAAAIBxCVQzZgUDjjQxDlq9alt8n37Ytql4XfdGK4tdekh0MtlKFAAAAABrDQhUxFJ/TS0ZCguzq6siNgkEVz39Be199Ue4emZJhRF6sQlKwZK98Wzcrof+gNqgYAAAAwMHoqYoh05OgjElnSGbTvobAnl1RA1UtO1DjtDQAAAAATUSoirHMi2coYeBhqpsodTBj/9yppjDi4hWfm9dK1QEAAABoDKEqxszERPW9+2FlXT5TcTm5oV4rlysUspoZqGSaSpt4mlxJyW1XMAAAAIB6mFMVQ8GKcpV/sVRWRZnic3I18Ld/keGO0/ofX6xgaYn2r+vXNJ68/sq85Oo2qRUAAABAeISqGLBtW8UvP6viV18MzX8yTMm2ZKakKXvmjTLiPS26b48fzqCXCgAAAGhnDP+LgT3/fkZ7Xn5m/4IStiVJssq92vHYfaE5Vk1cvKKO6VL5Zx+3cqUAAAAAGkOoamfBMq+KX3sxcgPbVsWXn+6bU9WM4X9WUMEyr/MCAQAAADQLw//aWfnnn0iNbfobDEq2GixUYdt26Hg4pktxPbNarU4AAAAATUNPVTsLlpdJpqvRduE7qYzIa1dYQaVNPN1JaQAAAABagFDVzuIysyUr2KS2B+cnw1DdUuu1DQzTqHvteGSOyr/8rDXLBQAAANAIQlU7Sx4zXqaDFfpCuWpfkDqoOyuwd48KHr5bFd986bBKAAAAAE1FqGpnZny8sq66rm1ubocmXO169i+h+VcAAAAA2hyhKgbSTjhVubPulKtbj9a/uW3Ln79J/u35rX9vAAAAAA0QqmIk5dgJGvCHf8idld28pdObqGb3zla/JwAAAICGCFUxZLrcyrvzYcXl9G71e5d9tLDV7wkAAACgIUJVjMX1yFT/3zwpd3avxhsbprpfcKnkSdj3PrT6X7hl1iu/+lTBstJWqzOwt1jF819Q4eO/UdFff6+Kr7+QbVmtdn8AAACgs2Lz3w7AcLvV4/zpKnry0ajt8u56SIlDjpBv/XeqXvNN/Y2BLVvBQGjTYNNlSsGgqtetVvLRxzmur3TRW9o570+hhTD2LYDhXbxAZkqqcmfdocQhRzp+BgAAANBZ0VPVQaSdOEnJY45rOL9q3/seF16mxCFHyPvhu/Kt/bbhDQzJFeeS6TJDvVdSXQByomLF59r59z9KltXgflZ5mbbde6sqVn7l+DkAAABAZ0Wo6iAM06Xcm+5Qz0uulrt7z7rjnr4DlHPDberxg8sUrK7S7qcfl23bDfaoqn1vuPYdN015Bg1xXFfxqy9Gb2DbKvztvbJ81Y6fBQAAAHRGDP/rQAyXS93P+oG6nXmBgt5SGS6XXKlpdecLH/u1FAw2CFR11+87bhtSytgT5c7o7qieYEW5qr//rtF2lq9a5Z/9V2knneboeQAAAEBnRKiKoUDpXlV++amsqgrFZecq6aixMtxuGaYpd0a3em39RTtUteorGaYRMVTVcmf2Us8rf+q4PrvG37SGhiHfxu8lQhUAAAAOQYSqGLCDQe158e/yvvd6aK6SaUqWJTM1XVlX/1xJo45tcI33w3ebfP+cG38lV3KK4zpdaekyU9JklXujtjMMQ4Y7zvHzAAAAgM6IOVUxsOe5v8j77muhQCXV/dMq96rw9/eqau3KBtcEdu+U3cgK5rZtS4YpT96AVqnTMF3KOP2sxhvalpKOOqZVngkAAAB0NoSqdhbYs1Pe99+UFGZlPtuWbGnvy/9scMrc1/NkW+FX9LNrV+ZLct5DdaBuZ1+kuF6RNyc2XKbi+/RX4hGjWvW5AAAAQGdBqGpn5cs+VtjdemvZlqq/X6XA3j31DqdOmFh7WlbQqgtR9gHLnFtBW57+g1u1XjPeo773/1FJR41pcM4wpfjsXsr9xRwZJn+VAAAAcGhiTlU7syrKJNOQgk1o161H3fuEwUPl6tZDwb17ZFuhHivDsCVDsvb1cElS+ilntHrNZrxHvW+5V76CbfK+94b8hdvkSkxS8jETlHLs8cynAgAAwCGNUNXO3D2zpWAjico05erWs94hwzDU66Y7tO2um+o24bVt7R9FaBiK79NPyaPHtn7R+3hy+yjzip+02f0BAACAzogxW+0sZdxJMuLiIzcwTSUfMyHs6n2Jgw5X79t+LTMxKXTAMEMrB0ryDDhMvWffJ8PlaouyAQAAAERAT1U7MxOT1OPSH2v3vD+GOWnKTExW9x/MiHh90pGjNeBPz6r8s4/l27xehjtOyaPHKmHIEY3uXwUAAACg9RGqYiBt4lSZSSkqfvlpBYoKQgcNQ0kjx6jHJT9WXFZO1OvNeI/STpwknTipHaoFAAAAEA2hKkZSxp6g5GOPV822LbKqK+XumS33AQtTAAAAAOgcCFUxZBiG4vP6x7oMR2zblm/j96r4/GNZ1VWKy+mt1ONPlSs1PdalAQAAAO2CUIUWs6oqVfTH+1W1aoVUu0CGZan4X/9Qz8t/orSJU2NaHwAAANAeWP0PLVb0xIOqWv1N6E0wGHrZthQMaPe8P6pixbLYFggAAAC0A0IVWsS3ZYOqvlkuWVb4Boahva8+375FAQAAADFAqEKLVHz5ad0eWWHZtvyb1ilQUtx+RQEAAAAxQKhCi9i+aqkJ+2LZvup2qAYAAACIHUIVWiS+d9/QHKooDE+CXCwTDwAAgC6OUIWWMRr5q2MYSj3pNJnxnvapBwAAAIgRQhWazQ7UaM/zf43eyB2nbudd2j4FAQAAADFEqEKzVX79hayKsuiNavyyykrbpyAAAAAghghVaLZA8a4mLVJRs6uoHaoBAAAAYotQhWZzpaSFNvltRM2uwnaoBgAAAIitmIequ+++W4Zh1HsNHTo06jX/+te/NHToUCUkJGjEiBF666232qlaSFLiiDFNaufP39jGlQAAAACxF/NQJUlHHHGEduzYUff6+OOPI7ZdsmSJpk+frquvvlpfffWVzjvvPJ133nlauXJlO1Z8aDPi4hof/mcYqlr9tcq/+ERWjb99CgMAAABiwLDtJozjakN333235s+frxUrVjSp/cUXX6yKigq98cYbdceOO+44jRo1Sk8++WST7uH1epWenq7S0lKlpaW1pOxDmm3byp81Q8GS4vDDAA1DhhnqdZQkmaZST56qjPMulSs5pX2LBQAAAKJojWzQIXqq1q1bp9zcXA0cOFCXXnqp8vPzI7ZdunSpJk+eXO/YlClTtHTp0ojX+Hw+eb3eei+0nGEYSp80TYZphnqsDnoZ5kG9WJalssVvacfcWxQsb2TVQAAAAKCTiXmoGjdunObNm6cFCxboiSee0KZNm3TiiSeqrCz8L9+FhYXKzs6udyw7O1uFhZEXRZg7d67S09PrXnl5ea36GQ5FaaefK8+Aw2WYrvpz4vYFKiPM8MBA0Q6VvPZ8e5cKAAAAtKmYh6ozzjhDF110kUaOHKkpU6borbfeUklJiV566aVWe8bs2bNVWlpa99q6dWur3ftQVLN7p6rXrlLG+ZcqfdqFMpOS650PF6gkSbal8o/fk+X3tUOVAAAAQPtwx7qAg2VkZOjwww/X+vXrw57PyclRUVH9/Y+KioqUk5MT8Z4ej0cej6dV6zwU1ezcoV3/eEJV3y6vO+ZKy1DKCaepbOF8SVEC1T6236fg3j0ys3PbslQAAACg3cS8p+pg5eXl2rBhg3r16hX2/Pjx47Vo0aJ6xxYuXKjx48e3R3mHrJrdO7VtzixVrfqq3vGgt0Slb70sw+VqNFDVMgi4AAAA6EJiHqp+8Ytf6MMPP9TmzZu1ZMkSnX/++XK5XJo+fbok6YorrtDs2bPr2v/sZz/TggUL9Mgjj2jNmjW6++679cUXX+j666+P1Uc4JOyd/7ysinLJssKetwKBJi2zHt9/sNwZPdqgQgAAACA2Yj78b9u2bZo+fbr27NmjzMxMnXDCCfr000+VmZkpScrPz5dp7s9+EyZM0HPPPafbb79dv/rVr3TYYYdp/vz5OvLII2P1Ebo8y+9T2ZLFEQOVJNlByUxLlVUeZWVF21bGOdPboEIAAAAgdmK+T1UssE9V8wSKd2vLz6+M3sjlUurxp8qdkSHvwtekYDB0vLb3yuVSj0t/otQTT2vbYgEAAIBmaI1sEPOeKnR8ZlKyZJpRe6pkWarZvVOJQ0co77f/lL8gX1UrPpNdXa24nN5KPu5kuVLC/yW1g0HZ1VUyEhJluFxt9CkAAACAtkGoQqPMhEQljxmviuVLIwcr21b12pXyrflGRrxH3f9nhrr/YEbU+wZ271TJ2/9WxacfyAgGZMTFK/m4iUo740K5u2e2/gcBAAAA2kDMF6pA59DtvEtkuNySEfmvjGGHApft92nPM/8n74fvRGxbtvgtbb/9WlX8912pxi/bskJztz5eqML7fqGaooJW/wwAAABAWyBUoUk8ef2Ve9v9cmdmh28QZuG/vS//U3bt3KoDlLzxooqf/7NkHXTOtqVgUMHKchX/8/FWqBoAAABoe4QqNFnCYcPU96G/KHf2XKWdemYoSBmSYRph96gKektUvXZlvWO+zetU+trz0R9kWfKtX62awm2tWD0AAADQNphThWYxDEOJw0bKt2VDkzb7LXnrZZUvWayaXQXyb14fmpNl26EwFul625YMQzXb8xWX06eVPwEAAADQughVaBH/lvVNale95msZqstJ+9mSLTtqMDPi450VCQAAALQDhv+hRXzb8pvUrjYyhc1OthRpmzQj3iPP4WzoDAAAgI6PUIUWsYOBRtsYphExNO2/UfjDqaedK9OT0ILKAAAAgPbF8D80S/X3q1Q8/zkFCrY23tgIv4BFY5LGnaz0aRe1oDoAAACg/RGq0GQVX32moj/c13YPcLnV4/KfKmXCqW33DAAAAKCVEarQJJbfp51/fkSybEUcs3egfT1Uth1lMQrDUFyvPorv00+ewcOUctwpMpOSW69oAAAAoB0QqtAkFV8skV1V2XjDeI8UCMgILe8nGRGClWHIiItX9k1z5O7Wo01qBgAAANoDC1WgSWoKtkouV6PtMq+6XmacWzL3/dWy6/1jH0OGJ0HZP7tTrpQ02VawtcsFAAAA2g09VWgSIyEhtNlUIxIOO0K5tz+sva+9oMovP5VsW4ZpyvB4ZLjj5OreU0nHnCDT5VLxs08osHOHZBhKGDZKaVPOV8IQllEHAABA50KoQpMkHz1ee//9dOQGhqH4vAFyZ3RX5eZ1cmf3Vnz/gQps3RTqtfL7ZNf4FdhWrrJdhbL9/v1DAm1b1Wu+VvV3X6n7FdcpZcKk9vlQAAAAQCsgVKFJ4nPzlHzM8apYvlSyrYYNbFvJY09U/i+ukuUtlVymzNppVJZV10aSbF916J86YMn1fW2Kn3lCCcNGMc8KAAAAnQZzqtBkmTNvUtLocaE3pis0x8owJLdbGedfqtLXX5RV5pUkGbIb3/g3HFuqWLKoFavufIJV5aopK5blr451KQAAAGgCeqrQZKYnQTk3/j/58jeqYtnHsqoqFZeTq5Txp6j4padkBwN1vVEt2fRXkmTb8m/b3HpFdyLVW1erpmhL/YPuOCUOOlru1G6xKQoAAACNIlSh2Tx9B8rTd2Dde9u2VbHso/3D/JrKtuv2s6pjGAp6S1Sx7CN5Bg2Vu0dWK1Tc8VWt+0KBkl2hNwf+mdT4VbX2MyUePlbutO6xKQ4AAABREargnG3J9vvrH4q26W+tcOdtS/6Na1S8aa0kKWHksep+2XVypaS2VrUdTqDSGz5Q1b63bVWt/1KpR09u/+IAAADQKOZUwTHDdMnVI7P+QVstm1N1kOqVy7XzsTtl+X2O79VR+Td9GwpPkUKoYUhWQMEKb/sWBgAAgCYhVKFVpJ1yZr1QYFt2XbCqF65q2xhG+J4s46D5WJalQEG+Kj/7sI0qjy3bVyWrbE+T9gALlu9th4oAAADQXIQqtIq0SWcpvt+g0J5U+9iWHQpXkuSOk6t7plzp3SXTbFqgqjtuqGJp11sR0PZVyv/hi5Kvaav8GXHxbVwRAAAAWoJQhVZhejzqdct9SjvtHBkJiXXH3Vm56jHjRvX707+Uc+sDsrx71SA2GZJhRui5kiTbVrC06/XS1KxaIruqTGb53shD/6S6XixXRnY7VQYAAIDmYKEKtBozIVE9Lv6Rup1/qQK7d8pwx8mdmV0XlqzK8ojXRl3YwjDk6tazLUqOGbvGJ2vbWsm2Zdb4FKzxS5F6ogxDrvRMmSb/DQQAAKAj4rc0tDoz3qP43DzFZeXUC0rubj3rDQ+sYzeyr5VtK3nCpDaoNHbsyjLJCta9d+3MlwI1+07a9eZYmQkpShx8dHuXCAAAgCYiVKHdmEnJShozIWywarCgRS3DVFzfQUo+9sR2qLAduePqvTVtS+7CTTJ3F0j+Kingl1FVobiEVCUfeULLN1MGAABAm2P4H9pVxnmXqXr1N6GhgPU2CzYU6rIyJXvfcdNU0jEnqNvFM7vcIg1GUpqM1O6yy4r3H5Pkqi6Xq3r/MMn40afGoDoAAAA0B6EK7crdI0s5t/1Ge1/+h6q+/qwuWMX1ylP6OZfIM2iI/Ju+l2xb8QMOlystI7YFtxHDMOQeOk41n78dqYXM3EEyU7q1a10AAABoPsNujR1aOxmv16v09HSVlpYqLS0t1uUcsoJlpQoU75KZkCR3Vq9DcohbYOM3Cnz7Uah3zjC1b3MvmTkDFHfMVBkHDRMEAABA62qNbEBPFWLGlZouV2p6rMuIKffAkXL1Hqzg1jWyK0old7xcvQ+XmZEZ69IAAADQRIQqIMYMT5LcrO4HAADQabH6HwAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABNv8FHKrJX6/Kpe8psH2TDHecPMPHKGHsKXKlZcS6NAAAALQDQhXgQMV7r6hi0SuSaUqWJUkKFG5V5cdvK+OqXyqu32ExrhAAAABtjeF/QAv5vlseClRSXaCSJNm2bL9PJfMekeWrik1xAAAAaDeEKqCFKv/7tmRE+BGybdnVlar+akn7FgUAAIB2R6gCWsC2LNVsWSfZVuRGhqGajavbrygAAADEBKEKaCnbjnUFAAAA6AAIVUALGKYpd9/BkYf/SZJtK67/4e1XFAAAAGKCUAW0UNIJUyMP/zMMGZ4EJRx9QvsWBQAAgHZHqAJayHPksUo6eVrojXnAj5JhSu44pV8xS2ZCUmyKAwAAQLthnyqghQzDUMrUixV/+EhVLlmowLZNMtxueY48RonjJsnVrWesSwQAAEA7IFQBDsUPHKb4gcNiXQYAAABihFAFNIFt27JKdkk1fpnpPWR4EmNdEgAAADoIQhXQCP+aL+Vb8ras4p2hA6ZLccPGKOGkc2Qmp8a2OAAAAMQcC1UAUfiWf6CqN/6xP1BJkhVUzXdfqPy538qqLI9dcQAAAOgQCFVABFaFV9UfvBr+pG3J9u6V79N32rcoAAAAdDiEKiCCmlWfS7IjN7At+b/9THYw2G41AQAAoOMhVAERWCW7JcOI3qjGJ7u6on0KAgAAQIdEqAIiadIKf4aMOE+blwIAAICOi9X/cEgKlpeqatmHCmzfLLnc8gwfrYQjj5Xh3v8jET90tPyfL4p8E8OUe8AwGfGEKgAAgEMZoQqHnKoVS1X6wpOSZYUOGIaqv1qism491f3Ht8ndM0eS5MrOk3vQCAU2rpTsg+dWGZIhecZPad/iAQAA0OEQqtDpBPbuVsUn76nq2y+kQEDxA4co5cQpiu87sNFr/fnrVfrcn+qHpH3/bpUWq/j/5irz1odluOMkSUlnXaHKBc8psPar0Pwqw5AsS0ZCkhKnXS53r35t8hkBAADQeRCq0CHZti3LV62qLz5W5ZdLZFdXKS63r+LyBql0/tNSICDZlmQYCuwuVOWni5V+7mVKnXxO1PtWfPBmKBg16HmSZFmySvao+tvPlTh6giTJiItX8tkzFDxhmgLrvpFd45erZ47cg0fIcPHjAwAAAEIVOhDbtlW5/BOVLXpD/s3rakfY1fFv2SAt2TfHyTBk1IajYFAyDJW++ozi8gYoYciIiPf3fffV/mF/4RiGfN99WReqarm6Zco1dpLDTwgAAICuiFCFDsG2be198W8q/+CtfcuY26Etog5c0tyOEoZsW3K5VP7+GxFDVSiABRorRHZNTXPLBwAAwCGMJdXRIVR/uzwUqCTJtmXU9kRFYtuyDx7CZ1mq/n6l7HDnJBmmKXdOnur3fx3cyFBcLvOkAAAA0HT0VKFD8C5+UzLN0NA8I9RzFTVURWDYQe2YdUnojcstV48spZ56lhLHnCjD7VbSCafL+++/RbuDEsdNbNFnAAAAwKGJnip0CDVbNkSf69QIwzRlul31DwYDCu4sUMkLf9buP/1alq9aiceeLM+IYxrewAz9KKRddLVc6d1bXAcAAAAOPYQqdAwHbLorW03rpaptYxoyXOa+Q+Gvq9n8vcreeF6GaSrjshuVdsFVcmXl1t0nfshIdb/2diUde7KTTwEAAIBDEMP/0CEkHTVW5Z+8V9dbVTsnKmK4OmDOlWGYjQ8XtG1VfLpYqdMulpmQpKTxk5Q0fpLsYEAyTBkm/30BAAAALcNvkugQUk+Ztq/naV8w2rfORLgFJxowmtizFahRTUF+/UtdbgIVAAAAHOG3SXQIcbl56vm/t4SGAdYFpP3/NOI9+/7VkMyW9ywZBn/lAQAA0Lpi/hvm3Llzdeyxxyo1NVVZWVk677zztHbt2qjXzJs3r27J7dpXQkJCO1WMtpI08lj1nvtnZZx3mRKPGqvEUePUbfr/qvej/1T2LQ/IMM3wS61HWEL9YIYnUe7eLJcOAACA1hXzOVUffvihrrvuOh177LEKBAL61a9+pdNPP13fffedkpOTI16XlpZWL3y1ZPltdDyu1HSlTTm/wXE7OeWAN/sC1L7v3LZsGS6jkXlVhpJPPF1mbY8XAAAA0EpiHqoWLFhQ7/28efOUlZWl5cuX66STTop4nWEYysnJaevy0EG40rsrftAw+TesDnvetiwZ5v4FKw7+p+eIo5U69QftXDUAAAAOBTEf/new0tJSSVL37tH3CiovL1e/fv2Ul5enc889V6tWrYrY1ufzyev11nuh80k/+4fSwXOi7LoVLWQHLdlW/aGA7pw+6nbNL9X9R7NkuGL+3xAAAADQBRl2k5ZXax+WZemcc85RSUmJPv7444jtli5dqnXr1mnkyJEqLS3Vww8/rI8++kirVq1Snz59GrS/++67NWfOnAbHS0tLlZaW1qqfAW2ratWXKn7mT7LLSusdNzwJSj5lmuJ65siurpSZmq6EI8fI9DDXDgAAAJF5vV6lp6c7ygYdKlRde+21evvtt/Xxxx+HDUeR1NTUaNiwYZo+fbruvffeBud9Pp98Pl/de6/Xq7y8PEJVJ2UHg6r+7isFdhXKTExSwohj5ErhewQAAEDztUao6jDjoa6//nq98cYb+uijj5oVqCQpLi5Oo0eP1vr168Oe93g88nhYoKCrMFwuJY44JtZlAAAAAJI6wJwq27Z1/fXX65VXXtH777+vAQMGNPsewWBQ3377rXr16tUGFQIAAABAZDHvqbruuuv03HPP6dVXX1VqaqoKCwslSenp6UpMTJQkXXHFFerdu7fmzp0rSbrnnnt03HHHafDgwSopKdFDDz2kLVu26JprronZ5wAAAABwaIp5qHriiSckSRMnTqx3/KmnntKMGTMkSfn5+TLN/Z1qe/fu1cyZM1VYWKhu3bppzJgxWrJkiYYPH95eZQMAAACApA62UEV7aY3JaAAAAAA6v9bIBjGfUwUAAAAAnRmhCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAONAhQtXjjz+u/v37KyEhQePGjdOyZcuitv/Xv/6loUOHKiEhQSNGjNBbb73VTpUCAAAAQH0xD1UvvviiZs2apbvuuktffvmljjrqKE2ZMkU7d+4M237JkiWaPn26rr76an311Vc677zzdN5552nlypXtXDkAAAAASIZt23YsCxg3bpyOPfZY/fGPf5QkWZalvLw83XDDDbrtttsatL/44otVUVGhN954o+7Ycccdp1GjRunJJ59s0jO9Xq/S09NVWlqqtLS01vkgAAAAADqd1sgGMe2p8vv9Wr58uSZPnlx3zDRNTZ48WUuXLg17zdKlS+u1l6QpU6ZEbC9JPp9PXq+33gsAAAAAWkNMQ9Xu3bsVDAaVnZ1d73h2drYKCwvDXlNYWNis9pI0d+5cpaen173y8vKcFw8AAAAA6gBzqtrD7NmzVVpaWvfaunVrrEsCAAAA0EW4Y/nwnj17yuVyqaioqN7xoqIi5eTkhL0mJyenWe0lyePxyOPxOC8YAAAAAA4S056q+Ph4jRkzRosWLao7ZlmWFi1apPHjx4e9Zvz48fXaS9LChQsjtgcAAACAthTTnipJmjVrlq688kodc8wxGjt2rB577DFVVFToqquukiRdccUV6t27t+bOnStJ+tnPfqaTTz5ZjzzyiKZNm6YXXnhBX3zxhf785z/H8mMAAAAAOETFPFRdfPHF2rVrl+68804VFhZq1KhRWrBgQd1iFPn5+TLN/R1qEyZM0HPPPafbb79dv/rVr3TYYYdp/vz5OvLII2P1EQAAAAAcwmK+T1UssE8VAAAAAKkL7FMFAAAAAJ0doQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAAB2IWqjZv3qyrr75aAwYMUGJiogYNGqS77rpLfr8/6nUTJ06UYRj1Xj/5yU/aqWoAAAAAqM8dqwevWbNGlmXp//7v/zR48GCtXLlSM2fOVEVFhR5++OGo186cOVP33HNP3fukpKS2LhcAAAAAwopZqJo6daqmTp1a937gwIFau3atnnjiiUZDVVJSknJyctq6RAAAAABoVIeaU1VaWqru3bs32u7ZZ59Vz549deSRR2r27NmqrKyM2t7n88nr9dZ7AQAAAEBriFlP1cHWr1+vP/zhD432Ul1yySXq16+fcnNz9c033+jWW2/V2rVr9Z///CfiNXPnztWcOXNau2QAAAAAkGHbtt2aN7ztttv04IMPRm2zevVqDR06tO799u3bdfLJJ2vixIn661//2qznvf/++5o0aZLWr1+vQYMGhW3j8/nk8/nq3nu9XuXl5am0tFRpaWnNeh4AAACArsPr9So9Pd1RNmj1ULVr1y7t2bMnapuBAwcqPj5eklRQUKCJEyfquOOO07x582SazRuRWFFRoZSUFC1YsEBTpkxp0jWt8QcHAAAAoPNrjWzQ6sP/MjMzlZmZ2aS227dv1ymnnKIxY8boqaeeanagkqQVK1ZIknr16tXsawEAAADAqZgtVLF9+3ZNnDhRffv21cMPP6xdu3apsLBQhYWF9doMHTpUy5YtkyRt2LBB9957r5YvX67Nmzfrtdde0xVXXKGTTjpJI0eOjNVHAQAAAHAIi9lCFQsXLtT69eu1fv169enTp9652hGJNTU1Wrt2bd3qfvHx8Xrvvff02GOPqaKiQnl5ebrwwgt1++23t3v9AAAAACC1wZyqzoA5VQAAAACk1skGHWqfKgAAAADobAhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAgZiGqv79+8swjHqvBx54IOo11dXVuu6669SjRw+lpKTowgsvVFFRUTtVDAAAAAD1xbyn6p577tGOHTvqXjfccEPU9jfddJNef/11/etf/9KHH36ogoICXXDBBe1ULQAAAADU5451AampqcrJyWlS29LSUv3tb3/Tc889p1NPPVWS9NRTT2nYsGH69NNPddxxx7VlqQAAAADQQMx7qh544AH16NFDo0eP1kMPPaRAIBCx7fLly1VTU6PJkyfXHRs6dKj69u2rpUuXRrzO5/PJ6/XWewEAAABAa4hpT9WNN96oo48+Wt27d9eSJUs0e/Zs7dixQ48++mjY9oWFhYqPj1dGRka949nZ2SosLIz4nLlz52rOnDmtWToAAAAASGqDnqrbbrutweITB7/WrFkjSZo1a5YmTpyokSNH6ic/+YkeeeQR/eEPf5DP52vVmmbPnq3S0tK619atW1v1/gAAAAAOXa3eU3XzzTdrxowZUdsMHDgw7PFx48YpEAho8+bNGjJkSIPzOTk58vv9KikpqddbVVRUFHVelsfjkcfjaVL9AAAAANAcrR6qMjMzlZmZ2aJrV6xYIdM0lZWVFfb8mDFjFBcXp0WLFunCCy+UJK1du1b5+fkaP358i2sGAAAAgJaK2ZyqpUuX6rPPPtMpp5yi1NRULV26VDfddJMuu+wydevWTZK0fft2TZo0SU8//bTGjh2r9PR0XX311Zo1a5a6d++utLQ03XDDDRo/fjwr/wEAAACIiZiFKo/HoxdeeEF33323fD6fBgwYoJtuukmzZs2qa1NTU6O1a9eqsrKy7thvf/tbmaapCy+8UD6fT1OmTNGf/vSnWHwEAAAAAJBh27Yd6yLam9frVXp6ukpLS5WWlhbrcgAAAADESGtkg5jvUwUAAAAAnRmhCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABxwx7oAAAAAAK0nELD07oe7Nf+dQm3bUa3kJJcmn9hTF5yRo8wenliX1yUZtm3bsS6ivXm9XqWnp6u0tFRpaWmxLgcAAABoFf4aS7PnrtHyb0plGFLtb/qmKSUluvTYnCM0uH9ybIvsYFojGzD8DwAAAOgi/vnvbfry21JJ+wOVJFmWVFkV1P97cK2CwUOuT6XNEaoAAACALqCmxtL8BYWKNA7NsqSiXT4tW1HSrnUdCghVAAAAQBdQsNOnsopg1DYul6FV35e1U0WHDkIVAAAA0AW4mvKbvW3LZRptXsuhhlAFAAAAdAG52QnK7BEftU3Qko45Kr2dKjp0EKoAAACALsA0DU0/NzfieZcpDRmUrCOHpLZjVYcGQhUAAADQRZx/Ro7OnZItaf9wQGPfaL9e2Qn69S1DZBgM/2ttbP4LAAAAdBGGYeimmQN1+kmZen1hkbZsr1JKskuTTuipUyb0lCeePpW2QKgCAAAAupgjhqTqCIb5tRuiKgAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABwgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQhUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADjgjnUBAAAAADq+QMDSx58Xa+Uar1ymoTEjM3TMURkyTSPWpcUcoQoAAABAVGs3lGv2/d9pd7FfbpchW9Lz87erb+9E/eb2I5SbkxDrEmMqZsP/PvjgAxmGEfb1+eefR7xu4sSJDdr/5Cc/acfKAQAAgEPHzt0+/fzOb1Vc4pckBYK2gkFbkrR9R5VuvOMbVVYF69p7ywN66fUduuGOVZp5y7d66MmN+n5jRUxqby8x66maMGGCduzYUe/YHXfcoUWLFumYY46Jeu3MmTN1zz331L1PSkpqkxoBAACAQ90rb+9QVXVQltXwXNCSdu72a+GHO3Xu1F5av7lCN9+zRmUVAdmh3KVN+ZV66/1d+tHFfXT5hb3bt/h2ErNQFR8fr5ycnLr3NTU1evXVV3XDDTfIMKKPy0xKSqp3LQAAANDZbdxSoc+/2qugZeuIIWkaOTyt0d+L28Oi/+4KG6hqGYb0/ie7dcap2brlvrUqr9wfqKRQ8JKkv7+4TQPyEnXC2O5tW3AMdJg5Va+99pr27Nmjq666qtG2zz77rJ555hnl5OTo7LPP1h133BG1t8rn88nn89W993q9rVIzAAAA4FRJaY3ufug7ffF1iQwjFFIsSxrQN0n3zT5CffvEdlRWZXUw6nnblsorA1q8dI/2ltZEbGea0guv7eiSoarDLKn+t7/9TVOmTFGfPn2itrvkkkv0zDPPaPHixZo9e7b++c9/6rLLLot6zdy5c5Wenl73ysvLa83SAQAAgBapqbH08zu+1lfflkgKBZTaXqH8bVX66W0rVLzXH7sCJfXPS5IZJTWYpjSwb5K+/NYbtZ1lSau+L1dNIEq3VyfV6qHqtttui7gARe1rzZo19a7Ztm2b3nnnHV199dWN3v/HP/6xpkyZohEjRujSSy/V008/rVdeeUUbNmyIeM3s2bNVWlpa99q6davjzwkAAAA49eHS3Vq/qaJuiNyBgpYtb1mN/vPm9vYv7ADnTe0VdfifZUlZPRNkWXbkRgewu16mav3hfzfffLNmzJgRtc3AgQPrvX/qqafUo0cPnXPOOc1+3rhx4yRJ69ev16BBg8K28Xg88ng8zb43AAAA0JYWflAk01TE0GJZ0tvvF+maywa0b2EHOGVCT7346nat3VAesc3zrxboqov7Njr3akBeouLjO8xguVbT6qEqMzNTmZmZTW5v27aeeuopXXHFFYqLi2v281asWCFJ6tWrV7OvBQAAQMez22trj1eKd0t5mZLbFfvFGtpKiTcQNYhIoSXKY8nlCk30MkxD9kG9UUbtJDBJlVUBJSWaqqq26i1UUcu2pYvO6pq/s8c8Jr7//vvatGmTrrnmmgbntm/frqFDh2rZsmWSpA0bNujee+/V8uXLtXnzZr322mu64oordNJJJ2nkyJHtXToAAABa0W6vracXBfXnty29/Iml5z+09PtXLX26xpId7rf0LqBPr4RQaInAMKTc7NhvrLthS6UMw5RhhnkZhiwrtHT6r395uOLijHpzq2r//ezJWZpycs/YfIA2FvPV//72t79pwoQJGjp0aINzNTU1Wrt2rSorKyWFlmF/77339Nhjj6miokJ5eXm68MILdfvtt7d32QAAAGhFxWW2/vGeJf9BnTLVNdL7X9uq9ktjBtuqqJbSkw0lerpG79VZp/fSOx/sjNzAls47I7f9CorA7Tbl91sRl3g3DCk+3tToI9P11CMj9cqCIn30abH8NZYG90/W+VOzNX5MRodYIr4tGHZXjf1ReL1epaenq7S0VGlpabEuBwAA4JD36qdBrc6Xwq11UFMTVEVFQDU1oXFyhiEdNcilM4/zKDMj5gOvHLFtW/f9dq0WLC5qcM40pWGHper394+SJ8bzkO5+5Hv997M9YRfUqHXrdYN0xilZ7VdUK2mNbNC5/xYCAACg0/MH7IiByu8PqqTEXxeopNDcnG82BPXbf1Vq597Ot5RceUVAy78p0Rdfl6i8IqjZPxuimZf1V3rq/kFknnhT55+Zq9/ee1TMA5UkXXxOr7DfjxQKfz27xenUCT3at6gOJObD/wAAAHBoq/KFD1S2bausLPweTZYt+fzSPxdUKkXlKqsMKqtHnE47PkO9MuPbuOKW8fmCevKfm/X6u4Xy14Q+cJzb0BmTsnXdjAG65II8bdhcoUDQ1sC+SUpK6ji/qg87LFW3/+wwzf3DegWDVv3FNQxDZ5yaKbc79uEvVhj+x/A/AACAmPLX2HrklYYrxvl8QXm90Te+tW1b+WsL5KvyKxgMyrZDvSaXnpulMyb27DBzeAJBW7+Ys1IrVpY2CJCmKR1xeKoeu2eE4uI6djDJ316pG+9Yqb0lDVckTEl26fH7R6h/XlIMKmu51sgGHSf+AgAA4JAUH2doSG9p7XbVC1bBYOP/7d9X5VdleZVsOxSwDMPQrmK/fjdvu/749DYN6u3WEYel6KzTc9SnV2IbforoPvp0t778tlSGaco0Jduy61Y0tCzp2zVlev+T3Zoy0dmcJJ8vqPc/2aPFS3arsjKoAX2TdPZp2Tp8UEprfAw98n8bwwYqSSqvCOqnt32rF/88RqnJh1bMOLQ+LQAAADqkE480tWGHpYC1P1iZjXTa2Lat/O8L6trX9krV/jMQlNZs9uvb77br2f9s00+u6K9LL8xrq48Qkb/G0hNP58sdv39PVsMd2vMpGAjItm2ZhvT6u4WOQlXRLp9+fudKFRT5ZBihP8dV35fptXeLdNTwNM24uI9GH5ne4t67DVsqtGKlN2qbiqqg3l60U/9zTuxXLGxPHbt/EQAAAIeEzHRDl51qqucBo6/i411Rr/HuLVegJhi1jWGaMuNCc6yefHqzFn+yy3GtzfXA4xtUXBqUYRh1r1BxkivOLRmhOWKFO6tb/AzbtnXrfatVtMu3733oeO3cp6+/8+qmu77TjJ+tUP72qhY947Ple5vUbsHiKEvEd1GEKgAAAHQIvbobumaKqRmTTZ011tCFJ7h00sjIA6uqyqKHkNoA43K79v279M9/bW3tsqNat6lCH34aPozUhiuXKxQeu2XEhW3XFF9+W6pN+ZVRlzyXpPztVbrx9pXaWxJ9rlo4/kDTlmKorI4edLsihv8BAACgwzAMQ7k9pNweocAxpLdHtqSPvwlIhmQaUtCSLMtWVYWv6fc1DVlBW+s2Vai4xK/uGe2zQuCij/fI5ZKCEXKGYRiSacpQUGecmt3i53y+okQul9HoPDTLlkpKa3TVrBXqnh6vUUem67ypOerbu/H5ZocNSG5SLRlpcbr/998rELB12IBknTEpWxlpLQ+MnQGhCgAAAB2WaRq64KQEnTLa0op1AZVX2+qWYuipF7cqUBN+wYRaBy5yfeC/H7jnVVvzlgekRjp4DMNQbk6Cpp4SPVSVVwS06OPd2lZQpeRkt06Z0EP9+oRW2gsGbTV1ppRl2yreW6PivTXalF+hV97aoVuvH6ypjWzce9zR3ZSW6pa3LPqf+3ffe7V2vVe2LS36eJf++twW3f7zITrl+J5NrLDzIVQBAACgw+uWauqUo/f3LmWm5upXj2xWjT9Qt+rfwQzDkBUMygpasvetY56e6laPbu23j1V2z/jGMpVMQ/rdvSOUlBh5Dtnb7+/Uo3/eqJoaSy7TkGXbeuqFrZp0Qg9d/6MBCtqhZdujsW1btlU/UAas0J/T3D+s0+D+yRocpTfK5TJ0/21DdeMdK2VFzKWhGg4chhgI2Jrz6BplZx6l4YenRq2xs2JOFQAAADqdIQMS9djtA3X8Md1kGEYoMOzrjapbqnxfmAr4Q/OHTEM674xe7bpJ7ZSTMxvsv3Ug05TOnZKtrJ6eiG2WfFGsB/64Xn5/aC+vQNCuCzXvf7JHP/jxcv3nrUIZpiHDNBSuy+rAP59w52TbevmtHY1+nhHD0jTvsVEafnj9JdoTE0zZthX2GbZCJb3w6rZG799Z0VMFAACATikvx6M7b+in4tJeevDJLVrxXXldQLCsUKCqqfbLDloyDOnIYWm6/KK+7VpjTpZHl56fq2f+U9DgnGlKPTLidcl50Zcf//vzW+uWSK/HCAWWg3uNjH3HG3SRRUl3lmVr6fLiqHXU6tcnSU88MFKWZWvnbp/cblOPP7VRi5fsjtiDFbSkj5cVR+xV7OwIVQAAAOjUuqfH68FbD1NFZVCfflWijVsq9d1ar775rkRW0FJuToIuODNX553RS5749h+oNeOi3uqeEadn/lOg4pIaSaHgc/wx3XTdjH7qHmbVv2pfUIs/2aPl35Ro3aaKiPcOH1CMfcHKluzww/7Cqapq3qp9pmkoJytBkuSvsaMMCQwJBGzZduizdzWEKgAAAHQJyUkuTTq+hyYd36PumGXZMs3Y/hZvGIbOPT1bZ03K0rrNFfL5LOXlJkRcgfCrlaW6/cE1Kq8IyuUgAxqGoZRks/7CEkb9IBbq2Qv9e0Zqy6PB4AHJ+uTzPRGDlWGEerhi/V20FeZUAQAAoMvqSL/Eu1yGhg5K0VHD0yIGqvztVbrl3u9UURnqNYq471QTP9Yjdw3X/z10lEwz/DWGsX8e1vAhLV9EYtqk6CsX2rZ04bReLb5/R0eoAgAAADqIf71RoGDQjrq4haRGl2mXQr1D2T0TNGxwijIy4mUo0nDBkDNPjb6kejRZPT36xbWDJYXmih1cxwlju2va5JwW37+jY/gfAAAA0EEs/mRP5N6pg0Sbm2SaoX2lMtLjtLvYr70lNVEvMAxDW7ZX69jRzSz4AGdNzlFudoKee2WbPv+qRLakPr0S9IOzcnXOlF5yu0LPtyxb3vKA3C5DKcldI450jU8BAAAAdAE+f9M3Js7NSlDBTl+D46YpeeJN/fjS0EqHpd6aRu/ldhnaWxq5XXlFQN+tK5NtSUMGpSgjveHiGpJ09IgMHT0iQ4GgrWDQrrcwSCBg6+W3izT/nZ3avTf0rCEDk/TDc3J0wrHdGq2xIyNUAQAAAG2saFe1ysoDysr0KC0lfCCRpH69E7V+c0XE4X+GIZ12Uk/99Mr+6pYRr7ff36m/Pp+vPXv3B6IjDk/VTTMHqH9ektauL9OX35Y2Wl/QspXVo+E8L5/f0pNPb9Lr7xbKXxMqyuUyNPnETP3smoERe5rcLqOuZ0oKBao7H12vL77x1vts6zZVas5jGzVzem/9z1mdd3ggoQoAAABoI8u+LNZfntms1evKJIUCySnH99RPrhxYtxz5gc4/M0e/eXxDxPvZtnTJ+X3Ubd9CF2ecmqXTT87U6nXlqqgMKDcnQXm5idpaUKVrZn2ltRvKQxfW7gkcYQig223o1BMy6x0LBm39au53+uLrknpBKBi0tfCjndqUX6HH7x8pj8fV6J/Dgg936/OvvQ2OW/vu+5fnt2vCMRnqk9Pwz6QzYKEKAAAAoA0s+u9O3Xz3t1qzvqzuWDBoa/HHuzVz1pcq3Fnd4JopE7M0/phuDbJP7furp+dpQN+keudcLkNHDk3VuKO7KS83UbuL/frpbV9r/aby/Y3qVk4P3wX240v7KzWlfn/Lki+K9fmKkrC9ZpYlfb+xQgs+2Bnp49fz2sKdjc4Be+v93U26V0dETxUAAAAQxZatlXpzUaGKdlYrPS1Op52cpSOHpkVdSa+6OqgH//j9AWFmv6Bly1sW0J/mbdQ9twyvd87tMvTrW4boX2/s0Mtv7tCuPX5J0uD+ybrkgt469fiejdb70mvb5S2rabhn1L5aDiy7W0acrp7eT+ec3nDo3ZvvFck0FXXvqdffLdS5U8Ivlb55W5W2F1YrJcml/ILqqCsaWpa0eWtV9A/WgRGqAAAAgDBs29bjf9+oF+Zvk8sMDb0zTEP/ebNAE47trntvHR5x6NuHS3erct9eU+EELVsffrJb3rIapaXWn2Pldpuafl5vXXxOrkq8NXXbSyUkRB9mt3FLhXYX+/XGwsKIQUh2KAyNOiJNV03vpyOHptWb+3Sgol3Vke+j0J9H0e6GC2Ws31yhx/66WavXV9QdM13RazcNKcHTeQfREaoAAACAMF58dZtemL9N0gGb8AZD3S2fLi/Wbx5fpztmDQ177baCKrlchoLByN0zQctW0S5fg1BVq6IqqBdfK9Ab7xapvDIoQ9LYozN0xQ/66MihaXXtVqwq1R/+tlHrNoVCjG1F38TKsmy53aa6Z8Trd3/ZqMWf7JbPb6lvn0SdP7WXpp6aJbfLUPdu8dqUX6lItzMkdUuvv7jFpq2V+tldq+WvqZ/GbMuSDCNi755lq1OvANh54yAAAADQRgIBS8/8e2vE85YlvftBkXaG6amRpORkV6PhRpKSk8L34JSVB3Td7G/10msFKt/X42VL+nxFiW64faU+WVYsSVqxslQ33bVSGzZXhL1POIYR6mW6etYKvflekcoqgvLX2NqwuVIPPbFB/++BNQoELE09JStioArdSJo2Kbveob8+v03+GqtBD5ddN/av4Q1dppSb7dEJYzOa/Bk6GkIVAAAAcJA168tVEmXfJikUTJZ+sSfsuYkTMiMsCRFiGNLhA1OUm5MY9vxTL27V1oKqBuHEskLP/fXv1qmqOqBH/7xBlmXXDz9RFoSorfvLb72qCdj1NhquzT2ffblXL71WoInje2rIoBSZYRKDy5RSU+K1ZmOlfv/3zVq5tkx7S/367KuSiEMGbcuqe4bLFVpgQ5J65yToN7MPU3xc540mDP8DAAAADnLw8LVwDEPyR9isNycrQWedlqM3FhaGXaDBtqVrLusf9lqfL6g33yuKHE5sqbIqqBfmF2jz1sqI9dlhHmwYhmQYocAXIfXZtvTyW4X64Xm99eicI/XAH77Xfz8r3n8P05RcLlX5bX30WbEMQ3plQZGOODxFlmVHXcDDNGwdMzJNWT09crsNjRuVrjEj0mSajSTBDo5QBQAAABxkQF5S1JXvpFD4GDwgJeL5m689TDKk198plGlKpmEoELSVkGDqlz89XBOO7RH2ul17/Kr2RQ91bpeh9RGG/BmGIcu2FC7N2bJluhqPALuL/dpbWqMe3eJ1323DtWNntVasLNU3q8u04MNQ79zBfzar15WHFvOIko8sKxSqLjij8270Gw6hCgAAADhIt4x4TTw+Ux9+sqveELlapin1zknUqCPTI97D7TZ16/VDdOX/9NPiT3aprDygPr0SdcoJmUqMspJfY6v8SaFeqIP3lTrwXMTJULZC55rQM+R272/TKytB2RM9+ud/dkRsX/tIw7Bl2+HvbxrSKRPCh8nOjFAFAAAAhPGzmYO1em2ZinbXX1rcZUoej0tzbhkWdahbrZysBE0/P6/Jz+3ZPV6HD0zWuk0VEfd2ClrSBWf20hdf79XO3f565+xwKfAAlmXJFW6i1D6GIQ3qn6T0A1YlDAZtbdlepR07wy/MceC1klG3GMbBfnhurrqlh1/tsDPrvLPBAAAAgDbUo1u8/vrbo3XJBXl1vULxcabOPK2X/v7YGB0+KLXNnj3jf/KibpY7qH+SDh+Yop/OGFDveL15VPvmTzVg22HnWx1wWpde0EeS9NGne3Td7G916kVLddXPVzRat2lKp5/UQ72yPPWOJ3hM/ejiPrrqf3o3eo/OiJ4qAAAAIIL0tDj95MqB+t8rBsjvtxQXZzpaVKGktEZvL96pzVsrleBx6cRx3XX0iPQG94yLi/6MzfmVKtxZrVOPz1Sgxtbv/7ZR3vJA6OS+/aDqglNtsKoXpCwlJsSpqtqq61VymaEesKun5+nU43vqb8/l6+l/b6s/UrCRSVPBoDRhTDf98icD9e2aMm3b4VNKskvHHpUedchjZ0eoAgAAABphGIY8Hmeh4O33d+rhJzYoaNmhoGJI8xcUasjgZP3m/w1XxgHD4v79xo6oC2XYkl57t0g/vqyfTp+YpVOO76lPv9yrJ+Zt1NbtVXU1H/QhQpvwSsrLTdKf5o7Up1/u1Uef7lFFlaWBfZN0zunZ6p+XpG9We/X0v7eFwlndE/f3hIUb9mgaUkZ6nMaP6SbDMDRyWJpGDnPwB9aJEKoAAACAJiorD+g/bxXotXd2aE9xjdLS3Jo2OUcXnZ2r7hnxEa/7fEWJHvjj+rr3wQM6jdZtrNBt96/WEw+MqAsrK9eURV150LKkb1d7697HxZnqleXR1oLqiD1J9r5eJpcp/WnuSKWnxWnKxCxNmZhVr11xSY3u/8NGuePj6uqxbVtWMCgraMlwGQ16rFxmaN+pO34+uG7/qUMJoQoAAABoguISv35669fasXP/whV7S2r03H+26q1FhXriwVHKzU4Ie+0zL2+L2PNkWaHlyFes8mr0vtUEo6wjUefg8PLxsuKovVu1AWnGD/OUnhZ+sYhSb41uuHO1du8N1OuNMgxDLrdbUlBWMCiZhkzTqBs2ePL4Hrr0/FwN7JvUeOFdEAtVAAAAAE3wyBPrVbizukFosSyptLRG9z66Jux1lVVBrVjljdrz5HJJHx+wwe7Y0d2i9vgYhjR2VEa9Yz6/JbMJqxGecnxWxHMvvVmkXXv8Ec+73C7JkGzLVu+sOL0xb4wWPHOs7vjZ4EM2UEmEKgAAAKBRu/b49N/P9oTds0oKLfCwck2ZNoTZkNfnCzbpGT7//ptfdHYvWRH2mjKN0Gp6Z07Ornd8cP9kBYJRlgxU6Lqcg1bmq2Xbtt5atKuRDY9tmaZLpimddFwPJSe55XYTKfgTAAAAABrx/cbyqEuc11qzvqzBsbTUOKWnRZ91Y1nSgAN6eoYdlqpbrxss06g/FNAwJI/H1IO3D1fGQUP4Tjyuh9JT3REX5zNN6czJ2UqIsOCGv8ZWWUXjAdAwQkvLnzslp9G2hwpCFQAAANCIuCb2xoTrtXG5DJ0/NSfiPClDoYUmTp+YWe/4Gadm6Z9/HK3/OTtXww9P0chhqbrmkr56/k9H66jhaQ3uEx9n6u5fDJXLFVqM4kCmKfXrk6RrLukfsfY4t6H4RpZylyS329BDdw5XVs/wPV6HIhaqAAAAABpx5NA0JXhMVfsij40zTemYozLCnpt+fm8tW1GiNevKdeCoPtMMLaQ3+4bBSk1u+Kt5n16JuvbK/k2u85hR3fTnh0bpmZe36sOlexQM2spIi9O5U3M0/fw+Sk6K/Ou/aRqafGIPvfPB7ojDHA3D0AOzh2jksIah7lBGqAIAAAAakZTo0oXTcvXcK9vCDgM0Den0iVnq0S38suoJHpd+O+cIvfhqgV5ZUKi9JTUyFFps4tIL+0QMKbZtq7QsIJdpKDWlab+6HzYwRXN+OUyBgCW/31JioivsvlLh/PCcHH2wtFjVPqvB3CrDkMaNTtfoI1ObdK9DiWHbTRkd2rV4vV6lp6ertLRUaWmkbAAAADQuELB072Pf6/3/7pLLZSgYtOUyQ4tUHDsqQ/f/anjE+UoHsixblVVBxcWZ8sSHHxNoWbbmL9ihl14vUEFhtSRpUL8kTT+/j047KbPJIaklNmyp1K9/v1FbC6plHLAl1ekn9dCNP+oXsebOqjWyAaGKUAUAAIAmsm1bK9eU6c33CrVzt0/dM+I19ZQsHT0yQ6bZOkHHsmz9+nff672PdsmQVPvLem3AuezCPvrxZf1b5VmR2LatlWvLtWFLleLjDI0dla6e3SNvbtyZtUY2YPgfAAAA0ESGYWjEsDSNaMM5RR99ukfvfbRL0v5AJalu2OEzL2/TCWN7aPjhbTcMzzAMjRiaqhFDGerXFF2r7w4AAADo5F5+syDqedOQXnt3RztVg6YgVAEAAAAdyJoN5VHPW7a0flPDTYYRO4QqAAAAoIPw+YLy+yMv214rvostFtHZ8W0AAAAAHcTX33nDLtl+sH59ktq+GDQZoQoAAADoICqrg01qN3RwShtXguYgVAEAAAAdRL/eiU1qN2QQoaojIVQBAAAAHcSAvskafniqzAi/pZtmaBNgQlXHQqgCAAAAOpBbfjpYCR6XXAf9pu4ypfg4U7fdcLgMo3U2GkbrIFQBAAAAHcjAfsn6y0OjNHFCz7pgZZrSicf10J8fGkUvVQdk2HZT1hfpWrxer9LT01VaWqq0tLbbDRsAAABworIqqNKyGqWnupWU6I51OV1Sa2QDvhkAAACgg0pKdCkp0RXrMtAIhv8BAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAOAAoQoAAAAAHCBUAQAAAIADhCoAAAAAcIBQBQAAAAAOEKoAAAAAwAFCFQAAAAA4QKgCAAAAAAcIVQAAAADgAKEKAAAAABxos1B13333acKECUpKSlJGRkbYNvn5+Zo2bZqSkpKUlZWlX/7ylwoEAlHvW1xcrEsvvVRpaWnKyMjQ1VdfrfLy8jb4BAAAAADQuDYLVX6/XxdddJGuvfbasOeDwaCmTZsmv9+vJUuW6B//+IfmzZunO++8M+p9L730Uq1atUoLFy7UG2+8oY8++kg//vGP2+IjAAAAAECjDNu27bZ8wLx58/Tzn/9cJSUl9Y6//fbbOuuss1RQUKDs7GxJ0pNPPqlbb71Vu3btUnx8fIN7rV69WsOHD9fnn3+uY445RpK0YMECnXnmmdq2bZtyc3ObVJPX61V6erpKS0uVlpbm7AMCAAAA6LRaIxvEbE7V0qVLNWLEiLpAJUlTpkyR1+vVqlWrIl6TkZFRF6gkafLkyTJNU5999lnEZ/l8Pnm93novAAAAAGgN7lg9uLCwsF6gklT3vrCwMOI1WVlZ9Y653W5179494jWSNHfuXM2ZM6fBccIVAAAAcGirzQROBvA1K1TddtttevDBB6O2Wb16tYYOHdrigtrC7NmzNWvWrLr327dv1/Dhw5WXlxfDqgAAAAB0FGVlZUpPT2/Rtc0KVTfffLNmzJgRtc3AgQObdK+cnBwtW7as3rGioqK6c5Gu2blzZ71jgUBAxcXFEa+RJI/HI4/HU/c+JSVFW7duVWpqqgzDaFK9XY3X61VeXp62bt3KvLIuhO+1a+J77Zr4Xrsmvteuie+1a6r9XvPz82UYRpPXZwinWaEqMzNTmZmZLX7YgcaPH6/77rtPO3furBvSt3DhQqWlpWn48OERrykpKdHy5cs1ZswYSdL7778vy7I0bty4Jj/bNE316dPH+YfoAtLS0vgfhy6I77Vr4nvtmvheuya+166J77VrSk9Pd/y9ttlCFfn5+VqxYoXy8/MVDAa1YsUKrVixom5PqdNPP13Dhw/X5Zdfrq+//lrvvPOObr/9dl133XV1vUrLli3T0KFDtX37dknSsGHDNHXqVM2cOVPLli3TJ598ouuvv14//OEPHSVLAAAAAGipNluo4s4779Q//vGPuvejR4+WJC1evFgTJ06Uy+XSG2+8oWuvvVbjx49XcnKyrrzySt1zzz1111RWVmrt2rWqqampO/bss8/q+uuv16RJk2Sapi688EL9/ve/b6uPAQAAAABRtVmomjdvnubNmxe1Tb9+/fTWW29FPD9x4sQGq3B0795dzz33XGuUeEjzeDy666676s01Q+fH99o18b12TXyvXRPfa9fE99o1teb32uab/wIAAABAVxazzX8BAAAAoCsgVAEAAACAA4QqAAAAAHCAUAUAAAAADhCqAAAAAMABQtUh6L777tOECROUlJSkjIyMsG0Mw2jweuGFF9q3UDRLU77X/Px8TZs2TUlJScrKytIvf/lLBQKB9i0UjvTv37/Bz+YDDzwQ67LQAo8//rj69++vhIQEjRs3TsuWLYt1SXDg7rvvbvCzOXTo0FiXhWb66KOPdPbZZys3N1eGYWj+/Pn1ztu2rTvvvFO9evVSYmKiJk+erHXr1sWmWDRZY9/rjBkzGvz8Tp06tVnPIFQdgvx+vy666CJde+21Uds99dRT2rFjR93rvPPOa58C0SKNfa/BYFDTpk2T3+/XkiVL9I9//EPz5s3TnXfe2c6Vwql77rmn3s/mDTfcEOuS0EwvvviiZs2apbvuuktffvmljjrqKE2ZMkU7d+6MdWlw4Igjjqj3s/nxxx/HuiQ0U0VFhY466ig9/vjjYc//5je/0e9//3s9+eST+uyzz5ScnKwpU6aourq6nStFczT2vUrS1KlT6/38Pv/88816Rptt/ouOa86cOZLU6ObMGRkZysnJaYeK0Boa+17fffddfffdd3rvvfeUnZ2tUaNG6d5779Wtt96qu+++W/Hx8e1YLZxITU3lZ7OTe/TRRzVz5kxdddVVkqQnn3xSb775pv7+97/rtttui3F1aCm3283PZid3xhln6Iwzzgh7zrZtPfbYY7r99tt17rnnSpKefvppZWdna/78+frhD3/YnqWiGaJ9r7U8Ho+jn196qhDRddddp549e2rs2LH6+9//LvaJ7tyWLl2qESNGKDs7u+7YlClT5PV6tWrVqhhWhuZ64IEH1KNHD40ePVoPPfQQQzg7Gb/fr+XLl2vy5Ml1x0zT1OTJk7V06dIYVgan1q1bp9zcXA0cOFCXXnqp8vPzY10SWtGmTZtUWFhY72c3PT1d48aN42e3C/jggw+UlZWlIUOG6Nprr9WePXuadT09VQjrnnvu0amnnqqkpCS9++67+ulPf6ry8nLdeOONsS4NLVRYWFgvUEmqe19YWBiLktACN954o44++mh1795dS5Ys0ezZs7Vjxw49+uijsS4NTbR7924Fg8GwP49r1qyJUVVwaty4cZo3b56GDBmiHTt2aM6cOTrxxBO1cuVKpaamxro8tILa/68M97PL/492blOnTtUFF1ygAQMGaMOGDfrVr36lM844Q0uXLpXL5WrSPQhVXcRtt92mBx98MGqb1atXN3nS7B133FH376NHj1ZFRYUeeughQlU7a+3vFR1Tc77nWbNm1R0bOXKk4uPj9b//+7+aO3euPB5PW5cKIIIDhxaNHDlS48aNU79+/fTSSy/p6quvjmFlABpz4NDNESNGaOTIkRo0aJA++OADTZo0qUn3IFR1ETfffLNmzJgRtc3AgQNbfP9x48bp3nvvlc/n4xe3dtSa32tOTk6D1cWKiorqziF2nHzP48aNUyAQ0ObNmzVkyJA2qA6trWfPnnK5XHU/f7WKior4WexCMjIydPjhh2v9+vWxLgWtpPbns6ioSL169ao7XlRUpFGjRsWoKrSFgQMHqmfPnlq/fj2h6lCTmZmpzMzMNrv/ihUr1K1bNwJVO2vN73X8+PG67777tHPnTmVlZUmSFi5cqLS0NA0fPrxVnoGWcfI9r1ixQqZp1n2n6Pji4+M1ZswYLVq0qG5VVcuytGjRIl1//fWxLQ6tpry8XBs2bNDll18e61LQSgYMGKCcnBwtWrSoLkR5vV599tlnja6ojM5l27Zt2rNnT73w3BhC1SEoPz9fxcXFys/PVzAY1IoVKyRJgwcPVkpKil5//XUVFRXpuOOOU0JCghYuXKj7779fv/jFL2JbOKJq7Hs9/fTTNXz4cF1++eX6zW9+o8LCQt1+++267rrrCMudxNKlS/XZZ5/plFNOUWpqqpYuXaqbbrpJl112mbp16xbr8tAMs2bN0pVXXqljjjlGY8eO1WOPPaaKioq61QDR+fziF7/Q2WefrX79+qmgoEB33XWXXC6Xpk+fHuvS0Azl5eX1ehc3bdqkFStWqHv37urbt69+/vOf69e//rUOO+wwDRgwQHfccYdyc3PZdqaDi/a9du/eXXPmzNGFF16onJwcbdiwQbfccosGDx6sKVOmNP0hNg45V155pS2pwWvx4sW2bdv222+/bY8aNcpOSUmxk5OT7aOOOsp+8skn7WAwGNvCEVVj36tt2/bmzZvtM844w05MTLR79uxp33zzzXZNTU3sikazLF++3B43bpydnp5uJyQk2MOGDbPvv/9+u7q6OtaloQX+8Ic/2H379rXj4+PtsWPH2p9++mmsS4IDF198sd2rVy87Pj7e7t27t33xxRfb69evj3VZaKbFixeH/f/SK6+80rZt27Ysy77jjjvs7Oxs2+Px2JMmTbLXrl0b26LRqGjfa2VlpX366afbmZmZdlxcnN2vXz975syZdmFhYbOeYdg262QDAAAAQEuxTxUAAAAAOECoAgAAAAAHCFUAAAAA4AChCgAAAAAcIFQBAAAAgAOEKgAAAABwgFAFAAAAAA4QqgAAAADAAUIVAAAAADhAqAIAAAAABwhVAAAAAODA/wfTxVlzFrMxDwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "# import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distance_matrix = pairwise_distances(output_emb_formIII, metric=\"cosine\")\n",
    "tsne = TSNE(n_components=2, metric=\"precomputed\", init=\"random\", random_state=42)\n",
    "tsne_embedding = tsne.fit_transform(distance_matrix)\n",
    "# umap_model = umap.UMAP(n_neighbors=5, min_dist=0.3, metric=\"cosine\")\n",
    "# tsne_embedding = umap_model.fit_transform(output_emb)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(tsne_embedding[:, 0], tsne_embedding[:, 1], c=output_pred_formIII, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred = []\n",
    "\n",
    "for i in range(len(val_sequences)):\n",
    "    inputs = loaded_tokenizer(train_sequences[i], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {key: inputs[key] for key in inputs}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"]\n",
    "\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred = []\n",
    "\n",
    "for i in range(len(train_sequences)):\n",
    "    inputs = loaded_tokenizer(train_sequences[i], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    labels = [train_binary_activity[i]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"].squeeze(0)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        # Sigmoid activation\n",
    "        outputs = 1 / (1 + np.exp(-outputs))\n",
    "        # print(outputs, labels)\n",
    "\n",
    "        output_pred.append(outputs)\n",
    "\n",
    "#Plot the values in output_pred with the labels from val_set_labels\n",
    "\n",
    "output_pred = np.array(output_pred)\n",
    "# val_set_labels = np.array(val_set_labels)\n",
    "\n",
    "plt.scatter(output_pred, train_binary_activity)\n",
    "plt.title(\"Predictions vs Labels for the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predictions vs Labels for the validation set')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQFRJREFUeJzt3Xd4VGX+/vF70iaNJEAgBWISWQuogEaBKEU0EnqxYaVY10VR+VpAhYCisSIuoCir4rqrApZ1V1gQUFZcQVwCq4AiQigCCT2hJpB5fn/wyyxD2kyYyQP4fl3XXJozzznn+Zw295w55+AwxhgBAABYEmS7AwAA4LeNMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACv0pLS9OgQYPcfy9YsEAOh0MLFizw2zwcDodGjx7tt+n9Vg0aNEjR0dF+nebll1+uyy+/3C/TKiws1LXXXquGDRvK4XBo/PjxfpmurwKxnOrC6NGj5XA4PIYdv39WZerUqXI4HFq/fr3f+rN+/Xo5HA5NnTrVb9PE6YMwchopP4CUv8LDw3X22Wfr3nvvVWFhoe3u+WTWrFkEjkqkpaWpZ8+etrtRJx588EHNmTNHI0aM0LvvvquuXbsGbF4HDhzQ6NGj/Rqaf6vee+89a8GxLpzu9dkSYrsD8L8nn3xS6enpOnTokL7++mu99tprmjVrllasWKHIyMg67UvHjh118OBBhYWF+TTerFmzNGnSpEoDycGDBxUSwqZ7uvviiy/Up08fPfTQQwGf14EDBzRmzBhJ8tuZnZPR6tWrFRQU2O+g7733nlasWKEHHnjAY3hqaqoOHjyo0NDQgM4/0KqqDyeGI/ppqFu3brr44oslSXfccYcaNmyocePG6dNPP9WNN95Y6Tj79+9XVFSU3/sSFBSk8PBwv07T39PDyWnbtm2Ki4vz2/QOHTqksLCwgH8Yn8ycTqe1eZefrQUq89vdK39DrrjiCklSfn6+pP/9Br527Vp1795d9erV08033yxJcrlcGj9+vM477zyFh4crISFBd999t3bv3u0xTWOMxo4dq6ZNmyoyMlKdO3fWypUrK8y7qmtGvv32W3Xv3l3169dXVFSUWrZsqVdeecXdv0mTJkmSx89O5Sq7ZmTZsmXq1q2bYmJiFB0drSuvvFKLFy/2aFP+M9a///1vDRs2TI0aNVJUVJT69eun7du3e7T9z3/+o+zsbMXHxysiIkLp6em67bbbql3OPXv21Jlnnlnpe5mZme6AKElz585V+/btFRcXp+joaJ1zzjl67LHHqp2+txYuXKjrrrtOZ5xxhpxOp1JSUvTggw/q4MGDlbZft26dsrOzFRUVpeTkZD355JM6/h/z9na7qMyECRN03nnnKTIyUvXr19fFF1+s9957r8r25evJGKNJkyZVWP/r1q3TddddpwYNGigyMlLt2rXTzJkzPaZRvt198MEHeuKJJ9SkSRNFRkaquLi4wvzWr1+vRo0aSZLGjBnjnt/x29jmzZvVt29fRUdHq1GjRnrooYdUVlbml+X04osvyuFwaMOGDRXeGzFihMLCwtzT8HX9Hquya0ZWrlypK664QhEREWratKnGjh0rl8tVYdxPP/1UPXr0UHJyspxOp5o1a6annnrKYxlcfvnlmjlzpjZs2OBejmlpaZKqvmbkiy++UIcOHRQVFaW4uDj16dNHP/74o0eb8utffvnlFw0aNEhxcXGKjY3V4MGDdeDAgRrrXrNmja655holJiYqPDxcTZs21Q033KCioiKPdn/5y1+UkZGhiIgINWjQQDfccIM2bdrkVX04MZwZ+Q1Yu3atJKlhw4buYUeOHFF2drbat2+vF1980f3zzd13362pU6dq8ODBGjp0qPLz8zVx4kQtW7ZM//73v92nWEeNGqWxY8eqe/fu6t69u/Ly8tSlSxeVlpbW2J+5c+eqZ8+eSkpK0v3336/ExET9+OOP+uyzz3T//ffr7rvv1pYtWzR37ly9++67NU5v5cqV6tChg2JiYvTII48oNDRUr7/+ui6//HL961//Utu2bT3a33fffapfv75ycnK0fv16jR8/Xvfee6+mTZsm6eg38i5duqhRo0YaPny44uLitH79en388cfV9qN///4aMGCAvvvuO11yySXu4Rs2bNDixYv1wgsvuPvbs2dPtWzZUk8++aScTqd++eUX/fvf/66xVm/MmDFDBw4c0D333KOGDRtqyZIlmjBhgn799VfNmDHDo21ZWZm6du2qdu3a6fnnn9fs2bOVk5OjI0eO6Mknn3S383a7ON6UKVM0dOhQXXvttbr//vt16NAhff/99/r222910003VTpOx44d9e677+rWW2/VVVddpQEDBrjfKyws1KWXXqoDBw5o6NChatiwod555x317t1bH374ofr16+cxraeeekphYWF66KGHVFJSUunPhY0aNdJrr72me+65R/369dPVV18tSWrZsqXHcsrOzlbbtm314osvat68eXrppZfUrFkz3XPPPSe8nK6//no98sgjmj59uh5++GGP96ZPn64uXbqofv36knxbvzUpKChQ586ddeTIEQ0fPlxRUVF64403FBERUaHt1KlTFR0drWHDhik6OlpffPGFRo0apeLiYve2/fjjj6uoqEi//vqrXn75ZUmq9uLfefPmqVu3bjrzzDM1evRoHTx4UBMmTNBll12mvLy8Ch/0119/vdLT05Wbm6u8vDz96U9/UuPGjfXcc89VOY/S0lJlZ2erpKRE9913nxITE7V582Z99tln2rNnj2JjYyVJTz/9tEaOHKnrr79ed9xxh7Zv364JEyaoY8eOWrZsmeLi4nyuDz4wOG28/fbbRpKZN2+e2b59u9m0aZP54IMPTMOGDU1ERIT59ddfjTHGDBw40Egyw4cP9xh/4cKFRpL561//6jF89uzZHsO3bdtmwsLCTI8ePYzL5XK3e+yxx4wkM3DgQPewL7/80kgyX375pTHGmCNHjpj09HSTmppqdu/e7TGfY6c1ZMgQU9XmKcnk5OS4/+7bt68JCwsza9eudQ/bsmWLqVevnunYsWOF5ZOVleUxrwcffNAEBwebPXv2GGOM+eSTT4wk891331U6/6oUFRUZp9Np/u///s9j+PPPP28cDofZsGGDMcaYl19+2Ugy27dv92n6xhiTmppqevToUW2bAwcOVBiWm5vr0Qdj/rcd3Hfffe5hLpfL9OjRw4SFhbn75+12YYwxnTp1Mp06dXL/3adPH3Peeef5VGM5SWbIkCEewx544AEjySxcuNA9bO/evSY9Pd2kpaWZsrIyY8z/trszzzyz0uVxvO3bt1fYrsqVL6cnn3zSY/iFF15oMjIy3H/7spwqk5mZ6TE9Y4xZsmSJkWT+/Oc/u4d5u35zcnIq7EOpqake+2f58vz222/dw7Zt22ZiY2ONJJOfn1/tfO+++24TGRlpDh065B7Wo0cPk5qaWqFtfn6+kWTefvtt97DWrVubxo0bm507d7qH/fe//zVBQUFmwIABFWq57bbbPKbZr18/07BhwwrzOtayZcuMJDNjxowq26xfv94EBwebp59+2mP4Dz/8YEJCQjyGV1UfTgw/05yGsrKy1KhRI6WkpOiGG25QdHS0PvnkEzVp0sSj3bHf6KSj37hiY2N11VVXaceOHe5XRkaGoqOj9eWXX0o6+m2mtLRU9913n8fpc28u6Fq2bJny8/P1wAMPVLge4PjbEL1RVlamzz//XH379vX4iSQpKUk33XSTvv766wqn5u+66y6PeXXo0EFlZWXuU+Tl/frss890+PBhr/sSExOjbt26afr06R4/c0ybNk3t2rXTGWec4TH9Tz/9tNLT4Sfq2G+1+/fv144dO3TppZfKGKNly5ZVaH/vvfe6/9/hcOjee+9VaWmp5s2bJ8n77aIycXFx+vXXX/Xdd9/5pbZZs2apTZs2at++vXtYdHS07rrrLq1fv16rVq3yaD9w4MBKv+XXxu9//3uPvzt06KB169a5/z6R5SQdPbO2dOlS95lM6ei243Q61adPH/cwX9dvdWbNmqV27dqpTZs27mGNGjVy/2x7rGPnu3fvXu3YsUMdOnTQgQMH9NNPP/k0X0naunWrli9frkGDBqlBgwbu4S1bttRVV12lWbNmVRinsnWwc+fOSn9+K1d+5mPOnDlV/qTz8ccfy+Vy6frrr/dYd4mJiTrrrLNqXHc4cYSR09CkSZM0d+5cffnll1q1apX7moBjhYSEqGnTph7D1qxZo6KiIjVu3FiNGjXyeO3bt0/btm2TJPeH9llnneUxfqNGjdynkqtSfqA9//zzT6jGctu3b9eBAwd0zjnnVHivefPmcrlcHr/5SnKHgnLlfS7/Tb5Tp0665pprNGbMGMXHx6tPnz56++23VVJSUmN/+vfvr02bNmnRokWSjta7dOlS9e/f36PNZZddpjvuuEMJCQm64YYbNH36dL8Fk40bN7oP8OXXN3Tq1EmSKvxGHhQUVOE6l7PPPluS3M+Y8Ha7qMyjjz6q6OhotWnTRmeddZaGDBlyQj9Hbdiwocp1Xf7+sdLT02s9r2OFh4e7ryspV79+fY9rQU5kOUnSddddp6CgIPfPhcYYzZgxw30tVDlf1m9NNmzYUGE/llTpMl65cqX69eun2NhYxcTEqFGjRrrllltqNd/yeVc1r+bNm2vHjh3av3+/x/Ca9t3KpKena9iwYfrTn/6k+Ph4ZWdna9KkSR59XrNmjYwxOuussyqsux9//LHGdYcTxzUjp6E2bdp4XCxZGafTWeGuApfLpcaNG+uvf/1rpeMcfzA+VQUHB1c6vPxshsPh0IcffqjFixfrH//4h+bMmaPbbrtNL730khYvXlztb8S9evVSZGSkpk+frksvvVTTp09XUFCQrrvuOnebiIgIffXVV/ryyy81c+ZMzZ49W9OmTdMVV1yhzz//vMr+eaOsrExXXXWVdu3apUcffVTnnnuuoqKitHnzZg0aNKhWgedEtovmzZtr9erV+uyzzzR79mx99NFHevXVVzVq1Cj3rbSB5K+zIt6skxPdf5KTk9WhQwdNnz5djz32mBYvXqyNGzd6XA8RiPXrjT179qhTp06KiYnRk08+qWbNmik8PFx5eXl69NFHAzbf49W071blpZde0qBBg/Tpp5/q888/19ChQ5Wbm6vFixeradOmcrlccjgc+uc//1npPLguJPAII3Br1qyZ5s2bp8suu6zag3hqaqqko98mjv1WvX379hrvGmjWrJkkacWKFcrKyqqynbc/2TRq1EiRkZFavXp1hfd++uknBQUFKSUlxatpHa9du3Zq166dnn76ab333nu6+eab9cEHH+iOO+6ocpyoqCj17NlTM2bM0Lhx4zRt2jR16NBBycnJHu2CgoJ05ZVX6sorr9S4ceP0zDPP6PHHH9eXX35Z7XKpyQ8//KCff/5Z77zzjseFn3Pnzq20vcvl0rp169xnQyTp559/liT3xYPebhdViYqKUv/+/dW/f3+Vlpbq6quv1tNPP60RI0b4fKtnampqleu6/P3aqM1PhMc70eUkHT1r9oc//EGrV6/WtGnTFBkZqV69ernf93X91iQ1NVVr1qypMPz4ZbxgwQLt3LlTH3/8sTp27OgeXn6H3rG8XZbl66qq9RkfH+/Xxw1ccMEFuuCCC/TEE0/om2++0WWXXabJkydr7NixatasmYwxSk9P99gXKuOPbQUV8TMN3K6//nqVlZXpqaeeqvDekSNHtGfPHklHr0kJDQ3VhAkTPL6RePNUwosuukjp6ekaP368e3rljp1W+UHo+DbHCw4OVpcuXfTpp596PLq6sLBQ7733ntq3b+9xitsbu3fvrvBNq3Xr1pLk9U81W7Zs0Z/+9Cf997//9fiJRpJ27dpVYRxfpl+d8m91x/bfGOO+bboyEydO9Gg7ceJEhYaG6sorr5Tk/XZRmZ07d3r8HRYWphYtWsgY49P1OOW6d++uJUuWuH8Gk45eN/HGG28oLS1NLVq08Hmaktx3k9W0vVXnRJZTuWuuuUbBwcF6//33NWPGDPXs2dPjA7k267c63bt31+LFi7VkyRL3sO3bt1c4u1PZfEtLS/Xqq69WmGZUVJRXP9skJSWpdevWeueddzyWzYoVK/T555+re/fuvpZTqeLiYh05csRj2AUXXKCgoCD3/nb11VcrODhYY8aMqbDvG2M8tmNv64NvODMCt06dOunuu+9Wbm6uli9fri5duig0NFRr1qzRjBkz9Morr+jaa691P2MhNzdXPXv2VPfu3bVs2TL985//VHx8fLXzCAoK0muvvaZevXqpdevWGjx4sJKSkvTTTz9p5cqVmjNnjiQpIyNDkjR06FBlZ2crODhYN9xwQ6XTHDt2rPu5HX/4wx8UEhKi119/XSUlJXr++ed9Xg7vvPOOXn31VfXr10/NmjXT3r17NWXKFMXExHh1gCx/dstDDz2k4OBgXXPNNR7vP/nkk/rqq6/Uo0cPpaamatu2bXr11VfVtGlTjwszq/LLL79o7NixFYZfeOGF6tKli5o1a6aHHnpImzdvVkxMjD766KMqz1iFh4dr9uzZGjhwoNq2bat//vOfmjlzph577DH3zwrebheV6dKlixITE3XZZZcpISFBP/74oyZOnKgePXqoXr16NdZ6vOHDh+v9999Xt27dNHToUDVo0EDvvPOO8vPz9dFHH9X6gWYRERFq0aKFpk2bprPPPlsNGjTQ+eef79O1TSeynMo1btxYnTt31rhx47R3794KQfbcc8/1af3W5JFHHnE/av/+++9339qbmpqq77//3t3u0ksvVf369TVw4EANHTpUDodD7777bqU/j2RkZGjatGkaNmyYLrnkEkVHR3uc3TnWCy+8oG7duikzM1O33367+9be2NhYv/1zEF988YXuvfdeXXfddTr77LN15MgRvfvuux77ZrNmzTR27FiNGDFC69evV9++fVWvXj3l5+frk08+0V133eV+ErAv9cEHdXrvDgKq/NbVmm5JHThwoImKiqry/TfeeMNkZGSYiIgIU69ePXPBBReYRx55xGzZssXdpqyszIwZM8YkJSWZiIgIc/nll5sVK1ZUuHXw+Ft7y3399dfmqquuMvXq1TNRUVGmZcuWZsKECe73jxw5Yu677z7TqFEj43A4PG5RVCW3YObl5Zns7GwTHR1tIiMjTefOnc0333zj1fI5vo95eXnmxhtvNGeccYZxOp2mcePGpmfPnuY///lPdYvVw8033+y+jfh48+fPN3369DHJyckmLCzMJCcnmxtvvNH8/PPPNU43NTXVSKr0dfvttxtjjFm1apXJysoy0dHRJj4+3tx5553mv//9b4XbKsu3g7Vr15ouXbqYyMhIk5CQYHJycty3yB7Lm+3i+Ft7X3/9ddOxY0fTsGFD43Q6TbNmzczDDz9sioqKaqxVldzaa4wxa9euNddee62Ji4sz4eHhpk2bNuazzz7zaFO+Tqu7nfN433zzjcnIyDBhYWEe21hV+0tlt84a491yqs6UKVOMJFOvXj1z8ODBCu97u369ubXXGGO+//5706lTJxMeHm6aNGlinnrqKfPmm29WuLX33//+t2nXrp2JiIgwycnJ5pFHHjFz5sypsH/v27fP3HTTTSYuLs5Ict8GW9mtvcYYM2/ePHPZZZeZiIgIExMTY3r16mVWrVrl0aa8luNvhy/fp4/t5/HWrVtnbrvtNtOsWTMTHh5uGjRoYDp37mzmzZtXoe1HH31k2rdvb6KiokxUVJQ599xzzZAhQ8zq1atrrA8nxmFMDVf+AAAABBDXjAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAqlPioWcul0tbtmxRvXr1eBQvAACnCGOM9u7dq+Tk5GofSnhKhJEtW7bU+t8XAQAAdm3atKnCvxR/rFMijJQ/NnrTpk0+/zsjAADAjuLiYqWkpNT4zz+cEmGk/KeZmJgYwggAAKeYmi6x4AJWAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWnxEPPAqHMZbQkf5e27T2kxvXC1Sa9gYKDav53byobT5J7WHy0UzLSjv0lio9ySg5px74SNa4XrozU+vouf5cWrdshyaHMZg3V7syGHuM3iAzTTwV7tWn3AaU2iNStmWkKC/lfZtx36IgenLZMG3cfVEr9cN3cJlV7Dh7Wjn2l2r2/VFv2HJQxLrnk0M79JSo57JIzJEgtkmOUv22f1u7cr9DgIEWGBav0cJl2HTyi+uHBKi5xScalMknRYSFHxwuVnCEhOlxm5DIu7T10WAdLXSotM3JIchkjY6TgYIciQ4PkcDgUGRasA6VHdOjI0feiQ4N06IhLpWUulZZJrv9fR7Ck8GDp4DHDHJKCHdIRU/06CHZIQY6j/40IDZEjSHIZKcoZopZN6mnLnhLl79iv0jKj+hEhSo2PUsOoUK3beUC79x9WjDNEGWn1dVFqA+3cV6KFa7ZrS1GJkmPDdVeHM9X+7EYVtoUyl9HidTu1aO1OSUZt0xpKDunb/F3H/b3TvW4vSWug7/J36Zt1O7Rl90Elx0Xo0mbxatfMc51Xt/1Vtr2VHnHp6Zmr9N9f9ygmPFR3dThTmb+L19INu1VQfEi79pWoQVSYEmMjKm6f/3+bLCw6pLyNu1RYXKJoZ4iuvqipLv1dvFf7QE2OX1aZZx6t+dhp13b/C6RA9ckfx5pjjyu17VtdLXN/HlttbxO2ebNMSo+49O6i9dqwq/LPjBOZdl1yGGNqOPTbV1xcrNjYWBUVFfnlCayzV2zVmH+s0taiQ+5hSbHhyunVQl3PT/JpvLjIUEnSngOHa5yvQ9LxCzsqLFihIUFVjh/kkO7skK4R3Vuo98SF+v7X4hrngxPjDAnSKze0dm8Ls1ds1fCPf/BqHXsjMixYYcet88q2v8q2N2dIkEqOuOQtX7bPqLBgvXR9q2r3gZpUtaziIkP17NUXqOv5SbXe/wIpUH3y57HmWL72ra6WuT/rtb1N2ObNMsmdtUpTFubLdcwHy7GfGScybX/x9vPb5zDy1Vdf6YUXXtDSpUu1detWffLJJ+rbt2+14yxYsEDDhg3TypUrlZKSoieeeEKDBg3yep7+DCOzV2zVPX/JqxAKyvPga7dcVOnKqGq8utIoOkzb95Vamvtv0+RbLpIk/f4veQGf1/Hbn83tbXIV+0BNZq/YWuOyurtjut74Kt/n/S+QantMCNR0vVn3vvQtUPX5az511b9TiTfLZNnG3Xr9q/wqp3F3x8oDSV0vb28/v32+ZmT//v1q1aqVJk2a5FX7/Px89ejRQ507d9by5cv1wAMP6I477tCcOXN8nfUJK3MZjfnHqkp38vJhY/6xSmUuzxbVjVdXCCJ1L+fTlcr5dGWdzOvY7a/0iMvq9lbZPlCTMpfR6L+vqrFdZUFEqn7/C6TaHhMCNV1vjzXe9i1Q9flrPnXVv1OJN8tk9N9XasrCqoOIJE1ZmK/S486inszL2+cw0q1bN40dO1b9+vXzqv3kyZOVnp6ul156Sc2bN9e9996ra6+9Vi+//HKV45SUlKi4uNjj5Q9L8ndVedpTOroythYd0pL8XT6Nh9NT4d4SFe4tqbP5lW9/7y5ab3V7q2wfqMmS/F0qKK65z9Ud4qra/wKptseEQE3Xl2ONN30LVH3+mk9d9e9U4s0yKSguUU15wWWkdxet93natpZ3wO+mWbRokbKysjyGZWdna9GiRVWOk5ubq9jYWPcrJSXFL33Ztte7nfz4dt6OB/jDhl0HbHfB523en/tIXe5vtT0mBGq6tam9unECVZ+/5lNX/TuV+LPW448lJ/PyDngYKSgoUEJCgsewhIQEFRcX6+DBg5WOM2LECBUVFblfmzZt8ktfGtcLr1U7b8cD/CG1QaTtLvi8zftzH6nL/a22x4RATbc2tVc3TqDq89d86qp/pxJ/1nr8seRkXt4n5XNGnE6nYmJiPF7+0Ca9gZJiw1XVzUsOHb2iuPx2SG/Hw+kpoZ5TCfWcdTa/8u3v1sw0q9tbZftATdqkN1BiTM0HsOpqqmr/C6TaHhMCNV1fjjXe9C1Q9flrPnXVv1OJN8skMcapmu7CDXJIt2am+TxtW8s74GEkMTFRhYWFHsMKCwsVExOjiIiIQM/eQ3CQQzm9jl5dfPzKKP87p1eLCvdaVzdeXWkUHWZpzr9dY/qcpzF9zquTeR27/YWFBFnd3irbB2oSHOTQ6N5V30pY7q6O6XLIt/0vkGp7TAjUdL091njbt0DV56/51FX/TiXeLJPRvc/TnR3Sq53OnR3SKzxv5GRe3gEPI5mZmZo/f77HsLlz5yozMzPQs65U1/OT9NotFykx1vNbXGJseLW3NFU1XlxkqPtZDjWpbPVGOYOrHT/IcfQWre+euEotm/rnDBGq5wwJct/e2vX8JE2+5SKv17E3IsMqrvPjt7+qtjenFw8zOpYv22eUM7jWt/VKqnZZxUWGavItF2lE9xa12v8CqbbHhEBNt6rxatu3QNXnr/nUVf9OJd4skxHdW+jujukVzpCUf2ZU9ZyRk3V5+/yckX379umXX36RJF144YUaN26cOnfurAYNGuiMM87QiBEjtHnzZv35z3+WdPTW3vPPP19DhgzRbbfdpi+++EJDhw7VzJkzlZ2d7dU8/f3QM4knsPIEVp7AyhNYPfEEVv/gCaz+czo8gTVgDz1bsGCBOnfuXGH4wIEDNXXqVA0aNEjr16/XggULPMZ58MEHtWrVKjVt2lQjR4609tAzAABQNwIWRmwgjAAAcOoJ2BNYAQAA/IkwAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMCqWoWRSZMmKS0tTeHh4Wrbtq2WLFlSbfvx48frnHPOUUREhFJSUvTggw/q0KFDteowAAA4vfgcRqZNm6Zhw4YpJydHeXl5atWqlbKzs7Vt27ZK27/33nsaPny4cnJy9OOPP+rNN9/UtGnT9Nhjj51w5wEAwKnP5zAybtw43XnnnRo8eLBatGihyZMnKzIyUm+99Val7b/55htddtlluummm5SWlqYuXbroxhtvrPFsCgAA+G3wKYyUlpZq6dKlysrK+t8EgoKUlZWlRYsWVTrOpZdeqqVLl7rDx7p16zRr1ix17969yvmUlJSouLjY4wUAAE5PIb403rFjh8rKypSQkOAxPCEhQT/99FOl49x0003asWOH2rdvL2OMjhw5ot///vfV/kyTm5urMWPG+NI1AABwigr43TQLFizQM888o1dffVV5eXn6+OOPNXPmTD311FNVjjNixAgVFRW5X5s2bQp0NwEAgCU+nRmJj49XcHCwCgsLPYYXFhYqMTGx0nFGjhypW2+9VXfccYck6YILLtD+/ft111136fHHH1dQUMU85HQ65XQ6fekaAAA4Rfl0ZiQsLEwZGRmaP3++e5jL5dL8+fOVmZlZ6TgHDhyoEDiCg4MlScYYX/sLAABOMz6dGZGkYcOGaeDAgbr44ovVpk0bjR8/Xvv379fgwYMlSQMGDFCTJk2Um5srSerVq5fGjRunCy+8UG3bttUvv/yikSNHqlevXu5QAgAAfrt8DiP9+/fX9u3bNWrUKBUUFKh169aaPXu2+6LWjRs3epwJeeKJJ+RwOPTEE09o8+bNatSokXr16qWnn37af1UAAIBTlsOcAr+VFBcXKzY2VkVFRYqJibHdHQAA4AVvP7/5t2kAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVtUqjEyaNElpaWkKDw9X27ZttWTJkmrb79mzR0OGDFFSUpKcTqfOPvtszZo1q1YdBgAAp5cQX0eYNm2ahg0bpsmTJ6tt27YaP368srOztXr1ajVu3LhC+9LSUl111VVq3LixPvzwQzVp0kQbNmxQXFycP/oPAABOcQ5jjPFlhLZt2+qSSy7RxIkTJUkul0spKSm67777NHz48ArtJ0+erBdeeEE//fSTQkNDa9XJ4uJixcbGqqioSDExMbWaBgAAqFvefn779DNNaWmpli5dqqysrP9NIChIWVlZWrRoUaXj/P3vf1dmZqaGDBmihIQEnX/++XrmmWdUVlZW5XxKSkpUXFzs8QIAAKcnn8LIjh07VFZWpoSEBI/hCQkJKigoqHScdevW6cMPP1RZWZlmzZqlkSNH6qWXXtLYsWOrnE9ubq5iY2Pdr5SUFF+6CQAATiEBv5vG5XKpcePGeuONN5SRkaH+/fvr8ccf1+TJk6scZ8SIESoqKnK/Nm3aFOhuAgAAS3y6gDU+Pl7BwcEqLCz0GF5YWKjExMRKx0lKSlJoaKiCg4Pdw5o3b66CggKVlpYqLCyswjhOp1NOp9OXrgEAgFOUT2dGwsLClJGRofnz57uHuVwuzZ8/X5mZmZWOc9lll+mXX36Ry+VyD/v555+VlJRUaRABAAC/LT7/TDNs2DBNmTJF77zzjn788Ufdc8892r9/vwYPHixJGjBggEaMGOFuf88992jXrl26//779fPPP2vmzJl65plnNGTIEP9VAQAATlk+P2ekf//+2r59u0aNGqWCggK1bt1as2fPdl/UunHjRgUF/S/jpKSkaM6cOXrwwQfVsmVLNWnSRPfff78effRR/1UBAABOWT4/Z8QGnjMCAMCpJyDPGQEAAPA3wggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAq2oVRiZNmqS0tDSFh4erbdu2WrJkiVfjffDBB3I4HOrbt29tZgsAAE5DPoeRadOmadiwYcrJyVFeXp5atWql7Oxsbdu2rdrx1q9fr4ceekgdOnSodWcBAMDpx+cwMm7cON15550aPHiwWrRoocmTJysyMlJvvfVWleOUlZXp5ptv1pgxY3TmmWeeUIcBAMDpxacwUlpaqqVLlyorK+t/EwgKUlZWlhYtWlTleE8++aQaN26s22+/3av5lJSUqLi42OMFAABOTz6FkR07dqisrEwJCQkewxMSElRQUFDpOF9//bXefPNNTZkyxev55ObmKjY21v1KSUnxpZsAAOAUEtC7afbu3atbb71VU6ZMUXx8vNfjjRgxQkVFRe7Xpk2bAthLAABgU4gvjePj4xUcHKzCwkKP4YWFhUpMTKzQfu3atVq/fr169erlHuZyuY7OOCREq1evVrNmzSqM53Q65XQ6fekaAAA4Rfl0ZiQsLEwZGRmaP3++e5jL5dL8+fOVmZlZof25556rH374QcuXL3e/evfurc6dO2v58uX8/AIAAHw7MyJJw4YN08CBA3XxxRerTZs2Gj9+vPbv36/BgwdLkgYMGKAmTZooNzdX4eHhOv/88z3Gj4uLk6QKwwEAwG+Tz2Gkf//+2r59u0aNGqWCggK1bt1as2fPdl/UunHjRgUF8WBXAADgHYcxxtjuRE2Ki4sVGxuroqIixcTE2O4OAADwgref35zCAAAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhVqzAyadIkpaWlKTw8XG3bttWSJUuqbDtlyhR16NBB9evXV/369ZWVlVVtewAA8NvicxiZNm2ahg0bppycHOXl5alVq1bKzs7Wtm3bKm2/YMEC3Xjjjfryyy+1aNEipaSkqEuXLtq8efMJdx4AAJz6HMYY48sIbdu21SWXXKKJEydKklwul1JSUnTfffdp+PDhNY5fVlam+vXra+LEiRowYIBX8ywuLlZsbKyKiooUExPjS3cBAIAl3n5++3RmpLS0VEuXLlVWVtb/JhAUpKysLC1atMiraRw4cECHDx9WgwYNqmxTUlKi4uJijxcAADg9+RRGduzYobKyMiUkJHgMT0hIUEFBgVfTePTRR5WcnOwRaI6Xm5ur2NhY9yslJcWXbgIAgFNInd5N8+yzz+qDDz7QJ598ovDw8CrbjRgxQkVFRe7Xpk2b6rCXAACgLoX40jg+Pl7BwcEqLCz0GF5YWKjExMRqx33xxRf17LPPat68eWrZsmW1bZ1Op5xOpy9dAwAApyifzoyEhYUpIyND8+fPdw9zuVyaP3++MjMzqxzv+eef11NPPaXZs2fr4osvrn1vAQDAacenMyOSNGzYMA0cOFAXX3yx2rRpo/Hjx2v//v0aPHiwJGnAgAFq0qSJcnNzJUnPPfecRo0apffee09paWnua0uio6MVHR3tx1IAAMCpyOcw0r9/f23fvl2jRo1SQUGBWrdurdmzZ7svat24caOCgv53wuW1115TaWmprr32Wo/p5OTkaPTo0SfWewAAcMrz+TkjNvCcEQAATj0Bec4IAACAvxFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGBViO0O4PRS5jJakr9L2/YeUuN64WqT3kDBQQ7b3fKJNzVU18bGMqhpnse/n5FaX0s37Pa5j6VHXHrnm3wtyd+lg6VlOi85RvtLy+SSUZAciggN0jdrd2rLnoOSQ2qeUE93d/qdMn8Xr+/W79K/Vm/T56sKdaTMpcYxTl19URP9a/UOHThcpjPjo/RY9xYKDnLonW/y9d363YoMC9bZCfW0uqBYm/ccVFJMuOpFhEqStu8tUYOoMP1cUKzdBw7riMulmIhQJcVGKDEmXJFhwVq1da8Olh5RyRGX4uuFafPug9q1v0QHD7tULzxE8dFOnRkfrR37SvTr7oMKDXbo0jPj9Ui35pr+n436dt1Obd59QNv2lurg4TKFBDsUFRosh8PIERSk8JBghQY7tLfkiI6UGTmDHQoKMtpadFhlLqOQICksWHIpWEEOI2dIkCKdIWoYFabw0GBJDpWWudQ0LlL9WjdRSGiQtu0t0a59R2trXC9cLmO0OH+nNu8+qCMul3btK9G2vSU6VOpShDNYLZJidW1GU12c1kB/WbxBS/J36kBpmRpEhUky2rmvRAcOl2nPgcMyLqPo8BCdGV9PTRpEaNe+Ei1cs13Fh46ofmSYbm57hm7v0EzBQQ739tIgMkw/FRRr0+6DahIXIeMy+m7Dbq3dvk9RYcG68Iw4Pd7jPIWFBFW6jRUUH3LXkxgbUWHbq+22eLLwZX/317GhNtOpapyT5ZjtMMaYOp+rj4qLixUbG6uioiLFxMTY7g6qMHvFVo35xyptLTrkHpYUG66cXi3U9fwkiz3znjc1VNdGUp0vg5r6XNn7QQ7Jdcye700fc2et0htf5eukP2DghEWFBWt/aZlP44SFBKn0iMv99/HbWFXDa7Mtnix8Oeb56/hYm+lUNU7vVkn6+3+3BvR45e3nd63CyKRJk/TCCy+ooKBArVq10oQJE9SmTZsq28+YMUMjR47U+vXrddZZZ+m5555T9+7dvZ4fYeTkN3vFVt3zl7wKH1Tl+fq1Wy466Q8u3tQgqco2Ve1IgVwGNfX5ro7pXgWImvqYO2uVXv8q/wR7C9TsVDlm+HLM89fxsTbTqWqcqvh7+Xv7+e3zNSPTpk3TsGHDlJOTo7y8PLVq1UrZ2dnatm1bpe2/+eYb3Xjjjbr99tu1bNky9e3bV3379tWKFSt8nTVOUmUuozH/WFXpxl4+bMw/Vqmssq9JJwlvahj995Ua/ffq21QmUMugpj4bSVMWencmo7o+lh5x6Q2CCOrIqXDM8OWY56/jY22mU904VbG1/H0OI+PGjdOdd96pwYMHq0WLFpo8ebIiIyP11ltvVdr+lVdeUdeuXfXwww+refPmeuqpp3TRRRdp4sSJVc6jpKRExcXFHi+cvJbk7/I4zXc8I2lr0SEtyd9Vd53ykTc1FBSXqKC46jbVCcQyqKnPUuWnyatSVR/fXbSen2ZQp072Y4Yvxzx/HR9rMx1vjhEn0id/8imMlJaWaunSpcrKyvrfBIKClJWVpUWLFlU6zqJFizzaS1J2dnaV7SUpNzdXsbGx7ldKSoov3UQd27bXu43d23Y21FXf/DmfQPX5+Olu2HUgIPMBanKyHjN8Oeb56/hYm+mc6PKry+XvUxjZsWOHysrKlJCQ4DE8ISFBBQUFlY5TUFDgU3tJGjFihIqKityvTZs2+dJN1LHG9cL92s6GuuqbP+cTqD4fP93UBpEBmQ9Qk5P1mOHLMc9fx8faTOdEl19dLv+T8jkjTqdTMTExHi+cvNqkN1BSbLiquhnMoaNXaLdJb1CX3fKJNzUkxjiVGFN1m+oEYhnU1Gfp6J0K3va3qj7emplWq5qB2jrZjxm+HPP8dXyszXS8OUacSJ/8yacwEh8fr+DgYBUWFnoMLywsVGJiYqXjJCYm+tQep57gIIf7ttbjN/ryv3N6tTipnx3gTQ2je5+n0b2rb1Pde/5eBjX12SHpzg7plb5/vOr6GBYSpLs6pp9odwGvnArHDF+Oef46PtZmOtWNUxVby9+nMBIWFqaMjAzNnz/fPczlcmn+/PnKzMysdJzMzEyP9pI0d+7cKtvj1NT1/CS9dstFSoz1PK2XGBt+0t+iV86bGqprM/mWizS5jpdBTX0e0b1Fpe8ff4ypqY8jurfQ3R3TOUPyGxEVFuzzOGEhnh8nVX2OHT/c123xZOHLMc9fx8faTKeqcZJiw3V3x3QlnSTHbJ+fMzJt2jQNHDhQr7/+utq0aaPx48dr+vTp+umnn5SQkKABAwaoSZMmys3NlXT01t5OnTrp2WefVY8ePfTBBx/omWeeUV5ens4//3yv5slzRk4dJ8vT/E4ET2CtGk9g5QmsPIHVE09grV5AH3o2ceJE90PPWrdurT/+8Y9q27atJOnyyy9XWlqapk6d6m4/Y8YMPfHEE+6Hnj3//PM89AwAgNNcQMNIXSOMAABw6gnYE1gBAAD8iTACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwKoQ2x3wRvlz2YqLiy33BAAAeKv8c7um56ueEmFk7969kqSUlBTLPQEAAL7au3evYmNjq3z/lHgcvMvl0pYtW1SvXj05HKfOP6DkjeLiYqWkpGjTpk2n9aPufyt1Sr+dWqnz9PNbqZU6644xRnv37lVycrKCgqq+MuSUODMSFBSkpk2b2u5GQMXExJzWO0W530qd0m+nVuo8/fxWaqXOulHdGZFyXMAKAACsIowAAACrCCOWOZ1O5eTkyOl02u5KQP1W6pR+O7VS5+nnt1IrdZ58TokLWAEAwOmLMyMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCiJ9NmjRJaWlpCg8PV9u2bbVkyZIq206dOlUOh8PjFR4e7tHGGKNRo0YpKSlJERERysrK0po1awJdhlf8XevHH3+sLl26qGHDhnI4HFq+fHmAK/COP+s8fPiwHn30UV1wwQWKiopScnKyBgwYoC1bttRFKdXy9/ocPXq0zj33XEVFRal+/frKysrSt99+G+gyvOLvWo/1+9//Xg6HQ+PHjw9Az33j7zoHDRpUoU3Xrl0DXYZXArFOf/zxR/Xu3VuxsbGKiorSJZdcoo0bNwayjBr5u87j3y9/vfDCC4EuxQNhxI+mTZumYcOGKScnR3l5eWrVqpWys7O1bdu2KseJiYnR1q1b3a8NGzZ4vP/888/rj3/8oyZPnqxvv/1WUVFRys7O1qFDhwJdTrUCUev+/fvVvn17Pffcc4Huvtf8XeeBAweUl5enkSNHKi8vTx9//LFWr16t3r1710U5VQrE+jz77LM1ceJE/fDDD/r666+VlpamLl26aPv27YEup1qBqLXcJ598osWLFys5OTlQ3fdaoOrs2rWrR5v3338/kGV4JRC1rl27Vu3bt9e5556rBQsW6Pvvv9fIkSOrDaKBFog6j31v69ateuutt+RwOHTNNdcEuhxPBn7Tpk0bM2TIEPffZWVlJjk52eTm5lba/u233zaxsbFVTs/lcpnExETzwgsvuIft2bPHOJ1O8/777/ut37Xh71qPlZ+fbySZZcuW+aGnJyaQdZZbsmSJkWQ2bNhwIl09IXVRZ1FRkZFk5s2bdyJdPWGBqvXXX381TZo0MStWrDCpqanm5Zdf9lOPaycQdQ4cOND06dPHj730j0DU2r9/f3PLLbf4s5snrC720z59+pgrrrjiRLpZK5wZ8ZPS0lItXbpUWVlZ7mFBQUHKysrSokWLqhxv3759Sk1NVUpKivr06aOVK1e638vPz1dBQYHHNGNjY9W2bdtqpxlogaj1ZFRXdRYVFcnhcCguLs5fXfdJXdRZWlqqN954Q7GxsWrVqpVf+++LQNXqcrl066236uGHH9Z5550XsP57K5DrdMGCBWrcuLHOOecc3XPPPdq5c2dAavBWIGp1uVyaOXOmzj77bGVnZ6tx48Zq27at/va3vwWylGrVxX5aWFiomTNn6vbbb/dr371BGPGTHTt2qKysTAkJCR7DExISVFBQUOk455xzjt566y19+umn+stf/iKXy6VLL71Uv/76qyS5x/NlmnUhELWejOqizkOHDunRRx/VjTfeaO1f1QxknZ999pmio6MVHh6ul19+WXPnzlV8fHzAaqlJoGp97rnnFBISoqFDhwa0/94KVJ1du3bVn//8Z82fP1/PPfec/vWvf6lbt24qKysLaD3VCUSt27Zt0759+/Tss8+qa9eu+vzzz9WvXz9dffXV+te//hXwmipTF8ejd955R/Xq1dPVV1/t9/7XJKTO5wi3zMxMZWZmuv++9NJL1bx5c73++ut66qmnLPbM/34rtfpS5+HDh3X99dfLGKPXXnutrrt6Qryts3Pnzlq+fLl27NihKVOm6Prrr9e3336rxo0b2+h2rdRU69KlS/XKK68oLy9PDofDYk9PjDfr9IYbbnC/f8EFF6hly5Zq1qyZFixYoCuvvLLO+1xbNdXqcrkkSX369NGDDz4oSWrdurW++eYbTZ48WZ06dbLSb1/5etx96623dPPNN1u5LoYzI34SHx+v4OBgFRYWegwvLCxUYmKiV9MIDQ3VhRdeqF9++UWS3OOdyDQDIRC1nowCWWd5ENmwYYPmzp1r7ayIFNg6o6Ki9Lvf/U7t2rXTm2++qZCQEL355pt+67uvAlHrwoULtW3bNp1xxhkKCQlRSEiINmzYoP/7v/9TWlqav0vwSl3to2eeeabi4+Ot7seBqDU+Pl4hISFq0aKFR7vmzZtbu5sm0Ot04cKFWr16te644w6/9NdXhBE/CQsLU0ZGhubPn+8e5nK5NH/+fI9kWp2ysjL98MMPSkpKkiSlp6crMTHRY5rFxcX69ttvvZ5mIASi1pNRoOosDyJr1qzRvHnz1LBhQ7/33Rd1uT5dLpdKSkpOqL8nIhC13nrrrfr++++1fPly9ys5OVkPP/yw5syZE5A6alJX6/TXX3/Vzp07re7Hgag1LCxMl1xyiVavXu3R7ueff1Zqaqr/Ou+DQK/TN998UxkZGfau6arzS2ZPYx988IFxOp1m6tSpZtWqVeauu+4ycXFxpqCgwBhjzK233mqGDx/ubj9mzBgzZ84cs3btWrN06VJzww03mPDwcLNy5Up3m2effdbExcWZTz/91Hz//femT58+Jj093Rw8eLDO6ztWIGrduXOnWbZsmZk5c6aRZD744AOzbNkys3Xr1jqvr5y/6ywtLTW9e/c2TZs2NcuXLzdbt251v0pKSqzUaIz/69y3b58ZMWKEWbRokVm/fr35z3/+YwYPHmycTqdZsWKFlRrLBWLbPd7JcDeNv+vcu3eveeihh8yiRYtMfn6+mTdvnrnooovMWWedZQ4dOmSlxnKBWKcff/yxCQ0NNW+88YZZs2aNmTBhggkODjYLFy6s8/rKBWrbLSoqMpGRkea1116r03qORRjxswkTJpgzzjjDhIWFmTZt2pjFixe73+vUqZMZOHCg++8HHnjA3TYhIcF0797d5OXleUzP5XKZkSNHmoSEBON0Os2VV15pVq9eXVflVMvftb799ttGUoVXTk5OHVVUOX/WWX7bcmWvL7/8sg6rqsifdR48eND069fPJCcnm7CwMJOUlGR69+5tlixZUpclVcnf2+7xToYwYox/6zxw4IDp0qWLadSokQkNDTWpqanmzjvvdH8Q2haIdfrmm2+a3/3udyY8PNy0atXK/O1vf6uLUqoViDpff/11ExERYfbs2VMXJVTKYYwxds7JAAAAcM0IAACwjDACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAq/4fLqzyaR73rsYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_pred = []\n",
    "\n",
    "for i in range(len(val_sequences)):\n",
    "    inputs = loaded_tokenizer(val_sequences[i], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    labels = [val_binary_activity[i]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"].squeeze(0)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        # Sigmoid activation\n",
    "        outputs = 1 / (1 + np.exp(-outputs))\n",
    "        # print(outputs, labels)\n",
    "\n",
    "        output_pred.append(outputs)\n",
    "\n",
    "#Plot the values in output_pred with the labels from val_set_labels\n",
    "\n",
    "output_pred = np.array(output_pred)\n",
    "# val_set_labels = np.array(val_set_labels)\n",
    "\n",
    "plt.scatter(output_pred, val_binary_activity)\n",
    "plt.title(\"Predictions vs Labels for the validation set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: ðŸš€ View run \u001b[33m/home/kaustubh/RuBisCO_ML/ESM_LoRA/training_runs/esm2_t33_650M-finetuned-lora_2025-04-15_06-58-30\u001b[0m at: \u001b[34mhttps://wandb.ai/kauamritkar-university-of-wisconsin-madison/huggingface/runs/hbgguq7j\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250415_070136-hbgguq7j/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "combined_seqs = train_sequences + val_sequences\n",
    "combined_labels = train_binary_activity + val_binary_activity\n",
    "\n",
    "output_pred_all = []\n",
    "output_emb_all = []\n",
    "\n",
    "for i in range(len(combined_seqs)):\n",
    "    inputs = loaded_tokenizer(combined_seqs[i], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    labels = [combined_labels[i]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)[\"logits\"].squeeze(0)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        # Sigmoid activation\n",
    "        outputs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        output_pred_all.append(outputs)\n",
    "        # print(outputs, labels)\n",
    "        outputs_emb = loaded_model(**inputs)[\"last_hidden_state\"].squeeze(0)[0]\n",
    "        outputs_emb = outputs_emb.cpu().numpy()\n",
    "\n",
    "        output_emb_all.append(outputs_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the values in output_pred with the labels from val_set_labels\n",
    "\n",
    "output_pred_all = np.array(output_pred_all)\n",
    "combined_labels = np.array(combined_labels)\n",
    "\n",
    "plt.scatter(output_pred_all, combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "# import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distance_matrix = pairwise_distances(output_emb_all, metric=\"cosine\")\n",
    "tsne = TSNE(n_components=2, metric=\"precomputed\", init=\"random\", random_state=42)\n",
    "tsne_embedding = tsne.fit_transform(distance_matrix)\n",
    "# umap_model = umap.UMAP(n_neighbors=5, min_dist=0.3, metric=\"cosine\")\n",
    "# tsne_embedding = umap_model.fit_transform(output_emb)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(tsne_embedding[:, 0], tsne_embedding[:, 1], c=combined_labels, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
